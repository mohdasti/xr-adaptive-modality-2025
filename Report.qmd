
---
title: "XR Adaptive Modality: Experiment Report"
author: "Mohammad Dastgheib"
date: last-modified
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    code-fold: true
    self-contained: true
    fig-width: 10
    fig-height: 6
    html-math-method: mathjax
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(htmltools)
library(scales)
library(ggsci)  # For pal_npg() function
library(lme4)
library(lmerTest)
library(emmeans)

# Check for ggdist (needed for proper raincloud plots)
has_ggdist <- requireNamespace("ggdist", quietly = TRUE)
if (!has_ggdist) {
  cat("Note: Install 'ggdist' package for proper raincloud plots: install.packages('ggdist')\n")
  cat("Using fallback violin plots for now.\n")
}

# --- COLOR PALETTE ---
# Use Nature Publishing Group (NPG) palette from scales package
npg_pal <- pal_npg("nrc")(10)  # Get 10 colors from the palette

# For 2-level factors (e.g., static/adaptive), use first 2 colors
custom_palette_2 <- npg_pal[1:2]

# For multi-level factors (e.g., TLX scales with 6 levels), use first 6 colors
custom_palette_multi <- npg_pal[1:6]

# --- RAINCLOUD PLOT HELPER ---
# Function to create proper raincloud plots (half-violin + boxplot + points + lines)
# Based on Allen et al. (2019) "Raincloud plots: a multi-platform tool for robust data visualization"
create_raincloud <- function(data, x_var, y_var, fill_var, group_var = NULL, 
                             violin_side = "r", violin_width = 0.4, 
                             box_width = 0.15, point_size = 2.5, 
                             line_alpha = 0.3, point_alpha = 0.7) {
  
  # Check if ggdist is available for proper half-violins
  has_ggdist <- requireNamespace("ggdist", quietly = TRUE)
  
  p <- ggplot(data, aes_string(x = x_var, y = y_var, fill = fill_var))
  
  if (has_ggdist) {
    # Use ggdist for proper half-violins
    p <- p + 
      ggdist::stat_halfeye(
        aes(fill = .data[[fill_var]]),
        side = violin_side,
        alpha = 0.4,
        width = violin_width,
        .width = 0,
        justification = ifelse(violin_side == "r", -0.3, 1.3),
        point_colour = NA
      )
  } else {
    # Fallback: create half-violin manually using geom_violin with positioning
    # This creates a full violin, but we'll position it to show only half
    p <- p +
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = violin_width,
        position = position_nudge(x = ifelse(violin_side == "r", 0.25, -0.25)),
        color = NA
      )
  }
  
  # Boxplot (positioned on the left, inside the violin area)
  p <- p +
    geom_boxplot(
      width = box_width,
      alpha = 0.6,
      outlier.shape = NA,
      position = position_nudge(x = -0.15),
      color = "grey30",
      linewidth = 0.5
    )
  
  # Connecting lines (if group_var provided, for paired data)
  if (!is.null(group_var)) {
    p <- p +
      geom_line(
        aes_string(group = group_var, color = fill_var),
        alpha = line_alpha,
        linewidth = 0.6,
        position = position_nudge(x = -0.25)
      )
  }
  
  # Individual points
  p <- p +
    geom_point(
      aes_string(color = fill_var),
      alpha = point_alpha,
      size = point_size,
      position = position_nudge(x = -0.25)
    )
  
  # Mean marker (white diamond)
  p <- p +
    stat_summary(
      fun = mean,
      geom = "point",
      shape = 23,
      size = 4,
      fill = "white",
      color = "black",
      stroke = 1.2,
      position = position_nudge(x = -0.25)
    )
  
  return(p)
}

# --- HELPER: BUILD MODEL FORMULAS WITH AVAILABLE FACTORS ---
build_mixed_formula <- function(dv, factors, data) {
  keep <- factors[sapply(factors, function(f) n_distinct(data[[f]], na.rm = TRUE) > 1)]
  dropped <- setdiff(factors, keep)
  rhs <- if (length(keep) > 0) paste(keep, collapse = " * ") else "1"
  list(
    formula = as.formula(paste(dv, "~", rhs, "+ (1 | pid)")),
    dropped = dropped
  )
}

# --- DATA LOADING ---
# Load the latest clean data
# Try multiple possible paths (relative to report location or working directory)
data_paths <- c(
  "data/clean/trial_data.csv",           # If running from project root
  "../data/clean/trial_data.csv"         # If running from subdirectory
)

df_raw <- NULL
for (path in data_paths) {
  if (file.exists(path)) {
    tryCatch({
      df_raw <- read_csv(path, show_col_types = FALSE)
      cat("Loaded data from:", path, "\n")
      break
    }, error = function(e) {
      # Continue to next path
    })
  }
}

if (is.null(df_raw)) {
  stop("Could not find 'trial_data.csv'. Tried paths:\n",
       paste("  -", data_paths, collapse = "\n"),
       "\nCurrent working directory:", getwd(),
       "\nPlease ensure the data pipeline has run and the file exists.")
}

# Normalize column names
if ("participant_id" %in% names(df_raw) && !"pid" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(pid = participant_id)
}
if ("movement_time_ms" %in% names(df_raw) && !"rt_ms" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(rt_ms = movement_time_ms)
}

# Ensure required pid column exists
if (!"pid" %in% names(df_raw)) {
  stop("Required column 'pid' is missing after loading data. Available columns: ", paste(names(df_raw), collapse = ", "))
}

# --- PREPROCESSING ---
# Create dataframe with ALL trials (correct + incorrect) for error rate calculations
# This includes trials with valid RTs (even if incorrect) and excludes only practice trials
df_all_trials <- df_raw %>%
  filter(
    practice == "false" | practice == FALSE | is.na(practice)
  ) %>%
  mutate(
    rt_s = rt_ms / 1000,
    log_rt = log(rt_ms),
    # Create factor labels for better plots
    Condition = paste(modality, ui_mode, sep = " - "),
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    ModalityLabel = str_to_title(modality),
    UILabel = str_to_title(ui_mode),
    # Ensure factors
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid),
    # Mark correct/incorrect for error calculations
    # Note: In the data, correct = TRUE for correct trials, and correct = NA for errors
    is_correct = !is.na(correct) & (correct == "true" | correct == TRUE | correct == 1)
  )

# Filter valid experimental trials (non-practice, correct, valid RTs) for performance metrics
df <- df_all_trials %>%
  filter(
    is_correct == TRUE,
    rt_ms >= 150,  # Physiological minimum
    rt_ms <= 6000  # Time-out threshold
  )

# --- DATA QUALITY & COVERAGE GATE (INTERIM) ---
# Precompute coverage metrics once; reused across report
qc_participants_total <- df_raw %>%
  filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
  pull(pid) %>%
  n_distinct()

qc_participants_included <- df %>% pull(pid) %>% n_distinct()
qc_participants_all_trials <- df_all_trials %>% pull(pid) %>% n_distinct()

qc_cell_coverage <- df_all_trials %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    trials = n(),
    pids = n_distinct(.data$pid),
    .groups = "drop"
  ) %>%
  tidyr::complete(modality, ui_mode, pressure, fill = list(trials = 0, pids = 0)) %>%
  mutate(missing_cell = trials == 0 | pids == 0)

qc_missing_factors <- list(
  modality = n_distinct(df_all_trials$modality, na.rm = TRUE) < 2,
  ui_mode = n_distinct(df_all_trials$ui_mode, na.rm = TRUE) < 2,
  pressure = n_distinct(df_all_trials$pressure, na.rm = TRUE) < 2
)

qc_block_completion <- df_all_trials %>%
  filter(!is.na(block_number)) %>%
  group_by(pid) %>%
  summarise(
    blocks_logged = n_distinct(block_number),
    .groups = "drop"
  )

# --- CALCULATE ISO METRICS (Throughput) ---
# ISO 9241-9: Calculate We (Effective Width) per condition per participant
df_iso <- df %>%
  group_by(pid, modality, ui_mode, pressure, A, W) %>%
  summarise(
    # We = 4.133 * SD of Projected Error
    sd_x = sd(projected_error_px, na.rm = TRUE),
    We = 4.133 * sd_x,
    
    # Effective ID
    IDe = log2((mean(A) / We) + 1),
    
    # Mean Movement Time for this condition
    MT_avg = mean(rt_s, na.rm = TRUE),
    
    # Throughput (Bits/s)
    TP = IDe / MT_avg,
    
    # Gaze Specifics
    reentries = mean(target_reentry_count, na.rm = TRUE),
    verification = mean(verification_time_ms, na.rm = TRUE),
    
    .groups = "drop"
  ) %>%
  filter(!is.na(TP), TP > 0, TP < 20) %>%  # Reasonable TP range
  mutate(
    # Recreate labels that were lost in summarise
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    Condition = paste(modality, ui_mode, sep = " - ")
  )

# Participant-level performance summaries (used across core analyses)
df_pid_cond <- df %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(
    rt_mean = mean(rt_s, na.rm = TRUE),
    rt_median = median(rt_s, na.rm = TRUE),
    trials_rt = n(),
    .groups = "drop"
  ) %>%
  left_join(
    df_all_trials %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(
        error_rate = mean(!is_correct, na.rm = TRUE),
        trials_all = n(),
        .groups = "drop"
      ),
    by = c("pid", "modality", "ui_mode", "pressure")
  ) %>%
  left_join(
    df_iso %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(tp_mean = mean(TP, na.rm = TRUE), .groups = "drop"),
    by = c("pid", "modality", "ui_mode", "pressure")
  )

# --- STATISTICAL MODELS ---
# Helper function for diagnostics
diagnose_model_data <- function(data, model_name) {
  diag <- list()
  
  if (nrow(data) == 0) {
    diag$n_participants <- 0
    diag$n_trials <- 0
    diag$n_conditions <- 0
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$single_level_factors <- character(0)
    return(diag)
  }
  
  diag$n_participants <- n_distinct(data$pid)
  diag$n_trials <- nrow(data)
  
  # Check if required columns exist
  has_modality <- "modality" %in% names(data)
  has_ui_mode <- "ui_mode" %in% names(data)
  has_pressure <- "pressure" %in% names(data)
  
  # Check for single-level factors (causes "contrasts" error)
  single_level_factors <- character(0)
  if (has_modality && n_distinct(data$modality, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "modality")
  }
  if (has_ui_mode && n_distinct(data$ui_mode, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "ui_mode")
  }
  if (has_pressure && n_distinct(data$pressure, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "pressure")
  }
  diag$single_level_factors <- single_level_factors
  
  if (has_modality && has_ui_mode && has_pressure) {
    diag$n_conditions <- length(unique(interaction(data$modality, data$ui_mode, data$pressure, drop = TRUE)))
    
    # Check trials per condition
    condition_counts <- data %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(n = n(), .groups = "drop")
    diag$condition_counts <- condition_counts
    diag$min_trials_per_condition <- if(nrow(condition_counts) > 0) min(condition_counts$n, na.rm = TRUE) else 0
    diag$empty_conditions <- sum(condition_counts$n == 0, na.rm = TRUE)
  } else {
    diag$n_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
  }
  
  # Check for missing values in key variables
  diag$missing_tp <- if("TP" %in% names(data)) sum(is.na(data$TP)) else 0
  diag$missing_modality <- if(has_modality) sum(is.na(data$modality)) else 0
  diag$missing_ui_mode <- if(has_ui_mode) sum(is.na(data$ui_mode)) else 0
  diag$missing_pressure <- if(has_pressure) sum(is.na(data$pressure)) else 0
  
  return(diag)
}

# Model 1: Throughput
model_tp <- NULL
emm_tp <- NULL
pairs_tp <- NULL
diag_tp <- NULL
model_tp_error <- NULL
model_tp_note <- NULL

if (nrow(df_iso) > 0) {
  diag_tp <- diagnose_model_data(df_iso, "Throughput")
  
  if (diag_tp$n_participants <= 1) {
    model_tp_error <- paste0("Insufficient participants: N = ", diag_tp$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_tp$n_trials == 0) {
    model_tp_error <- "No valid trials in dataset."
  } else if (diag_tp$min_trials_per_condition < 3) {
    model_tp_error <- paste0("Insufficient data per condition: minimum ", diag_tp$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_tp$empty_conditions > 0) {
    model_tp_error <- paste0("Empty conditions detected: ", diag_tp$empty_conditions, " condition(s) have no data.")
  } else {
  formula_tp <- build_mixed_formula("TP", c("modality", "ui_mode", "pressure"), df_iso)
  if (length(formula_tp$dropped) > 0) {
    model_tp_note <- paste0("Dropped single-level factor(s): ", paste(formula_tp$dropped, collapse = ", "), " (interim data).")
  }
  model_tp <- tryCatch({
    lmer(formula_tp$formula,
         data = df_iso, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_tp_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_tp_error)) {
        model_tp_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_tp)) {
      # Check for convergence warnings
      conv_warnings <- warnings()
      if (length(conv_warnings) > 0) {
        model_tp_error <- paste0("Convergence warnings detected. Model may be unreliable.")
      }
      
    tryCatch({
      emm_tp <- emmeans(model_tp, ~ modality * ui_mode * pressure)
      pairs_tp <- pairs(emm_tp, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_tp_error)) {
          model_tp_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_tp <- list(n_participants = 0, n_trials = 0)
  model_tp_error <- "No data available for throughput analysis."
}

# Model 2: Movement Time
model_rt <- NULL
emm_rt <- NULL
pairs_rt <- NULL
diag_rt <- NULL
model_rt_error <- NULL
model_rt_note <- NULL

if (nrow(df) > 0) {
  diag_rt <- diagnose_model_data(df, "Movement Time")
  
  if (diag_rt$n_participants <= 1) {
    model_rt_error <- paste0("Insufficient participants: N = ", diag_rt$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_rt$n_trials == 0) {
    model_rt_error <- "No valid trials in dataset."
  } else if (diag_rt$min_trials_per_condition < 3) {
    model_rt_error <- paste0("Insufficient data per condition: minimum ", diag_rt$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_rt$empty_conditions > 0) {
    model_rt_error <- paste0("Empty conditions detected: ", diag_rt$empty_conditions, " condition(s) have no data.")
  } else {
  formula_rt <- build_mixed_formula("log_rt", c("modality", "ui_mode", "pressure"), df)
  if (length(formula_rt$dropped) > 0) {
    model_rt_note <- paste0("Dropped single-level factor(s): ", paste(formula_rt$dropped, collapse = ", "), " (interim data).")
  }
  model_rt <- tryCatch({
    lmer(formula_rt$formula, 
         data = df, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_rt_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_rt_error)) {
        model_rt_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_rt)) {
      # Check for convergence warnings
      conv_warnings <- warnings()
      if (length(conv_warnings) > 0) {
        model_rt_error <- paste0("Convergence warnings detected. Model may be unreliable.")
      }
      
    tryCatch({
      emm_rt <- emmeans(model_rt, ~ modality * ui_mode * pressure, type = "response")
      pairs_rt <- pairs(emm_rt, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_rt_error)) {
          model_rt_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_rt <- list(n_participants = 0, n_trials = 0)
  model_rt_error <- "No data available for movement time analysis."
}

# Model 3: Error Rate
# Use df_all_trials which already has all trials (correct + incorrect)
df_errors <- df_all_trials %>%
  mutate(
    error = ifelse(is_correct, 0, 1),
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid)
  )

model_err <- NULL
emm_err <- NULL
pairs_err <- NULL
diag_err <- NULL
model_err_error <- NULL
model_err_note <- NULL

if (nrow(df_errors) > 0) {
  diag_err <- diagnose_model_data(df_errors, "Error Rate")
  
  if (diag_err$n_participants <= 1) {
    model_err_error <- paste0("Insufficient participants: N = ", diag_err$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_err$n_trials == 0) {
    model_err_error <- "No valid trials in dataset."
  } else if (diag_err$min_trials_per_condition < 3) {
    model_err_error <- paste0("Insufficient data per condition: minimum ", diag_err$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_err$empty_conditions > 0) {
    model_err_error <- paste0("Empty conditions detected: ", diag_err$empty_conditions, " condition(s) have no data.")
  } else {
    # Check for sufficient error variance (GLMM needs some errors)
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    if (error_rate < 0.01 || error_rate > 0.99) {
      model_err_error <- paste0("Insufficient error variance: error rate = ", round(error_rate * 100, 1), "%. GLMM requires some variation in outcomes.")
    } else {
  formula_err <- build_mixed_formula("error", c("modality", "ui_mode", "pressure"), df_errors)
  if (length(formula_err$dropped) > 0) {
    model_err_note <- paste0("Dropped single-level factor(s): ", paste(formula_err$dropped, collapse = ", "), " (interim data).")
  }
  model_err <- tryCatch({
    glmer(formula_err$formula,
          data = df_errors, family = binomial(link = "logit"),
          control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
  }, error = function(e) {
        model_err_error <<- paste0("Model fitting failed: ", e$message)
        NULL
      }, warning = function(w) {
        if (is.null(model_err_error)) {
          model_err_error <<- paste0("Model fitting warning: ", w$message)
        }
    NULL
  })
  
  if (!is.null(model_err)) {
        # Check for convergence warnings
        conv_warnings <- warnings()
        if (length(conv_warnings) > 0) {
          model_err_error <- paste0("Convergence warnings detected. Model may be unreliable.")
        }
        
    tryCatch({
      emm_err <- emmeans(model_err, ~ modality * ui_mode * pressure, type = "response")
      pairs_err <- pairs(emm_err, adjust = "holm")
    }, error = function(e) {
          if (is.null(model_err_error)) {
            model_err_error <<- paste0("Could not compute estimated marginal means: ", e$message)
          }
    })
  }
    }
  }
} else {
  diag_err <- list(n_participants = 0, n_trials = 0)
  model_err_error <- "No data available for error rate analysis."
}
```

# Data Quality & Coverage Gate (Interim N)

::: {.callout-note}
This section prevents misleading models when cells are missing. Current data are interim (N=`r n_distinct(df$pid)`); treat all effects as descriptive.
:::

```{r qc-gate}
# Participants
qc_participants <- tibble(
  Metric = c("Total participants (raw)", "Participants with any valid trials", "Participants in df (correct, RT-filtered)"),
  Count = c(qc_participants_total, qc_participants_all_trials, qc_participants_included)
)

# Cell coverage table
qc_cells_table <- qc_cell_coverage %>%
  arrange(modality, ui_mode, pressure) %>%
  mutate(
    pressure = as.character(pressure),
    Status = ifelse(missing_cell, "MISSING", "OK")
  )

missing_factors <- names(qc_missing_factors)[unlist(qc_missing_factors)]

qc_participants %>%
  kable(caption = "Participant counts (interim)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

qc_cells_table %>%
  kable(caption = "Condition coverage (modality × ui_mode × pressure)", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

if (length(missing_factors) > 0) {
  cat("**Missing factor levels detected:**", paste(missing_factors, collapse = ", "), "\n\n")
} else {
  cat("All factors have ≥2 levels in the interim data.\n\n")
}

if (nrow(qc_block_completion) > 0) {
  qc_block_completion %>%
    kable(caption = "Blocks logged per participant", align = "c") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```


# 1. Executive Summary

This report analyzes **`r n_distinct(df$pid)`** participants performing Fitts' law pointing tasks across two input modalities (Hand, Gaze) and two UI modes (Static, Adaptive).

**Note on Participant Exclusions:** Seven participants (P002, P003, P007, P008, P015, P039, P040) were excluded from the main 2×2×2 factorial analysis due to a data logging error that incorrectly recorded pressure conditions. The bug was fixed on December 8, 2025 (commit `04758db`), and seven replacement participants (P049-P055) were added. The final analysis sample consists of N=48 participants with complete data across all experimental conditions. See the Data Quality Notes section and `EXCLUSION_CRITERIA.md` for details.

# Results Snapshot (Interim, N = `r qc_participants_included`)

```{r results-snapshot}
# Simple contrasts: adaptive - static within modality (averaged over pressure where available)
contrast_table <- df_pid_cond %>%
  group_by(modality, ui_mode) %>%
  summarise(tp = mean(tp_mean, na.rm = TRUE),
            rt = mean(rt_mean, na.rm = TRUE),
            err = mean(error_rate, na.rm = TRUE),
            .groups = "drop") %>%
  pivot_wider(names_from = ui_mode, values_from = c(tp, rt, err)) %>%
  mutate(
    tp_diff_adapt_static = tp_adaptive - tp_static,
    rt_diff_adapt_static = rt_adaptive - rt_static,
    err_diff_adapt_static = err_adaptive - err_static
  ) %>%
  select(modality, tp_diff_adapt_static, rt_diff_adapt_static, err_diff_adapt_static)

tlx_snapshot <- df_raw %>%
  filter(!is.na(pid)) %>%
  group_by(pid, modality, ui_mode) %>%
  summarise(overall_tlx = mean(c_across(starts_with("tlx_")), na.rm = TRUE), .groups = "drop") %>%
  group_by(modality, ui_mode) %>%
  summarise(Mean_Overall_TLX = round(mean(overall_tlx, na.rm = TRUE), 1),
            .groups = "drop")

manip_snapshot <- df_raw %>%
  filter(!is.na(width_scale_factor)) %>%
  group_by(modality, ui_mode) %>%
  summarise(
    Mean_Width_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
    Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
    .groups = "drop"
  )

contrast_table %>%
  kable(caption = "RQ1 contrasts (adaptive - static; interim descriptive)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

tlx_snapshot %>%
  kable(caption = "RQ2 snapshot: Overall TLX (interim)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

manip_snapshot %>%
  kable(caption = "RQ3 manipulation check: width scaling (interim)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Key Findings

  * **Total Trials Analyzed:** `r nrow(df)` valid trials (correct responses, RT 150-6000ms)
  * **Total Trials Collected:** `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))`
  * **Overall Error Rate:** `r percent(round(1 - (sum(df$correct == TRUE | df$correct == "true" | df$correct == 1)/nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))), 3))`
  * **Mean Throughput:** `r round(mean(df_iso$TP, na.rm = TRUE), 2)` bits/s (SD = `r round(sd(df_iso$TP, na.rm = TRUE), 2)`)
  * **Mean Movement Time:** `r round(mean(df$rt_s, na.rm = TRUE), 3)`s (SD = `r round(sd(df$rt_s, na.rm = TRUE), 3)`s)

-----

# 2. Demographics

```{r demographics}
# Ensure pid column exists
demog_raw <- df_raw
if ("participant_id" %in% names(demog_raw) && !"pid" %in% names(demog_raw)) {
  demog_raw <- demog_raw %>% rename(pid = participant_id)
}

demog_summary <- demog_raw %>%
  distinct(pid, .keep_all = TRUE) %>%
  select(pid, age, gender, gaming_hours_per_week, input_device) %>%
  filter(!is.na(pid))

# Overall summary
overall_stats <- demog_summary %>%
  summarise(
    `N` = n(),
    `Mean Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Age Range` = paste(round(min(age, na.rm=TRUE), 0), "-", round(max(age, na.rm=TRUE), 0)),
    `Mean Gaming (Hrs/Week)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    `SD Gaming` = round(sd(gaming_hours_per_week, na.rm=TRUE), 1)
  )

# By gender
gender_stats <- demog_summary %>%
  filter(!is.na(gender)) %>%
  group_by(gender) %>%
  summarise(
    Count = n(),
    `Avg Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Avg Gaming (Hrs)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    .groups = "drop"
  )

# Input device distribution
device_stats <- demog_summary %>%
  filter(!is.na(input_device)) %>%
  count(input_device, name = "Count") %>%
  mutate(Percentage = round(100 * Count / sum(Count), 1))


```

## Overall Demographics

```{r}
overall_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## By Gender

```{r}
gender_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## Input Device Distribution

```{r}
device_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


-----

# 3. Primary Analysis: Throughput

**Research Question:** Does the Adaptive UI improve performance (Throughput) compared to Static, especially for Gaze?

## Summary Statistics

```{r tp-summary}
tp_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N = n(),
    Mean = round(mean(TP, na.rm = TRUE), 2),
    SD = round(sd(TP, na.rm = TRUE), 2),
    Median = round(median(TP, na.rm = TRUE), 2),
    Q25 = round(quantile(TP, 0.25, na.rm = TRUE), 2),
    Q75 = round(quantile(TP, 0.75, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

tp_summary %>%
  kable(caption = "Throughput (bits/s) by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-tp}
#| fig-cap: "Throughput by Modality and UI Mode (participant-level means). Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons."

# Prepare data for raincloud plot with mirrored half-violins
df_tp_plot <- df_pid_cond %>%
  filter(!is.na(tp_mean))

# Raincloud plot with mirrored half-violins
p_tp <- ggplot(df_tp_plot, aes(x = ui_mode, y = tp_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        # Static: half-violin extending LEFT (outward from left position)
        ggdist::stat_halfeye(
          data = df_tp_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        # Adaptive: half-violin extending RIGHT (outward from right position)
        ggdist::stat_halfeye(
          data = df_tp_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      # Fallback: full violins
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  facet_grid(modality ~ pressure, labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Throughput (bits/s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_tp)
```

```{r plot-tp-emm, eval=exists("emm_tp") && !is.null(emm_tp)}
#| fig-cap: "Estimated Marginal Means for Throughput (shown only when model fits and factors exist)."
if (exists("emm_tp") && !is.null(emm_tp)) {
  emm_tp_df <- as.data.frame(emm_tp) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Check for CI column names (may vary by emmeans version/type)
  ci_lower <- if ("lower.CL" %in% names(emm_tp_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_tp_df)) "asymp.LCL" else NULL
  ci_upper <- if ("upper.CL" %in% names(emm_tp_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_tp_df)) "asymp.UCL" else NULL
  
  p_emm_tp <- ggplot(emm_tp_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.1, position = position_dodge(0.2)) +
    geom_point(size = 2.8, position = position_dodge(0.2))
  
  # Add error bars only if CI columns exist
  if (!is.null(ci_lower) && !is.null(ci_upper)) {
    p_emm_tp <- p_emm_tp + geom_errorbar(
      aes(ymin = .data[[ci_lower]], ymax = .data[[ci_upper]]), 
      width = 0.1, position = position_dodge(0.2)
    )
  }
  
  p_emm_tp <- p_emm_tp +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Throughput (bits/s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(legend.position = "top")
  
  print(p_emm_tp)
}
```

## Statistical Model Results

```{r tp-model}
if (exists("model_tp") && !is.null(model_tp)) {
  cat("### Model: ", deparse(formula_tp$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_tp)) {
    cat("**Data Summary:** ", diag_tp$n_participants, " participants, ", diag_tp$n_trials, " trials, ", 
        diag_tp$n_conditions, " conditions, minimum ", diag_tp$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  if (!is.null(model_tp_note)) {
    cat("**Interim note:** ", model_tp_note, "\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_tp <- anova(model_tp, type = "III")
  print(anova_tp)
  
  # Model summary
  cat("\n#### Model Summary\n")
  print(summary(model_tp))
  
  # Pairwise comparisons
  if (exists("pairs_tp") && !is.null(pairs_tp)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_tp_df <- as.data.frame(pairs_tp)
    print(pairs_tp_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Throughput.**\n\n")
  
  if (!is.null(model_tp_error)) {
    cat("**Reason:** ", model_tp_error, "\n\n")
  }
  
  if (!is.null(diag_tp)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_tp$n_participants, "\n")
    cat("- Total trials: ", diag_tp$n_trials, "\n")
    cat("- Conditions: ", diag_tp$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_tp$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_tp$empty_conditions, "\n")
    
    if (length(diag_tp$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_tp$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_tp$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_tp$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 4. Movement Time Analysis

**Research Question:** How does movement time vary across conditions?

## Summary Statistics

```{r rt-summary}
rt_summary <- df %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N = n(),
    Mean = round(mean(rt_s, na.rm = TRUE), 3),
    SD = round(sd(rt_s, na.rm = TRUE), 3),
    Median = round(median(rt_s, na.rm = TRUE), 3),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

rt_summary %>%
  kable(caption = "Movement Time (s) by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-rt}
#| fig-cap: "Movement Time by Modality and UI Mode (participant-level means). Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons."

# Prepare data for raincloud plot
df_rt_plot <- df_pid_cond %>%
  filter(!is.na(rt_mean))

# Raincloud plot with mirrored half-violins
p_rt <- ggplot(df_rt_plot, aes(x = ui_mode, y = rt_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_rt_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_rt_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  facet_grid(modality ~ pressure, labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Movement Time (s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_rt)
```

```{r plot-rt-emm, eval=exists("emm_rt") && !is.null(emm_rt)}
#| fig-cap: "Estimated Marginal Means for Movement Time (shown only when model fits and factors exist)."
if (exists("emm_rt") && !is.null(emm_rt)) {
  emm_rt_df <- as.data.frame(emm_rt) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Check for CI column names (may vary by emmeans version/type)
  ci_lower <- if ("lower.CL" %in% names(emm_rt_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_rt_df)) "asymp.LCL" else NULL
  ci_upper <- if ("upper.CL" %in% names(emm_rt_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_rt_df)) "asymp.UCL" else NULL
  
  p_emm_rt <- ggplot(emm_rt_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.1, position = position_dodge(0.2)) +
    geom_point(size = 2.8, position = position_dodge(0.2))
  
  # Add error bars only if CI columns exist
  if (!is.null(ci_lower) && !is.null(ci_upper)) {
    p_emm_rt <- p_emm_rt + geom_errorbar(
      aes(ymin = .data[[ci_lower]], ymax = .data[[ci_upper]]), 
      width = 0.1, position = position_dodge(0.2)
    )
  }
  
  p_emm_rt <- p_emm_rt +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Movement Time (s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(legend.position = "top")
  
  print(p_emm_rt)
}
```

## Statistical Model Results

```{r rt-model}
if (exists("model_rt") && !is.null(model_rt)) {
  cat("### Model: ", deparse(formula_rt$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_rt)) {
    cat("**Data Summary:** ", diag_rt$n_participants, " participants, ", diag_rt$n_trials, " trials, ", 
        diag_rt$n_conditions, " conditions, minimum ", diag_rt$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  if (!is.null(model_rt_note)) {
    cat("**Interim note:** ", model_rt_note, "\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_rt <- anova(model_rt, type = "III")
  print(anova_rt)
  
  # Pairwise comparisons
  if (exists("pairs_rt") && !is.null(pairs_rt)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_rt_df <- as.data.frame(pairs_rt)
    print(pairs_rt_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Movement Time.**\n\n")
  
  if (!is.null(model_rt_error)) {
    cat("**Reason:** ", model_rt_error, "\n\n")
  }
  
  if (!is.null(diag_rt)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_rt$n_participants, "\n")
    cat("- Total trials: ", diag_rt$n_trials, "\n")
    cat("- Conditions: ", diag_rt$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_rt$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_rt$empty_conditions, "\n")
    
    if (length(diag_rt$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_rt$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_rt$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_rt$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 5. Fitts' Law Modelling

**Research Question:** How well does the data fit Fitts' Law? (Linearity check).
*Flatter slopes indicate less sensitivity to difficulty (ballistic movement).*

```{r plot-fitts}
#| fig-cap: "Fitts' Law Regression (Movement Time vs Effective Index of Difficulty). The effective index of difficulty (IDe) is calculated using the effective target width (We) derived from the spatial distribution of selection endpoints. Shaded regions around regression lines represent 95% confidence intervals. Linear regression fits are shown separately for each modality and UI mode combination."
# Aggregate for regression plot
fitts_model <- df_iso %>%
  group_by(modality, ui_mode, IDe) %>%
  summarise(
    MT = mean(MT_avg, na.rm = TRUE),
    MT_se = sd(MT_avg, na.rm = TRUE) / sqrt(n()),
    N = n(),
    .groups = "drop"
  ) %>%
  filter(!is.na(IDe), !is.na(MT))

# Fit linear models for each condition
fitts_fits <- fitts_model %>%
  group_by(modality, ui_mode) %>%
  do(model = tryCatch(lm(MT ~ IDe, data = .), error = function(e) NULL)) %>%
  filter(!is.null(model)) %>%
  mutate(
    r_squared = round(summary(model)$r.squared, 3),
    slope = round(coef(model)[2], 3),
    intercept = round(coef(model)[1], 3)
  )

ggplot(fitts_model, aes(x = IDe, y = MT, color = ui_mode)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  facet_grid(. ~ modality) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
  labs(
    x = "Index of Difficulty (bits)",
    y = "Movement Time (s)",
    color = "UI Mode"
  ) +
  theme_light(base_size = 14) +
  theme(legend.position = "top")
```

```{r}
# Display R² values
if (nrow(fitts_fits) > 0) {
  cat("\n### Model Fit Statistics\n")
  fitts_fits %>%
    select(modality, ui_mode, r_squared, slope, intercept) %>%
    kable(caption = "Linear Regression: MT ~ IDe") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```

-----

# 6. Error Rate Analysis

**Research Question:** How do error rates differ across conditions?

```{r error-analysis}
#| fig-cap: "Error Rate by Modality and UI Mode (participant-level means). Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons."
# Calculate condition-level summary
error_summary <- df_pid_cond %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Participants = n(),
    Mean_Error_Rate = round(100 * mean(error_rate, na.rm = TRUE), 2),
    SD_Error_Rate = round(100 * sd(error_rate, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

error_summary %>%
  kable(caption = "Error Rates by Condition (participant means)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# Prepare data for raincloud plot
df_err_plot <- df_pid_cond %>%
  filter(!is.na(error_rate)) %>%
  mutate(Error_Rate = 100 * error_rate)

# Raincloud plot with mirrored half-violins
p_err <- ggplot(df_err_plot, aes(x = ui_mode, y = Error_Rate, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_err_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_err_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  facet_grid(modality ~ pressure, labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Error Rate (%)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_err)
```

## Statistical Model Results

```{r error-model}
if (exists("model_err") && !is.null(model_err)) {
  cat("### Model: ", deparse(formula_err$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Data Summary:** ", diag_err$n_participants, " participants, ", diag_err$n_trials, " trials, ", 
        diag_err$n_conditions, " conditions, minimum ", diag_err$min_trials_per_condition, " trials per condition.\n")
    cat("**Overall Error Rate:** ", round(error_rate * 100, 1), "%\n\n")
  }
  
  if (!is.null(model_err_note)) {
    cat("**Interim note:** ", model_err_note, "\n\n")
  }
  
  # ANOVA table
  if (requireNamespace("car", quietly = TRUE)) {
    library(car)
    cat("#### ANOVA Table\n")
    print(Anova(model_err, type = "III"))
  }
  
  # Pairwise comparisons
  if (exists("pairs_err") && !is.null(pairs_err)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_err_df <- as.data.frame(pairs_err)
    print(pairs_err_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Error Rate.**\n\n")
  
  if (!is.null(model_err_error)) {
    cat("**Reason:** ", model_err_error, "\n\n")
  }
  
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_err$n_participants, "\n")
    cat("- Total trials: ", diag_err$n_trials, "\n")
    cat("- Conditions: ", diag_err$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_err$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_err$empty_conditions, "\n")
    cat("- Overall error rate: ", round(error_rate * 100, 1), "%\n")
    
    if (length(diag_err$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_err$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_err$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_err$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 7. Accuracy & Gaze Dynamics

## Effective Width ($W_e$)

*Lower $W_e$ indicates tighter shot grouping (higher precision).*

```{r we-summary}
#| tbl-cap: "Effective Width (px) by Condition"

we_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Mean_We = round(mean(We, na.rm = TRUE), 2),
    SD_We = round(sd(We, na.rm = TRUE), 2),
    .groups = "drop"
  )

knitr::kable(we_summary)
```

```{r plot-we}
#| fig-cap: "Effective Target Width (Accuracy) by Modality and UI Mode. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower values indicate tighter shot grouping and higher precision."

# Aggregate to participant-level means
df_we_plot <- df_iso %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(We_mean = mean(We, na.rm = TRUE), .groups = "drop") %>%
  filter(!is.na(We_mean))

# Raincloud plot for Effective Width
ggplot(df_we_plot, aes(x = ui_mode, y = We_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_we_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_we_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  facet_grid(modality ~ pressure, labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Effective Width (px)",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )
```

## Endpoint Accuracy Scatter Plot

*Visualization of endpoint errors relative to target center. Each point represents one trial's endpoint position.*

```{r plot-accuracy-scatter}
#| fig-width: 12
#| fig-height: 8
#| fig-cap: "Endpoint Accuracy Scatter Plot for Gaze Modality. Each point represents one trial's endpoint position relative to the target center (0,0). The red dashed circle shows the approximate target size. Points closer to the center indicate better accuracy. Dotted lines indicate zero error in X and Y directions. Faceted by pressure condition."
# Calculate endpoint errors relative to target center
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  # Calculate target radius (approximate from W, assuming circular targets)
  target_radius <- ifelse("W" %in% names(gaze_accuracy), 
                          mean(gaze_accuracy$W, na.rm = TRUE) / 2, 
                          20)
  
  # Create circle data for target visualization
  circle_data <- data.frame(
    x = target_radius * cos(seq(0, 2*pi, length.out = 100)),
    y = target_radius * sin(seq(0, 2*pi, length.out = 100))
  )
  
  p_accuracy <- ggplot(gaze_accuracy, aes(x = err_x, y = err_y, color = UI)) +
    # Draw target circle (centered at 0,0)
    geom_path(data = circle_data, aes(x = x, y = y), 
              inherit.aes = FALSE, color = "red", linetype = "dashed", linewidth = 1) +
    # Scatter points
    geom_point(alpha = 0.5, size = 2) +
    # Reference lines
    geom_vline(xintercept = 0, color = "grey70", linetype = "dotted") +
    geom_hline(yintercept = 0, color = "grey70", linetype = "dotted") +
    # Facet by pressure
    facet_wrap(~PressureLabel) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    coord_fixed(ratio = 1, xlim = c(-50, 50), ylim = c(-50, 50)) +
    labs(
      x = "Error X (px)",
      y = "Error Y (px)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top")
  
  print(p_accuracy)
} else {
  cat("⚠ No gaze accuracy data available for scatter plot.\n")
}
```

```{r accuracy-summary}
# Summary statistics for accuracy scatter plot
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  accuracy_summary <- gaze_accuracy %>%
    group_by(ui_mode, pressure) %>%
    summarise(
      N = n(),
      Mean_Error = round(mean(err_distance, na.rm = TRUE), 2),
      SD_Error = round(sd(err_distance, na.rm = TRUE), 2),
      Median_Error = round(median(err_distance, na.rm = TRUE), 2),
      .groups = "drop"
    )
  
  accuracy_summary %>%
    kable(caption = "Endpoint Error Distance (px) for Gaze Modality") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
} else {
  cat("⚠ No gaze accuracy data available for summary table.\n")
}
```

## The "Midas Touch" Struggle

*Target Re-entries measure how often the cursor drifted out of the target before selection.*

```{r reentry-summary}
# Check if hand modality has any non-zero reentry values
hand_has_reentry_data <- df_iso %>%
  filter(modality == "hand") %>%
  summarise(has_nonzero = any(!is.na(reentries) & reentries > 0)) %>%
  pull(has_nonzero)

if (!hand_has_reentry_data) {
  cat("⚠ **Note:** Hand modality shows zero re-entries because the legacy `target_reentry_count`\n")
  cat("   was only computed for gaze. Future data may compute re-entries from trajectory\n")
  cat("   or LBA timing fields for both modalities.\n\n")
}

reentry_summary <- df_iso %>%
  filter(!is.na(reentries)) %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Mean_Reentries = round(mean(reentries, na.rm = TRUE), 2),
    SD_Reentries = round(sd(reentries, na.rm = TRUE), 2),
    .groups = "drop"
  )

reentry_summary %>%
  kable(caption = "Target Re-entries by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-reentry}
#| fig-cap: "Target Re-entries (Control Stability) by Modality and UI Mode. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower values are better."

# Aggregate to participant-level means
df_reentry_plot <- df_iso %>%
  filter(!is.na(reentries)) %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(reentries_mean = mean(reentries, na.rm = TRUE), .groups = "drop") %>%
  filter(!is.na(reentries_mean))

# Raincloud plot for Re-entries
ggplot(df_reentry_plot, aes(x = ui_mode, y = reentries_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_reentry_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_reentry_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  facet_grid(modality ~ pressure, labeller = labeller(
    modality = function(x) paste("Modality:", str_to_title(x)),
    pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
  )) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Avg Re-entries per Trial",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )
```

-----

# 8. Workload (NASA-TLX)

*Subjective workload scores (lower is better).*

```{r plot-tlx}
#| fig-cap: "NASA-TLX Workload Scores by Modality and UI Mode. Scores range from 0-100, where lower values indicate lower subjective workload. The six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration) are shown separately. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."
# Check if TLX columns exist
tlx_cols <- c("tlx_mental", "tlx_physical", "tlx_temporal", "tlx_performance", "tlx_effort", "tlx_frustration")

if(all(tlx_cols %in% names(df_raw))) {
  # Block-level aggregation (if block_number exists), else participant-level
  df_tlx <- df_raw %>%
    filter(!is.na(pid)) %>%
    {
      if ("block_number" %in% names(.)) {
        group_by(., pid, modality, ui_mode, block_number)
      } else {
        group_by(., pid, modality, ui_mode)
      }
    } %>%
    summarise(across(starts_with("tlx_"), mean, na.rm = TRUE), .groups = "drop") %>%
    pivot_longer(cols = starts_with("tlx_"), names_to = "Scale", values_to = "Score") %>%
    mutate(
      Scale = str_remove(Scale, "tlx_"),
      Scale = str_to_title(Scale),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Summary table
  tlx_summary <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(
      Mean = round(mean(Score, na.rm = TRUE), 1),
      SD = round(sd(Score, na.rm = TRUE), 1),
      .groups = "drop"
    )
  
  tlx_summary %>%
    kable(caption = "NASA-TLX Scores by Condition (block-level where available)") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
  # Visualization (one concise view)
  p1 <- ggplot(df_tlx, aes(x = ui_mode, y = Score, color = ui_mode, group = pid)) +
    geom_line(alpha = 0.25) +
    geom_point(alpha = 0.6, size = 1.8) +
    facet_grid(modality ~ Scale,
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x)),
                 Scale = function(x) x
               )) +
    scale_color_manual(values = custom_palette_2,
                       labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    labs(
      y = "TLX Score (0-100)",
      x = "UI Mode",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 11),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank()
    )
  
  print(p1)
  
} else {
  cat("⚠ TLX Data not found in trial_data.csv\n")
  cat("Expected columns:", paste(tlx_cols, collapse = ", "), "\n")
  cat("Available columns with 'tlx':", 
      paste(grep("tlx", names(df_raw), value = TRUE, ignore.case = TRUE), collapse = ", "), "\n")
}
```

<!-- Consolidated: removed extra TLX overall violin for interim slimness -->
  
```{r plot-tlx-stacked}
#| fig-cap: "NASA-TLX Workload Components (Stacked Bar Chart). Total height represents overall workload, with each colored segment representing one of the six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration). Lower total height indicates lower overall subjective workload."
if(all(tlx_cols %in% names(df_raw)) && exists("df_tlx")) {
  # Stacked bar chart (inspired by Python script)
  df_tlx_stacked <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(Mean_Score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
    mutate(
      Modality = str_to_title(modality),
      UI = str_to_title(ui_mode),
      Condition = paste(Modality, UI, sep = "\n")
    )
  
  # Create stacked bar
  p3 <- ggplot(df_tlx_stacked, aes(x = Condition, y = Mean_Score, fill = Scale)) +
    geom_bar(stat = "identity", position = "stack", alpha = 0.8) +
    scale_fill_manual(values = custom_palette_multi) +
    labs(
      y = "TLX Score (0-100)",
      x = "Condition",
      fill = "TLX Scale"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "right",
      axis.text.x = element_text(angle = 0, hjust = 0.5)
    ) +
    guides(fill = guide_legend(ncol = 1))
  
  print(p3)
}
```

-----

# 9. Learning Curves & Practice Effects

**Research Question:** How does performance change within each condition? Do learning rates differ by condition?

*This section shows learning curves aligned by condition start (accounting for Williams counterbalancing). For block-level trends, see Section 12.*

```{r learning-curves}
# Calculate learning curves aligned by condition (not absolute trial number)
# With Williams counterbalancing, different participants experience conditions at different times
# So we align by "trial within condition" rather than absolute trial number

# For error rates, we need ALL trials (correct + incorrect)
# For movement time, we use only correct trials with valid RTs

# Option 1: Use trial_in_block if available (cleanest approach)
if ("trial_in_block" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      error_rate = 1 - mean(is_correct, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = mean(error_rate, na.rm = TRUE),
      error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      rt_avg = mean(rt_s, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_avg, na.rm = TRUE),
      rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_block", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_block"
  x_label <- "Trial Position in Block"
} else {
  # Option 2: Calculate position within condition by grouping consecutive trials
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = 1 - mean(is_correct, na.rm = TRUE),
      error_se = sd(1 - is_correct, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_s, na.rm = TRUE),
      rt_se = sd(rt_s, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_condition", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_condition"
  x_label <- "Trial Position in Condition"
}

# For throughput, we need to work with df_iso and join trial information
# Create approximate throughput learning by joining trial numbers
if ("trial_number" %in% names(df_raw)) {
  # Join df_iso with trial numbers from original data
  # Ensure pressure types match (df_iso has factor, df_raw has numeric)
  df_raw_for_join <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, trial_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),  # Convert to character for joining
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct()
  
  df_iso_for_join <- df_iso %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    )
  
  df_iso_with_trials <- df_raw_for_join %>%
    left_join(df_iso_for_join, by = c("pid", "modality", "ui_mode", "pressure", "A", "W")) %>%
    filter(!is.na(TP), !is.na(trial_number))
  
  if (nrow(df_iso_with_trials) > 0) {
    df_learning_tp <- df_iso_with_trials %>%
      mutate(
        trial_bin = cut(trial_number, breaks = seq(0, max(trial_number, na.rm = TRUE) + 1, 
                                                   length.out = 11), include.lowest = TRUE),
        trial_bin_num = as.numeric(trial_bin)
      ) %>%
      group_by(trial_bin_num, modality, ui_mode, pressure, pid) %>%
      summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
      group_by(trial_bin_num, modality, ui_mode, pressure) %>%
      summarise(
        TP_mean = mean(TP_avg, na.rm = TRUE),
        TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
        .groups = "drop"
      )
  } else {
    df_learning_tp <- data.frame()
  }
} else {
  df_learning_tp <- data.frame()
}

# Movement time learning curve (aligned by condition position)
if (nrow(df_learning_aligned) > 0) {
  # Check what conditions we have
  learning_summary_table <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      `N Positions` = n(),
      `Mean RT (s)` = round(mean(rt_mean, na.rm = TRUE), 3),
      `Mean Error Rate` = round(mean(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF")
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean RT (s)`, `Mean Error Rate`)
  
  learning_summary_table %>%
    kable(caption = "Learning Curve Data Summary by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-rt}
#| fig-cap: "Learning Curves: Movement Time Within Condition. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI."

if (nrow(df_learning_aligned) > 0) {
  # Create plot with dynamic x variable
  p1 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = rt_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points)
    geom_point(alpha = 0.4, size = 1.5) +
    # Smoothed trend line
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, labeller = labeller(
      pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF"),
      modality = function(x) str_to_title(x)
    )) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    labs(
      title = "Learning Curves: Movement Time Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Movement Time (s)",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p1)
}
```
  
```{r error-summary-learning}
if (nrow(df_learning_aligned) > 0) {
  # Error rate learning curve (aligned by condition position)
  # Check error rate data availability
  error_summary <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      n = n(),
      mean_error = round(mean(error_mean, na.rm = TRUE), 4),
      min_error = round(min(error_mean, na.rm = TRUE), 4),
      max_error = round(max(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
      `N Positions` = n,
      `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01),
      `Min Error Rate` = scales::percent(min_error, accuracy = 0.01),
      `Max Error Rate` = scales::percent(max_error, accuracy = 0.01)
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean Error Rate`, `Min Error Rate`, `Max Error Rate`)
  
  error_summary %>%
    kable(caption = "Error Rate Summary by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-error}
#| fig-cap: "Learning Curves: Error Rate Within Condition. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI."

if (nrow(df_learning_aligned) > 0) {
  # Ensure we have data for both UI modes in each condition
  # If error rates are very low, use a different scale or show raw values
  p2 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = error_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points) - make more visible
    geom_point(alpha = 0.6, size = 2, shape = 16) +
    # Smoothed trend line - only if we have enough data points
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, labeller = labeller(
      pressure = function(x) {
        x_char <- as.character(x)
        ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
      },
      modality = function(x) str_to_title(x)
    )) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
    labs(
      title = "Learning Curves: Error Rate Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Error Rate",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p2)
} else {
  cat("⚠ Insufficient data for learning curve visualization.\n")
}
```

*Note: Data aligned by position within condition to account for Williams counterbalancing. For block-level trends, see Section 12: Block Order & Temporal Effects.*

-----

# 10. Movement Quality Metrics

## Submovement Analysis

**Research Question:** Does adaptive UI reduce movement corrections? How do submovements relate to performance?

*Submovements indicate intermittent control - fewer submovements suggest smoother, more ballistic movements.*

```{r submovement-analysis}
if ("submovement_count" %in% names(df)) {
  df_submov <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov) > 0) {
    # Summary statistics
    submov_summary <- df_submov %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean = round(mean(submovement_count, na.rm = TRUE), 2),
        SD = round(sd(submovement_count, na.rm = TRUE), 2),
        Median = round(median(submovement_count, na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    submov_summary %>%
      kable(caption = "Submovement Count by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  }
}
```

```{r plot-submovement}
#| fig-cap: "Submovement Count (Movement Quality) by Modality and UI Mode. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower indicates smoother, more ballistic movements."

# Prefer recomputed submovement count (computed from trajectory for both modalities)
# Fall back to legacy submovement_count if recomputed is not available
submov_col <- if ("submovement_count_recomputed" %in% names(df)) {
  "submovement_count_recomputed"
} else if ("submovement_count" %in% names(df)) {
  "submovement_count"
} else {
  NULL
}

if (!is.null(submov_col)) {
  df_submov <- df %>%
    filter(!is.na(.data[[submov_col]]), .data[[submov_col]] >= 0)
  
  if (nrow(df_submov) > 0) {
    # Check if hand modality has any non-zero values
    hand_has_data <- df_submov %>%
      filter(modality == "hand") %>%
      summarise(has_nonzero = any(.data[[submov_col]] > 0)) %>%
      pull(has_nonzero)
    
    if (!hand_has_data && submov_col == "submovement_count") {
      cat("⚠ **Note:** Hand modality shows zero submovements because the legacy `submovement_count`\n")
      cat("   was only computed for gaze. Future data will use `submovement_count_recomputed`\n")
      cat("   computed from trajectory for both modalities.\n\n")
    }
    
    # Aggregate to participant-level means for raincloud plot
    df_submov_plot <- df_submov %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(submov_mean = mean(.data[[submov_col]], na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(submov_mean))
    
    # Raincloud plot for Submovement Count
    p1 <- ggplot(df_submov_plot, aes(x = ui_mode, y = submov_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_submov_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_submov_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      facet_grid(modality ~ pressure, labeller = labeller(
        modality = function(x) paste("Modality:", str_to_title(x)),
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Submovement Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

```{r plot-submovement-id}
#| fig-cap: "Submovements vs. Index of Difficulty. How movement corrections scale with task difficulty. Linear regression with 95% confidence intervals."

# Prefer recomputed submovement count (computed from trajectory for both modalities)
# Fall back to legacy submovement_count if recomputed is not available
submov_col <- if ("submovement_count_recomputed" %in% names(df)) {
  "submovement_count_recomputed"
} else if ("submovement_count" %in% names(df)) {
  "submovement_count"
} else {
  NULL
}

if (!is.null(submov_col)) {
  df_submov <- df %>%
    filter(!is.na(.data[[submov_col]]), .data[[submov_col]] >= 0)
  
  if (nrow(df_submov) > 0) {
    # Check if hand modality has any non-zero values
    hand_has_data <- df_submov %>%
      filter(modality == "hand") %>%
      summarise(has_nonzero = any(.data[[submov_col]] > 0)) %>%
      pull(has_nonzero)
    
    if (!hand_has_data && submov_col == "submovement_count") {
      cat("⚠ **Note:** Hand modality shows zero submovements because the legacy `submovement_count`\n")
      cat("   was only computed for gaze. Future data will use `submovement_count_recomputed`\n")
      cat("   computed from trajectory for both modalities.\n\n")
    }
    
    # Submovements vs. Difficulty
    # Check if IDe exists, otherwise use ID
    if ("IDe" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(IDe)) %>%
        mutate(difficulty = IDe)
    } else if ("ID" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(ID)) %>%
        mutate(difficulty = ID)
    } else {
      df_submov_id <- data.frame()
    }
    
    if (nrow(df_submov_id) > 0) {
      p2 <- ggplot(df_submov_id, aes(x = difficulty, y = .data[[submov_col]], color = ui_mode)) +
        geom_point(alpha = 0.3, size = 1) +
        geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
        facet_grid(modality ~ pressure, labeller = labeller(
          pressure = function(x) paste("Pressure:", x),
          modality = function(x) str_to_title(x)
        )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        labs(
          title = "Submovements vs. Index of Difficulty",
          subtitle = "How movement corrections scale with task difficulty",
          x = "Index of Difficulty (bits)",
          y = "Submovement Count",
          color = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(legend.position = "top", strip.text = element_text(face = "bold"))
      
      print(p2)
    }
  } else {
    cat("⚠ No valid submovement data available.\n")
  }
} else {
  cat("⚠ Neither submovement_count nor submovement_count_recomputed column found in dataset.\n")
}
```

## Verification Time Analysis

**Research Question:** How much time is spent "stopping" vs. "moving"? Does adaptive UI reduce verification time?

*Verification time represents the "precise stopping" phase, separate from the ballistic movement phase.*

```{r verification-time}
if ("verification_time_ms" %in% names(df)) {
  df_verify <- df %>%
    filter(!is.na(verification_time_ms), verification_time_ms > 0, verification_time_ms <= 6000)
  
  if (nrow(df_verify) > 0) {
    df_verify <- df_verify %>%
      mutate(
        verification_s = verification_time_ms / 1000,
        movement_s = rt_s - verification_s,
        verify_ratio = verification_time_ms / rt_ms,
        # Ensure PressureLabel exists
        PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF")
      )
    
    # Summary statistics
    verify_summary <- df_verify %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean_Verify = round(mean(verification_s, na.rm = TRUE), 3),
        Mean_MT = round(mean(rt_s, na.rm = TRUE), 3),
        Mean_Ratio = round(mean(verify_ratio, na.rm = TRUE), 3),
        .groups = "drop"
      )
    
    verify_summary %>%
      kable(caption = "Verification Time by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Aggregate to participant-level means for raincloud plot
    df_verify_plot <- df_verify %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(verification_s_mean = mean(verification_s, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(verification_s_mean))
    
    # Raincloud plot for Verification Time
    p1 <- ggplot(df_verify_plot, aes(x = ui_mode, y = verification_s_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_verify_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_verify_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      facet_grid(modality ~ pressure, labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Verification Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
    
    # Verification ratio (what proportion of total time is verification) - raincloud style
    df_verify_ratio_plot <- df_verify %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(verify_ratio_mean = mean(verify_ratio, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(verify_ratio_mean))
    
    p2 <- ggplot(df_verify_ratio_plot, aes(x = ui_mode, y = verify_ratio_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_verify_ratio_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_verify_ratio_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      facet_grid(modality ~ pressure, labeller = labeller(
        modality = function(x) paste("Modality:", str_to_title(x)),
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      scale_y_continuous(labels = scales::percent) +
      labs(
        x = "UI Mode",
        y = "Verification Ratio",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p2)
  } else {
    cat("⚠ No valid verification time data available.\n")
  }
} else {
  cat("⚠ verification_time_ms column not found in dataset.\n")
}
```

-----

# 11. Error Patterns & Types

**Research Question:** What types of errors occur? Do error patterns differ by condition?

```{r error-types}
if ("err_type" %in% names(df_raw)) {
  df_error_types <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    filter(!is.na(err_type), err_type != "") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      err_type = factor(err_type, levels = c("miss", "timeout", "slip"))
    )
  
  if (nrow(df_error_types) > 0) {
    # Summary table
    error_type_summary <- df_error_types %>%
      group_by(modality, ui_mode, pressure, err_type) %>%
      summarise(Count = n(), .groups = "drop") %>%
      group_by(modality, ui_mode, pressure) %>%
      mutate(
        Total = sum(Count),
        Percentage = round(100 * Count / Total, 1)
      ) %>%
      ungroup()
    
    error_type_summary %>%
      kable(caption = "Error Type Distribution by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  }
}
```

<!-- Consolidated: error type plots removed for interim slimness -->

<!-- Consolidated: error type proportional plot removed for interim slimness -->

-----

# 12. Block Order & Temporal Effects

**Research Question:** Are there order effects? Does performance improve or degrade over blocks?

```{r block-effects}
# Performance by block number
# Note: TP is only in df_iso, so we'll use movement time and error rate
# Error rates need ALL trials, movement time uses only correct trials

# Error rates from all trials
df_blocks_errors <- df_all_trials %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    error_rate = 1 - mean(is_correct, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    error_mean = mean(error_rate, na.rm = TRUE),
    error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Movement time from correct trials only
df_blocks_rt <- df %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    rt_avg = mean(rt_s, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    rt_mean = mean(rt_avg, na.rm = TRUE),
    rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Combine for convenience
df_blocks <- df_blocks_rt %>%
  left_join(df_blocks_errors, by = c("block_number", "modality", "ui_mode", "pressure"))

# Try to get throughput by block from df_iso
# Join df_iso with block information
if ("block_number" %in% names(df_raw)) {
  df_blocks_tp <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, block_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct() %>%
    left_join(
      df_iso %>% mutate(
        pressure = as.character(pressure),
        modality = as.character(modality),
        ui_mode = as.character(ui_mode),
        pid = as.character(pid)
      ),
      by = c("pid", "modality", "ui_mode", "pressure", "A", "W")
    ) %>%
    filter(!is.na(TP), !is.na(block_number)) %>%
    group_by(block_number, modality, ui_mode, pressure, pid) %>%
    summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
    group_by(block_number, modality, ui_mode, pressure) %>%
    summarise(
      TP_mean = mean(TP_avg, na.rm = TRUE),
      TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
} else {
  df_blocks_tp <- data.frame()
}
```

<!-- Consolidated: block-level TP plot removed for interim slimness -->

```{r plot-blocks-rt}
#| fig-cap: "Performance Across Blocks: Movement Time. Movement time by block number. Lower is better. Shaded regions show ±1 SE."

# Movement time by block
p2 <- ggplot(df_blocks, aes(x = block_number, y = rt_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = rt_mean - rt_se, ymax = rt_mean + rt_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  labs(
    title = "Performance Across Blocks: Movement Time",
    subtitle = "Movement time by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Movement Time (s)",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p2)

# Error rate by block
# Check what conditions we have for blocks
block_summary_table <- df_blocks %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    n_blocks = n(),
    mean_error = round(mean(error_mean, na.rm = TRUE), 4),
    .groups = "drop"
  ) %>%
  mutate(
    Modality = str_to_title(modality),
    `UI Mode` = str_to_title(ui_mode),
    Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
    `N Blocks` = n_blocks,
    `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01)
  ) %>%
  select(Modality, `UI Mode`, Pressure, `N Blocks`, `Mean Error Rate`)

block_summary_table %>%
  kable(caption = "Block-Level Data Summary by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-blocks-error}
#| fig-cap: "Performance Across Blocks: Error Rate. Error rate by block number. Lower is better. Shaded regions show ±1 SE."

p3 <- ggplot(df_blocks, aes(x = block_number, y = error_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = error_mean - error_se, ymax = error_mean + error_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
  labs(
    title = "Performance Across Blocks: Error Rate",
    subtitle = "Error rate by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Error Rate",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p3)
```

-----

# 13. Spatial Patterns & Heatmaps

**Research Question:** Are there spatial biases in performance? Do some screen regions show better/worse performance?

## Performance by Target Position

```{r spatial-heatmap}
# Create spatial performance heatmap
# Error rates need ALL trials, movement time uses only correct trials
if ("target_center_x" %in% names(df_all_trials) && "target_center_y" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_spatial_errors <- df_all_trials %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_error = 1 - mean(is_correct, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Movement time from correct trials only
  df_spatial_rt <- df %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_rt = mean(rt_s, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Combine
  df_spatial <- df_spatial_rt %>%
    left_join(df_spatial_errors, by = c("x_bin_num", "y_bin_num", "modality", "ui_mode")) %>%
    mutate(n_trials = pmax(n_trials.x, n_trials.y, na.rm = TRUE)) %>%
    select(-n_trials.x, -n_trials.y)
  
  if (nrow(df_spatial) > 0) {
    # Movement time heatmap
    p1 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_rt)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, labeller = labeller(
        modality = function(x) str_to_title(x),
        ui_mode = function(x) str_to_title(x)
      )) +
      scale_fill_viridis_c(name = "MT (s)", option = "plasma", direction = -1) +
      labs(
        title = "Spatial Performance Heatmap: Movement Time",
        subtitle = "Darker colors indicate faster movement times. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p1)
    
    # Error rate heatmap
    p2 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_error)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, labeller = labeller(
        modality = function(x) str_to_title(x),
        ui_mode = function(x) str_to_title(x)
      )) +
      scale_fill_viridis_c(name = "Error\nRate", option = "inferno", direction = 1) +
      labs(
        title = "Spatial Performance Heatmap: Error Rate",
        subtitle = "Darker colors indicate higher error rates. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p2)
  } else {
    cat("⚠ Insufficient spatial data for heatmap visualization.\n")
  }
} else {
  cat("⚠ Target position columns (target_center_x, target_center_y) not found.\n")
}
```

## Error Density Heatmap

*Where do endpoint errors occur? Are there systematic spatial biases?*

```{r error-density-heatmap}
# Error density heatmap for gaze modality
# Recalculate error data to ensure we have it
if ("endpoint_x" %in% names(df) && "target_center_x" %in% names(df)) {
  df_error_spatial <- df %>%
    filter(
      !is.na(endpoint_x), !is.na(endpoint_y),
      !is.na(target_center_x), !is.na(target_center_y),
      correct == TRUE | correct == "true" | correct == 1
    ) %>%
    mutate(
      err_x = as.numeric(endpoint_x) - as.numeric(target_center_x),
      err_y = as.numeric(endpoint_y) - as.numeric(target_center_y)
    )
  
  # Focus on gaze modality
  df_error_gaze <- df_error_spatial %>%
    filter(str_to_lower(modality) == "gaze") %>%
    filter(!is.na(err_x), !is.na(err_y), is.finite(err_x), is.finite(err_y))
} else {
  df_error_gaze <- data.frame()
}

if (nrow(df_error_gaze) > 0) {
  # Check actual data range
  err_x_range <- range(df_error_gaze$err_x, na.rm = TRUE)
  err_y_range <- range(df_error_gaze$err_y, na.rm = TRUE)
  
  # Use actual data range, but cap extreme outliers
  x_limit <- min(100, max(abs(err_x_range), na.rm = TRUE) * 1.2)
  y_limit <- min(100, max(abs(err_y_range), na.rm = TRUE) * 1.2)
  
  # Filter to reasonable range
  df_error_gaze <- df_error_gaze %>%
    filter(
      abs(err_x) <= x_limit,
      abs(err_y) <= y_limit
    )
  
  if (nrow(df_error_gaze) > 0) {
    # 2D density heatmap
    p1 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
      stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
      geom_vline(xintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_fill_viridis_c(name = "Density", option = "plasma") +
      coord_fixed(ratio = 1) +
      labs(
        title = "Endpoint Error Density: Gaze Modality",
        subtitle = paste("Heatmap shows where endpoints cluster relative to target center (0,0).",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p1)
    
    # Hexbin plot - COMMENTED OUT due to scaling issues
    # # Hexbin plot - use actual data range for limits
    # # Calculate number of bins based on data
    # n_bins <- min(20, max(5, round(sqrt(nrow(df_error_gaze)) / 2)))
    # 
    # # Get actual data limits for setting axis ranges
    # x_min <- min(df_error_gaze$err_x, na.rm = TRUE)
    # x_max <- max(df_error_gaze$err_x, na.rm = TRUE)
    # y_min <- min(df_error_gaze$err_y, na.rm = TRUE)
    # y_max <- max(df_error_gaze$err_y, na.rm = TRUE)
    # 
    # # Add some padding
    # x_pad <- (x_max - x_min) * 0.1
    # y_pad <- (y_max - y_min) * 0.1
    # 
    # p2 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
    #   geom_hex(bins = n_bins, alpha = 0.8) +
    #   geom_vline(xintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   geom_hline(yintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
    #   scale_fill_viridis_c(name = "Count", option = "plasma", na.value = "white") +
    #   coord_fixed(ratio = 1, xlim = c(x_min - x_pad, x_max + x_pad), 
    #               ylim = c(y_min - y_pad, y_max + y_pad)) +
    #   labs(
    #     title = "Endpoint Error Distribution: Gaze Modality (Hexbin)",
    #     subtitle = paste("Hexagonal binning shows error density. Red lines indicate target center.",
    #                     "N =", nrow(df_error_gaze), "trials. Data range: X [", 
    #                     round(x_min, 1), ",", round(x_max, 1), "], Y [",
    #                     round(y_min, 1), ",", round(y_max, 1), "] px."),
    #     x = "Error X (px)",
    #     y = "Error Y (px)"
    #   ) +
    #   theme_minimal(base_size = 14) +
    #   theme(
    #     legend.position = "right",
    #     strip.text = element_text(face = "bold")
    #   )
    # 
    # print(p2)
    
    # Always show scatter plot as well for comparison
    p3 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y, color = ui_mode)) +
      geom_point(alpha = 0.5, size = 1.5) +
      geom_vline(xintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      coord_fixed(ratio = 1, xlim = c(-x_limit, x_limit), ylim = c(-y_limit, y_limit)) +
      labs(
        title = "Endpoint Error Scatter: Gaze Modality",
        subtitle = paste("Individual trial endpoints. Red lines indicate target center.",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p3)
  } else {
    cat("⚠ No error data available after filtering.\n")
  }
} else {
  cat("⚠ Insufficient error spatial data for heatmap visualization.\n")
}
```

-----

# 14. Adaptive UI Mechanism Analysis

## Width Scaling (Target Size Adaptation)

**Research Question:** Does the adaptive UI dynamically change target sizes? How does width scaling relate to performance?

*The adaptive UI may scale target widths based on performance. This section examines whether and how target sizes are adjusted.*

```{r width-scaling-analysis}
# Check if width scaling fields exist
if (all(c("nominal_width_px", "displayed_width_px", "width_scale_factor") %in% names(df_raw))) {
  df_width <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(nominal_width_px),
      !is.na(displayed_width_px)
    ) %>%
    mutate(
      # Calculate scale factor if not present
      width_scale_factor = ifelse(
        is.na(width_scale_factor) | width_scale_factor == 0,
        displayed_width_px / nominal_width_px,
        width_scale_factor
      ),
      width_difference = displayed_width_px - nominal_width_px,
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(width_scale_factor),
      is.finite(width_scale_factor),
      width_scale_factor > 0,
      width_scale_factor < 5  # Filter extreme outliers
    )
  
  if (nrow(df_width) > 0) {
    # Check if any scaling actually occurred
    has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
    
    if (!has_scaling) {
      cat("**Note:** No target width scaling was observed in this dataset.\n")
      cat("All `width_scale_factor` values are 1.0 (no scaling applied).\n\n")
      cat("This indicates that the adaptive policy did not trigger during data collection.\n")
      cat("Possible reasons:\n")
      cat("- Hysteresis gate threshold not met (requires N consecutive slow/error trials)\n")
      cat("- Performance thresholds (RT p75, error burst) not exceeded\n")
      cat("- Adaptive policy not properly configured or enabled\n")
      cat("- Participants performed well enough that adaptation was not needed\n\n")
      
      # Still show the summary table for completeness
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = "Target Width Scaling by Condition (No Scaling Observed)") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    } else {
      # Summary statistics (when scaling did occur)
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = "Target Width Scaling by Condition") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    }
  } else {
    cat("⚠ No valid width scaling data available.\n")
  }
} else {
  cat("⚠ Width scaling columns not found in dataset.\n")
}
```

```{r plot-width-scaling}
#| fig-cap: "Target Width Scale Factor by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Scale factor = 1.0 means no scaling (nominal size). Values > 1.0 indicate enlarged targets."

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Aggregate to participant-level means for raincloud plot
  df_width_plot <- df_width %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    summarise(width_scale_factor_mean = mean(width_scale_factor, na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(width_scale_factor_mean))
  
  # Show plot even if no scaling occurred - it's still informative
  # Raincloud plot for width scale factor
  p1 <- ggplot(df_width_plot, aes(x = ui_mode, y = width_scale_factor_mean, fill = ui_mode, color = ui_mode)) +
    geom_hline(yintercept = 1.0, linetype = "dashed", color = "red", linewidth = 0.8) +
    # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
    {
      if (has_ggdist) {
        list(
          ggdist::stat_halfeye(
            data = df_width_plot %>% filter(ui_mode == "static"),
            aes(fill = ui_mode),
            side = "left",
            alpha = 0.4,
            width = 0.35,
            .width = 0,
            justification = 1.3,
            point_colour = NA
          ),
          ggdist::stat_halfeye(
            data = df_width_plot %>% filter(ui_mode == "adaptive"),
            aes(fill = ui_mode),
            side = "right",
            alpha = 0.4,
            width = 0.35,
            .width = 0,
            justification = -0.3,
            point_colour = NA
          )
        )
      } else {
        geom_violin(
          alpha = 0.4,
          trim = FALSE,
          scale = "width",
          width = 0.35,
          position = position_dodge(width = 0),
          color = NA
        )
      }
    } +
    # Boxplots inside violins (light gray for visibility)
    geom_boxplot(
      width = 0.15,
      alpha = 0.9,
      outlier.shape = NA,
      position = position_dodge(width = 0),
      fill = "grey90",
      color = "grey70",
      linewidth = 0.7,
      show.legend = FALSE
    ) +
    # Individual participant points (in columns, no jitter)
    geom_point(
      alpha = 0.5,
      size = 1.5,
      position = position_dodge(width = 0),
      show.legend = FALSE
    ) +
    # Connecting lines (between paired conditions)
    geom_line(
      aes(group = pid),
      alpha = 0.3,
      linewidth = 0.4,
      color = "grey60",
      position = position_dodge(width = 0),
      show.legend = FALSE
    ) +
    facet_grid(modality ~ pressure, labeller = labeller(
      modality = function(x) paste("Modality:", str_to_title(x)),
      pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
    )) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0.5, 1.5), breaks = seq(0.5, 1.5, 0.25)) +
    labs(
      x = "UI Mode",
      y = "Width Scale Factor",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 12),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
    )
  
  print(p1)
  
  if (!has_scaling) {
    cat("\n**Note:** All width scale factors are 1.0 (no scaling applied).\n")
    cat("This indicates the adaptive policy did not trigger during data collection.\n\n")
  }
}
```

```{r plot-width-scaling-over-time}
#| fig-cap: "Width Scaling Over Time (by Trial Number). Shows how target scaling changes throughout the experiment. LOESS smoothing with 95% CI."

if (exists("df_width") && nrow(df_width) > 0 && "trial_number" %in% names(df_width)) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Width scaling over time - show even if no scaling occurred
  df_width_time <- df_width %>%
    filter(!is.na(trial_number), trial_number > 0, trial_number <= 500)
  
  if (nrow(df_width_time) > 0) {
    p2 <- ggplot(df_width_time, aes(x = trial_number, y = width_scale_factor, color = ui_mode)) +
      geom_hline(yintercept = 1.0, linetype = "dashed", color = "grey50", linewidth = 0.5) +
      geom_point(alpha = 0.2, size = 1) +
      {if (has_scaling) geom_smooth(method = "loess", span = 0.3, se = TRUE, alpha = 0.2, linewidth = 1.2) else NULL} +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_y_continuous(limits = c(0.5, 1.5), breaks = seq(0.5, 1.5, 0.25)) +
      labs(
        x = "Trial Number",
        y = "Width Scale Factor",
        color = "UI Mode",
        subtitle = if (!has_scaling) {
          "No scaling observed (all values = 1.0). Adaptive policy did not trigger."
        } else {
          NULL
        }
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        plot.subtitle = element_text(face = "italic", color = "gray40", size = 11, hjust = 0.5)
      )
    
    print(p2)
    
    if (!has_scaling) {
      cat("\n**Note:** All width scale factors remain at 1.0 throughout the experiment.\n")
      cat("The adaptive policy did not trigger any target size adjustments.\n\n")
    }
  }
}
```

```{r plot-width-vs-performance}
#| fig-cap: "Width Scale Factor vs. Movement Time. Does target scaling improve performance? Linear regression with 95% CI."

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Join with performance data - show plot even if no scaling occurred
  df_width_perf <- df_width %>%
    filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
    mutate(rt_s = rt_ms / 1000)
  
  if (nrow(df_width_perf) > 0) {
    p3 <- ggplot(df_width_perf, aes(x = width_scale_factor, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.3, size = 1.5) +
      {if (has_scaling) geom_smooth(method = "lm", se = TRUE, alpha = 0.2, linewidth = 1.2) else NULL} +
      geom_vline(xintercept = 1.0, linetype = "dashed", color = "grey50", linewidth = 0.5) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_continuous(limits = c(0.5, 1.5), breaks = seq(0.5, 1.5, 0.25)) +
      labs(
        x = "Width Scale Factor",
        y = "Movement Time (s)",
        color = "UI Mode",
        subtitle = if (!has_scaling) {
          "No scaling observed (all values = 1.0). Cannot assess performance relationship."
        } else {
          NULL
        }
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        plot.subtitle = element_text(face = "italic", color = "gray40", size = 11, hjust = 0.5)
      )
    
    print(p3)
    
    if (!has_scaling) {
      cat("\n**Note:** All width scale factors are 1.0, so no relationship with performance can be assessed.\n")
      cat("The plot shows all points at x=1.0, indicating no scaling occurred.\n\n")
    }
  }
}
```

## Alignment Gate Metrics

**Research Question:** If alignment gates are used, how do they affect performance? How often are false triggers detected?

*Alignment gates may be used to ensure proper cursor alignment before selection. This section examines their usage and effectiveness.*

```{r alignment-gate-analysis}
# Check if alignment gate fields exist
if (all(c("alignment_gate_enabled", "alignment_gate_false_triggers") %in% names(df_raw))) {
  df_gate <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      alignment_gate_enabled == TRUE | alignment_gate_enabled == "true"
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    )
  
  if (nrow(df_gate) > 0) {
    # Summary statistics
    gate_summary <- df_gate %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_False_Triggers = round(mean(alignment_gate_false_triggers, na.rm = TRUE), 2),
        SD_False_Triggers = round(sd(alignment_gate_false_triggers, na.rm = TRUE), 2),
        Mean_Recovery_Time = round(mean(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        SD_Recovery_Time = round(sd(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        Mean_Mean_Recovery_Time = round(mean(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        SD_Mean_Recovery_Time = round(sd(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    gate_summary %>%
      kable(caption = "Alignment Gate Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else {
    # Check if columns exist but feature was disabled
    if (all(c("alignment_gate_enabled", "alignment_gate_false_triggers") %in% names(df_raw))) {
      enabled_count <- sum(df_raw$alignment_gate_enabled == TRUE | df_raw$alignment_gate_enabled == "true", na.rm = TRUE)
      disabled_count <- sum(df_raw$alignment_gate_enabled == FALSE | df_raw$alignment_gate_enabled == "false", na.rm = TRUE)
      cat("⚠ **Alignment gate feature was not enabled during data collection.**\n\n")
      cat("**Status:**\n")
      cat("- Alignment gate columns exist in dataset (columns: `alignment_gate_enabled`, `alignment_gate_false_triggers`, `alignment_gate_recovery_time_ms`, `alignment_gate_mean_recovery_time_ms`)\n")
      cat("- Trials with `alignment_gate_enabled = TRUE`: ", enabled_count, "\n")
      cat("- Trials with `alignment_gate_enabled = FALSE`: ", disabled_count, "\n")
      cat("- Trials with null values: ", sum(is.na(df_raw$alignment_gate_enabled)), "\n\n")
      cat("**Explanation:** Alignment gates are an experimental feature (P1) that is disabled by default.\n")
      cat("The feature requires hand input and hover-in-target for ≥80ms before selection.\n")
      cat("To enable alignment gates, set `experimental.alignmentGate = true` in `app/src/config.ts`.\n")
    } else {
      cat("⚠ Alignment gate columns not found in dataset.\n")
    }
  }
} else {
  cat("⚠ Alignment gate columns not found in dataset.\n")
}
```

```{r plot-alignment-gate}
#| fig-cap: "Alignment Gate False Triggers by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - false triggers
  if (sum(!is.na(df_gate$alignment_gate_false_triggers)) > 0) {
    # Aggregate to participant-level means
    df_gate_plot <- df_gate %>%
      filter(!is.na(alignment_gate_false_triggers)) %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(false_triggers_mean = mean(alignment_gate_false_triggers, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(false_triggers_mean))
    
    p1 <- ggplot(df_gate_plot, aes(x = ui_mode, y = false_triggers_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_gate_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_gate_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      facet_grid(modality ~ pressure, labeller = labeller(
        modality = function(x) paste("Modality:", str_to_title(x)),
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "False Trigger Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

```{r plot-alignment-recovery}
#| fig-cap: "Alignment Gate Recovery Time by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - recovery time
  if (sum(!is.na(df_gate$alignment_gate_recovery_time_ms)) > 0) {
    df_gate_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_recovery_time_ms), alignment_gate_recovery_time_ms > 0)
    
    if (nrow(df_gate_recovery) > 0) {
      # Aggregate to participant-level means
      df_gate_recovery_plot <- df_gate_recovery %>%
        group_by(pid, modality, ui_mode, pressure) %>%
        summarise(recovery_time_mean = mean(alignment_gate_recovery_time_ms, na.rm = TRUE), .groups = "drop") %>%
        filter(!is.na(recovery_time_mean))
      
      p2 <- ggplot(df_gate_recovery_plot, 
                   aes(x = ui_mode, y = recovery_time_mean, fill = ui_mode, color = ui_mode)) +
        # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
        {
          if (has_ggdist) {
            list(
              ggdist::stat_halfeye(
                data = df_gate_recovery_plot %>% filter(ui_mode == "static"),
                aes(fill = ui_mode),
                side = "left",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = 1.3,
                point_colour = NA
              ),
              ggdist::stat_halfeye(
                data = df_gate_recovery_plot %>% filter(ui_mode == "adaptive"),
                aes(fill = ui_mode),
                side = "right",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = -0.3,
                point_colour = NA
              )
            )
          } else {
            geom_violin(
              alpha = 0.4,
              trim = FALSE,
              scale = "width",
              width = 0.35,
              position = position_dodge(width = 0),
              color = NA
            )
          }
        } +
        # Boxplots inside violins (light gray for visibility)
        geom_boxplot(
          width = 0.15,
          alpha = 0.9,
          outlier.shape = NA,
          position = position_dodge(width = 0),
          fill = "grey90",
          color = "grey70",
          linewidth = 0.7,
          show.legend = FALSE
        ) +
        # Individual participant points (in columns, no jitter)
        geom_point(
          alpha = 0.5,
          size = 1.5,
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Connecting lines (between paired conditions)
        geom_line(
          aes(group = pid),
          alpha = 0.3,
          linewidth = 0.4,
          color = "grey60",
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        facet_grid(modality ~ pressure, labeller = labeller(
          modality = function(x) paste("Modality:", str_to_title(x)),
          pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
        )) +
        scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 13) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
        )
      
      print(p2)
    }
  }
}
```

```{r plot-alignment-mean-recovery}
#| fig-cap: "Alignment Gate Mean Recovery Time by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - mean recovery time (averaged across all recoveries in trial)
  if (sum(!is.na(df_gate$alignment_gate_mean_recovery_time_ms)) > 0) {
    df_gate_mean_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_mean_recovery_time_ms), alignment_gate_mean_recovery_time_ms > 0)
    
    if (nrow(df_gate_mean_recovery) > 0) {
      # Aggregate to participant-level means
      df_gate_mean_recovery_plot <- df_gate_mean_recovery %>%
        group_by(pid, modality, ui_mode, pressure) %>%
        summarise(mean_recovery_time_mean = mean(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), .groups = "drop") %>%
        filter(!is.na(mean_recovery_time_mean))
      
      p3 <- ggplot(df_gate_mean_recovery_plot, 
                   aes(x = ui_mode, y = mean_recovery_time_mean, fill = ui_mode, color = ui_mode)) +
        # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
        {
          if (has_ggdist) {
            list(
              ggdist::stat_halfeye(
                data = df_gate_mean_recovery_plot %>% filter(ui_mode == "static"),
                aes(fill = ui_mode),
                side = "left",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = 1.3,
                point_colour = NA
              ),
              ggdist::stat_halfeye(
                data = df_gate_mean_recovery_plot %>% filter(ui_mode == "adaptive"),
                aes(fill = ui_mode),
                side = "right",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = -0.3,
                point_colour = NA
              )
            )
          } else {
            geom_violin(
              alpha = 0.4,
              trim = FALSE,
              scale = "width",
              width = 0.35,
              position = position_dodge(width = 0),
              color = NA
            )
          }
        } +
        # Boxplots inside violins (light gray for visibility)
        geom_boxplot(
          width = 0.15,
          alpha = 0.9,
          outlier.shape = NA,
          position = position_dodge(width = 0),
          fill = "grey90",
          color = "grey70",
          linewidth = 0.7,
          show.legend = FALSE
        ) +
        # Individual participant points (in columns, no jitter)
        geom_point(
          alpha = 0.5,
          size = 1.5,
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Connecting lines (between paired conditions)
        geom_line(
          aes(group = pid),
          alpha = 0.3,
          linewidth = 0.4,
          color = "grey60",
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        facet_grid(modality ~ pressure, labeller = labeller(
          modality = function(x) paste("Modality:", str_to_title(x)),
          pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
        )) +
        scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Mean Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 13) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
        )
      
      print(p3)
    }
  }
}
```

## Task Type Analysis

**Research Question:** Are there different task types (point vs. drag)? How does performance differ across task types?

*If the experiment includes different task types, this section examines performance differences.*

```{r task-type-analysis}
# Check if task_type field exists
if ("task_type" %in% names(df_raw)) {
  df_task <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(task_type),
      task_type != ""
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure),
      task_type = factor(task_type)
    )
  
  if (nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
    # Summary statistics
    task_summary <- df_task %>%
      group_by(task_type, modality, ui_mode) %>%
      summarise(
        N_Trials = n(),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        SD_RT = round(sd(rt_ms, na.rm = TRUE), 1),
        Error_Rate = round(100 * mean(is.na(correct) | correct == FALSE | correct == "false", na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    task_summary %>%
      kable(caption = "Performance by Task Type") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else if (nrow(df_task) > 0) {
    cat("⚠ Only one task type found:", unique(df_task$task_type), "\n")
  } else {
    cat("⚠ No valid task type data available.\n")
  }
} else {
  cat("⚠ task_type column not found in dataset.\n")
}
```

```{r plot-task-type-rt}
#| fig-cap: "Movement Time by Task Type. Raincloud plot: half-violins with boxplots inside, individual points. Comparison of performance across different task types (if multiple exist). Lower is better."

if (exists("df_task") && nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
  # Filter for valid RT and aggregate to participant-level
  df_task_rt_plot <- df_task %>%
    filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
    mutate(rt_s = rt_ms / 1000) %>%
    group_by(pid, modality, task_type, ui_mode) %>%
    summarise(rt_s_mean = mean(rt_s, na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(rt_s_mean))
  
  if (nrow(df_task_rt_plot) > 0) {
    p1 <- ggplot(df_task_rt_plot, aes(x = task_type, y = rt_s_mean, fill = ui_mode, color = ui_mode)) +
      # Use regular violins with proper dodging for side-by-side comparison
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0.9),
        color = NA
      ) +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0.9),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0.9),
        show.legend = FALSE
      ) +
      facet_wrap(~modality, labeller = labeller(
        modality = function(x) paste("Modality:", str_to_title(x))
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Task Type",
        y = "Movement Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

```{r drag-distance-analysis}
# Compute path length from trajectory and derive efficiency metrics
# Note: For pointing tasks, path length is the actual cursor travel distance (not straight-line A)
# This analysis requires trajectory data - early participants may not have it

library(jsonlite)
library(purrr)

# Helper function to compute path length from trajectory JSON
path_length <- function(traj_json) {
  if (is.na(traj_json) || traj_json == "" || traj_json == "[]" || traj_json == "null") {
    return(NA_real_)
  }
  pts <- tryCatch(fromJSON(traj_json), error = function(e) NULL)
  if (is.null(pts) || length(pts) == 0 || (is.data.frame(pts) && nrow(pts) < 2)) {
    return(NA_real_)
  }
  # Handle both list and data.frame formats
  if (is.data.frame(pts)) {
    dx <- diff(pts$x)
    dy <- diff(pts$y)
  } else if (is.list(pts) && length(pts) > 0 && "x" %in% names(pts[[1]])) {
    x_vals <- sapply(pts, function(p) p$x)
    y_vals <- sapply(pts, function(p) p$y)
    dx <- diff(x_vals)
    dy <- diff(y_vals)
  } else {
    return(NA_real_)
  }
  sum(sqrt(dx^2 + dy^2), na.rm = TRUE)
}

# Prepare data with computed path length and derived metrics
if ("trajectory" %in% names(df_raw) && "A" %in% names(df_raw)) {
  df_drag <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      correct == TRUE | correct == "true" | correct == 1,  # Only successful trials
      !is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000,
      !is.na(A), A > 0
    ) %>%
    mutate(
      rt_s = rt_ms / 1000,
      # Compute path length from trajectory
      path_length_computed = map_dbl(trajectory, path_length),
      # Use existing drag_distance if numeric and valid, otherwise use computed
      # Convert drag_distance to numeric first to handle character/string values
      drag_distance_raw = if ("drag_distance" %in% names(.)) {
        suppressWarnings(as.numeric(drag_distance))
      } else {
        NA_real_
      },
      # Prefer computed path length, fall back to drag_distance if valid
      drag_distance = ifelse(
        !is.na(path_length_computed) & path_length_computed > 0,
        path_length_computed,
        ifelse(!is.na(drag_distance_raw) & drag_distance_raw > 0, drag_distance_raw, path_length_computed)
      ),
      # Derived metrics
      ratio = drag_distance / A,  # Path ratio (≥1, higher = less efficient)
      eff = A / drag_distance,    # Path efficiency (0-1], higher = more efficient
      excess = drag_distance - A, # Excess distance (px, 0 = straight)
      speed = drag_distance / rt_s, # Effective speed (px/s)
      # Flag outliers
      bad_traj = ratio < 1 | ratio > 5 | is.na(ratio),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(drag_distance),
      drag_distance > 0,
      !bad_traj  # Exclude invalid trajectories
    )
  
  if (nrow(df_drag) > 0) {
    # Summary statistics with derived metrics
    drag_summary <- df_drag %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_Path_Length = round(mean(drag_distance, na.rm = TRUE), 1),
        Mean_Amplitude = round(mean(A, na.rm = TRUE), 1),
        Mean_Ratio = round(mean(ratio, na.rm = TRUE), 2),
        Mean_Efficiency = round(mean(eff, na.rm = TRUE), 3),
        Mean_Excess = round(mean(excess, na.rm = TRUE), 1),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    drag_summary %>%
      kable(caption = "Path Length and Efficiency Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else {
    cat("⚠ No valid trajectory data available for path length computation.\n")
    cat("Note: Path length analysis requires trajectory data. Early participants may not have trajectory logs.\n")
    cat("This analysis will be limited to participants with trajectory data.\n")
  }
} else {
  cat("⚠ Required columns (trajectory, A) not found for path length analysis.\n")
  cat("Path length metrics require trajectory data to compute actual cursor travel distance.\n")
}
```

```{r plot-path-length-hexbin}
#| fig-cap: "Path Length vs. Movement Time (Log-Log Scale). 2D density plot showing the relationship between actual cursor path length and movement time. GAM smooth captures nonlinearity. Log scales handle right-skewed distributions and heteroscedasticity."

if (exists("df_drag") && nrow(df_drag) > 0) {
  # Try to load hexbin, fall back to density2d if not available
  has_hexbin <- requireNamespace("hexbin", quietly = TRUE)
  
  df_plot <- df_drag %>%
    filter(!is.na(drag_distance), drag_distance > 0, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    if (has_hexbin) {
      library(hexbin)
      # Note: geom_hex creates hexagons in data space, which may appear slightly stretched
      # on log scales. This is expected behavior. For better control, we use a single bins parameter.
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_hex(bins = 35, alpha = 0.7) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma", trans = "log10", name = "Count") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), name = "UI Mode") +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          legend.box = "horizontal",
          legend.direction = "horizontal",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    } else {
      # Fallback: use density2d and points
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_point(alpha = 0.1, size = 0.8) +
        stat_density2d(aes(fill = ..level..), geom = "polygon", alpha = 0.3, contour = TRUE) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma", name = "Density") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), name = "UI Mode") +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          legend.box = "horizontal",
          legend.direction = "horizontal",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    }
    
    print(p1)
  }
}

```{r plot-path-efficiency}
#| fig-cap: "Path Efficiency vs. Movement Time. Path efficiency (A / path length) indicates how straight the movement was. Higher efficiency (closer to 1.0) means straighter paths. This plot shows whether inefficient movements lead to longer movement times, and whether adaptive UI improves efficiency."

if (exists("df_drag") && nrow(df_drag) > 0) {
  df_plot <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    p2 <- ggplot(df_plot, aes(x = eff, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.15, size = 1) +
      geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                  alpha = 0.3, linewidth = 1.1, method.args = list(family = "gaussian")) +
      geom_vline(xintercept = 0.9, linetype = "dashed", alpha = 0.4, linewidth = 0.5) +
      scale_y_log10(labels = scales::label_number()) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Path Efficiency (A / path length)",
        y = "Movement Time (s, log10)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p2)
  }
}
```

```{r plot-path-ratio-by-id}
#| fig-cap: "Path Ratio by Index of Difficulty. Mean path ratio (path length / amplitude) binned by ID quartiles. Shows whether excess path length increases with task difficulty, and whether adaptive UI reduces this effect. Higher ratio indicates less efficient (more curved) movements."

if (exists("df_drag") && nrow(df_drag) > 0 && "ID" %in% names(df_drag)) {
  df_filtered <- df_drag %>%
    filter(!is.na(ID), !is.na(ratio), ratio > 0)
  
  if (nrow(df_filtered) > 0) {
    # Compute quantiles and ensure breaks are unique
    id_quantiles <- quantile(df_filtered$ID, probs = seq(0, 1, 0.25), na.rm = TRUE, names = FALSE)
    id_quantiles <- unique(sort(id_quantiles))
    
    # Need at least 2 unique break points for cut() to work
    # cut() creates length(breaks) - 1 intervals, so we need length(breaks) - 1 labels
    if (length(id_quantiles) >= 2) {
      # Determine how many bins we can create based on unique quantile values
      n_unique_quantiles <- length(id_quantiles)
      # We need n_unique_quantiles break points to create n_unique_quantiles - 1 intervals
      
      if (n_unique_quantiles >= 5) {
        # Can create 4 bins (quartiles)
        breaks <- id_quantiles
        labels <- c("Q1 (Low)", "Q2", "Q3", "Q4 (High)")  # 4 labels for 4 intervals
      } else if (n_unique_quantiles >= 4) {
        # Can create 3 bins
        breaks <- c(id_quantiles[1], id_quantiles[2], id_quantiles[n_unique_quantiles])
        labels <- c("Low", "Medium", "High")  # 3 labels for 3 intervals
      } else if (n_unique_quantiles >= 3) {
        # Can create 2 bins
        breaks <- c(id_quantiles[1], id_quantiles[n_unique_quantiles])
        labels <- c("Low", "High")  # 2 labels for 2 intervals
      } else {
        # Only 2 unique values - can only create 1 bin, which is not useful
        breaks <- NULL
        labels <- NULL
      }
      
      # Only proceed if we have valid breaks and labels match intervals
      if (!is.null(breaks) && length(breaks) >= 2 && length(breaks) == length(labels) + 1) {
        df_binned <- df_filtered %>%
          mutate(
            ID_bin = cut(ID, 
                         breaks = breaks,
                         include.lowest = TRUE,
                         labels = labels)
          ) %>%
          filter(!is.na(ID_bin)) %>%
          group_by(modality, pressure, ui_mode, ID_bin) %>%
          summarise(
            n = n(),
            mean_ratio = mean(ratio, na.rm = TRUE),
            se_ratio = sd(ratio, na.rm = TRUE) / sqrt(n()),
            mean_eff = mean(eff, na.rm = TRUE),
            .groups = "drop"
          )
        
        if (nrow(df_binned) > 0 && sum(df_binned$n) > 0) {
          p3 <- ggplot(df_binned, aes(x = ID_bin, y = mean_ratio, group = ui_mode, color = ui_mode)) +
            geom_line(linewidth = 1, alpha = 0.8) +
            geom_point(size = 2.5) +
            geom_errorbar(aes(ymin = mean_ratio - se_ratio, ymax = mean_ratio + se_ratio),
                          width = 0.1, linewidth = 0.5, alpha = 0.6) +
            geom_hline(yintercept = 1.0, linetype = "dashed", alpha = 0.3, linewidth = 0.5) +
            facet_grid(modality ~ pressure,
                       labeller = labeller(
                         modality = function(x) paste("Modality:", str_to_title(x)),
                         pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                       )) +
            scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
            labs(
              x = "Index of Difficulty (binned)",
              y = "Mean Path Ratio (path length / amplitude)",
              color = "UI Mode"
            ) +
            theme_minimal(base_size = 14) +
            theme(
              legend.position = "top",
              strip.text = element_text(face = "bold", size = 12),
              strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
              panel.grid.minor = element_blank(),
              axis.text.x = element_text(angle = 45, hjust = 1)
            )
          
          print(p3)
        } else {
          cat("⚠ Insufficient data for ID binning plot.\n")
        }
      } else {
        cat("⚠ Cannot create ID bins: insufficient variation or invalid break points.\n")
        cat("Skipping ID binning plot.\n")
      }
    } else {
      cat("⚠ Insufficient ID variation for binning (all values are similar).\n")
      cat("Skipping ID binning plot.\n")
    }
  } else {
    cat("⚠ No valid ID/ratio data for binning plot.\n")
  }
}
```

```{r plot-path-efficiency-individual}
#| fig-cap: "Individual Differences in Path Efficiency. Thin lines show per-participant mean efficiency by UI mode. Thick line and large point show condition mean. Shows whether adaptive UI consistently improves efficiency across participants."

if (exists("df_drag") && nrow(df_drag) > 0 && "pid" %in% names(df_drag)) {
  df_pid <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1) %>%
    group_by(pid, modality, pressure, ui_mode) %>%
    summarise(
      mean_eff = mean(eff, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 5)  # Only participants with sufficient data
  
  if (nrow(df_pid) > 0) {
    p4 <- ggplot(df_pid, aes(x = ui_mode, y = mean_eff, group = pid)) +
      geom_line(alpha = 0.2, linewidth = 0.5) +
      geom_point(alpha = 0.3, size = 1.5) +
      stat_summary(aes(group = 1), fun = mean, geom = "line", linewidth = 1.2, color = "black") +
      stat_summary(aes(group = 1), fun = mean, geom = "point", size = 3, color = "black", shape = 21, fill = "white") +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Mean Path Efficiency (A / path length)",
        caption = "Thin lines: individual participants. Thick line: condition mean."
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "none",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p4)
  }
}
```

-----

<!-- Consolidated: hover time section removed for interim slimness -->

-----

::: {.callout-note collapse=true}
## Planned advanced analyses (not executed in interim N)

- Hierarchical LBA (verification-time RTs); requires more data and packages (RWiener/rtdists).
- Control-theory kinematics (velocity profiles, submovement decomposition) once trajectories vetted.
- Identification checks: need ≥2 levels per factor and adequate trial counts per cell (~24+).
- Error-type breakdowns and spatial heatmaps to remain exploratory/QC until full N.
- Revisit hover/dwell and path-length efficiency once gaze data are richer.
:::

**Implementation Notes:**
- LBA requires RT data from the verification phase (time from target entry to selection)
- Model fitting can be done using `RWiener` or `rtdists` packages
- Key parameters to estimate: drift rate (v), threshold (b), starting point (A), non-decision time (t0)
- Hypothesis: Adaptive conditions should show lower threshold (b), indicating less caution needed

-----

# 17. Control Theory Analysis: Submovement Models

**Research Question:** How does the control loop efficiency differ across conditions? Do adaptive interventions reduce movement corrections?

*The Optimized Submovement Model [@meyer1988] posits that pointing movements are composed of a primary ballistic impulse followed by n corrective submovements. The Submovement Count (N_sub) serves as a proxy for the efficiency of the control loop. In gaze-based interaction, simulated lag and saccadic blindness force users into an intermittent control regime, theoretically increasing N_sub.*

**Status:** ⚠️ **PARTIALLY IMPLEMENTED - Basic analysis done, advanced control theory analysis pending**

**Note:** Basic submovement analysis (submovement count by condition) is already implemented in Section 10 (Movement Quality Metrics). This section is a placeholder for advanced control theory analyses such as velocity profile decomposition, primary vs. corrective movement identification, and control loop efficiency metrics. Trajectory data is now available in the `trajectory` column (JSON string) logged at ~60fps during trials.

**Power Analysis Summary:**
- **N=48 is sufficient** for medium main effects (dz≈0.41, power≈0.80)
- **Interactions will be underpowered** unless large (treat as exploratory)
- **60fps trajectory data** improves measurement precision but doesn't increase effective N
- **Key considerations:** Use duration-normalized smoothness metrics, control for multiple comparisons (FDR), pre-specify outcomes
- See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed recommendations

```{r control-theory-placeholder}
# TODO: Advanced control theory analysis
# Current status: Basic submovement_count analysis is in Section 10
# Advanced analysis needed:
# 1. Velocity profile analysis (extract from cursor trajectory data if available)
# 2. Submovement detection algorithm (zero-crossings in acceleration)
# 3. Primary vs. corrective movement decomposition
# 4. Control loop efficiency metrics

cat("⚠️ **Advanced Control Theory Analysis Not Yet Implemented**\n\n")
cat("This section will analyze movement control using the Optimized Submovement Model.\n\n")
cat("**Current Status:**\n")
cat("- Basic submovement_count analysis: ✅ DONE (Section 10)\n")
cat("- Velocity profile analysis: ❌ PENDING\n")
cat("- Submovement detection algorithm: ❌ PENDING\n")
cat("- Primary vs. corrective movement decomposition: ❌ PENDING\n\n")

# Check if submovement_count data exists
if ("submovement_count" %in% names(df)) {
  df_submov_check <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov_check) > 0) {
    cat("✅ Submovement count data available:\n")
    cat("   - N trials with submovement data:", nrow(df_submov_check), "\n")
    cat("   - Mean submovements per trial:", round(mean(df_submov_check$submovement_count, na.rm = TRUE), 2), "\n")
    cat("   - Range:", round(min(df_submov_check$submovement_count, na.rm = TRUE), 0), "-", 
        round(max(df_submov_check$submovement_count, na.rm = TRUE), 0), "\n\n")
    
    # Check for condition differences
    submov_by_condition <- df_submov_check %>%
      group_by(modality, ui_mode) %>%
      summarise(
        Mean_Submov = round(mean(submovement_count, na.rm = TRUE), 2),
        SD_Submov = round(sd(submovement_count, na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    cat("**Submovement Count by Modality and UI Mode:**\n")
    print(knitr::kable(submov_by_condition))
    
    cat("\n**Data Quality Check:**\n")
    # Check if we have cursor trajectory data (needed for velocity profile analysis)
    if ("trajectory" %in% names(df_raw)) {
      df_traj_check <- df_raw %>%
        filter(
          practice == "false" | practice == FALSE | is.na(practice),
          !is.na(trajectory),
          trajectory != "",
          trajectory != "null"
        )
      
      if (nrow(df_traj_check) > 0) {
        cat("   ✅ Trajectory data available in CSV:\n")
        cat("      - N trials with trajectory:", nrow(df_traj_check), "\n")
        cat("      - Trajectory stored as JSON string in 'trajectory' column\n")
        cat("      - Can be parsed in R: jsonlite::fromJSON(trajectory)\n")
      } else {
        cat("   ⚠️  Trajectory column exists but no data yet (may be from old data)\n")
      }
    } else {
      cat("   ⚠️  Trajectory column not found (may be from old data)\n")
    }
    cat("   - Current analysis uses pre-calculated submovement_count from FittsTask.tsx\n")
    
    cat("\n**Next Steps for Advanced Analysis:**\n")
    cat("1. If cursor trajectory data is needed, add logging to FittsTask.tsx\n")
    cat("2. Implement velocity profile extraction from trajectory\n")
    cat("3. Detect submovements using zero-crossings in acceleration profile\n")
    cat("4. Decompose primary vs. corrective movements\n")
    cat("5. Compare control loop efficiency across conditions\n")
    cat("6. Test hypothesis: Adaptive UI → fewer submovements (more ballistic)\n")
  } else {
    cat("❌ No valid submovement data available\n")
  }
} else {
  cat("❌ submovement_count column not found in dataset\n")
}
```

```{r control-theory-advanced}
# Placeholder: Advanced control theory metrics
# This would analyze velocity profiles and movement decomposition

cat("⚠️ **Advanced Control Theory Metrics Not Yet Implemented**\n\n")
cat("**Planned Analyses:**\n")
cat("1. **Velocity Profile Analysis:**\n")
cat("   - Peak velocity extraction\n")
cat("   - Time to peak velocity (TPV)\n")
cat("   - Deceleration phase duration\n")
cat("   - Velocity profile asymmetry\n\n")
cat("2. **Submovement Detection:**\n")
cat("   - Zero-crossing detection in acceleration profile\n")
cat("   - Primary movement identification (first ballistic phase)\n")
cat("   - Corrective submovement count and duration\n")
cat("   - Inter-submovement intervals\n\n")
cat("3. **Control Loop Efficiency:**\n")
cat("   - Ratio of primary to total movement time\n")
cat("   - Correction frequency (submovements per second)\n")
cat("   - Movement smoothness metrics (jerk, normalized jerk - MUST be duration-normalized)\n\n")
cat("4. **Modality-Specific Patterns:**\n")
cat("   - Gaze: Intermittent control due to lag and saccadic blindness\n")
cat("   - Hand: Continuous control with proprioceptive feedback\n")
cat("   - Adaptive: Reduced corrections due to target expansion/declutter\n\n")
cat("**Data Requirements:**\n")
cat("✅ Trajectory data is now available in 'trajectory' column (JSON string, ~60fps)\n")
cat("✅ Current CSV has submovement_count (pre-calculated) AND raw trajectory\n")
cat("\n**Power & Analysis Considerations:**\n")
cat("- N=48 is sufficient for main effects (dz≈0.41, power≈0.80)\n")
cat("- Interactions: Underpowered, treat as exploratory\n")
cat("- 60fps improves measurement precision but doesn't increase effective N\n")
cat("- Use duration-normalized smoothness metrics\n")
cat("- Control for multiple comparisons (FDR) if testing many metrics\n")
cat("- Pre-specify theoretically motivated outcomes\n")
cat("\n**See POWER_ANALYSIS_EXPERT_RESPONSE.md for detailed recommendations**\n")
```

**Implementation Notes:**
- Basic submovement analysis is already in Section 10 (Movement Quality Metrics)
- **Trajectory data is now available** in the `trajectory` column (JSON string, logged at ~60fps)
- Current `submovement_count` is pre-calculated in `FittsTask.tsx` using velocity peaks
- **Power:** N=48 sufficient for main effects (dz≈0.41, power≈0.80); interactions underpowered (treat as exploratory)
- **Key considerations:**
  - Use duration-normalized smoothness metrics (jerk is duration-sensitive)
  - Control for multiple comparisons (FDR) if testing many kinematic features
  - Pre-specify a small set of theoretically motivated outcomes
  - 60fps improves measurement precision but doesn't increase effective N
- **See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed power analysis and recommendations**

**Potential Issues to Check:**
- Verify that `submovement_count` calculation in `FittsTask.tsx` matches the Optimized Submovement Model definition
- Check if velocity profile data is needed or if pre-calculated counts are sufficient
- Ensure submovement detection algorithm handles both hand and gaze modalities correctly

-----

# 18. Summary & Conclusions

## Key Findings Summary

```{r summary-table}
# Create a comprehensive summary table
summary_table <- bind_rows(
  # Throughput
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Throughput (bits/s)",
      Mean = round(mean(TP, na.rm = TRUE), 2),
      SD = round(sd(TP, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Movement Time
  df %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Movement Time (s)",
      Mean = round(mean(rt_s, na.rm = TRUE), 3),
      SD = round(sd(rt_s, na.rm = TRUE), 3),
      .groups = "drop"
    ),
  # Error Rate
  df_errors %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Error Rate (%)",
      Mean = round(100 * mean(error, na.rm = TRUE), 2),
      SD = round(100 * sd(error, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Effective Width
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Effective Width (px)",
      Mean = round(mean(We, na.rm = TRUE), 2),
      SD = round(sd(We, na.rm = TRUE), 2),
      .groups = "drop"
    )
) %>%
  arrange(Metric, modality, ui_mode)

summary_table %>%
  kable(caption = "Summary of Key Metrics by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

## Data Quality Notes

- **Participants:** `r n_distinct(df$pid)`
- **Valid Trials:** `r nrow(df)` (out of `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))` total experimental trials)
- **Exclusion Rate:** `r percent(round(1 - nrow(df) / nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice))), 3))` (due to errors, timeouts, or invalid RTs)
- **Trials per Participant:** Mean = `r round(mean(table(df$pid)), 1)`, Range = `r paste(round(min(table(df$pid)), 0), "-", round(max(table(df$pid)), 0))`

### Participant Exclusions

**Excluded Participants:** Seven participants (P002, P003, P007, P008, P015, P039, P040) were excluded from the main 2×2×2 factorial analysis due to a data logging error.

**Reason:** A bug in the data logging code (fixed December 8, 2025, commit `04758db`) incorrectly recorded all trials as `pressure = 1` regardless of block condition. The bug was caused by passing the pressure value (always 1.0) instead of the pressure condition boolean (`pressureEnabled`) to the logging function in `TaskPane.tsx` line 1105.

**Impact:** 
- All 7 affected participants have only `pressure = 1` data
- Modality and UI Mode were logged correctly (0 mismatches)
- Without both pressure conditions (0 and 1), these participants cannot contribute to the full factorial model

**Resolution:** 
- Bug fixed and deployed (commit `04758db`)
- Seven replacement participants (P049-P055) added to maintain N=48
- Affected participants' data retained for exploratory analyses

**Final Sample:** N=48 participants with complete data across all experimental conditions.

For detailed exclusion criteria, see `EXCLUSION_CRITERIA.md`. For technical audit details, see `AUDIT_REPORT.md`.

