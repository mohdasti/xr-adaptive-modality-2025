
---
title: "XR Adaptive Modality: Experiment Report"
author: "Mohammad Dastgheib"
date: last-modified
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    code-fold: true
    self-contained: true
    fig-width: 10
    fig-height: 6
    html-math-method: mathjax
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(htmltools)
library(scales)
library(ggsci)  # For pal_npg() function
library(lme4)
library(lmerTest)
library(emmeans)
library(jsonlite)  # For reading LBA and ex-Gaussian results

# Try to load effectsize for effect size calculations
has_effectsize <- requireNamespace("effectsize", quietly = TRUE)
if (!has_effectsize) {
  cat("Note: Install 'effectsize' package for effect size calculations: install.packages('effectsize')\n")
  cat("Effect sizes will be approximated using Cohen's d from emmeans.\n")
}

# Set sum-to-zero contrasts for proper type-III ANOVA interpretation in factorial designs
options(contrasts = c("contr.sum", "contr.poly"))

# Check for ggdist (needed for proper raincloud plots)
has_ggdist <- requireNamespace("ggdist", quietly = TRUE)
if (!has_ggdist) {
  cat("Note: Install 'ggdist' package for proper raincloud plots: install.packages('ggdist')\n")
  cat("Using fallback violin plots for now.\n")
}

# --- COLOR PALETTE ---
# Use Nature Publishing Group (NPG) palette from scales package
npg_pal <- pal_npg("nrc")(10)  # Get 10 colors from the palette

# For 2-level factors (e.g., static/adaptive), use first 2 colors
custom_palette_2 <- npg_pal[1:2]

# For multi-level factors (e.g., TLX scales with 6 levels), use first 6 colors
custom_palette_multi <- npg_pal[1:6]

# --- RAINCLOUD PLOT HELPER ---
# Function to create proper raincloud plots (half-violin + boxplot + points + lines)
# Based on Allen et al. (2019) "Raincloud plots: a multi-platform tool for robust data visualization"
create_raincloud <- function(data, x_var, y_var, fill_var, group_var = NULL, 
                             violin_side = "r", violin_width = 0.4, 
                             box_width = 0.15, point_size = 2.5, 
                             line_alpha = 0.3, point_alpha = 0.7) {
  
  # Check if ggdist is available for proper half-violins
  has_ggdist <- requireNamespace("ggdist", quietly = TRUE)
  
  p <- ggplot(data, aes_string(x = x_var, y = y_var, fill = fill_var))
  
  if (has_ggdist) {
    # Use ggdist for proper half-violins
    p <- p + 
      ggdist::stat_halfeye(
        aes(fill = .data[[fill_var]]),
        side = violin_side,
        alpha = 0.4,
        width = violin_width,
        .width = 0,
        justification = ifelse(violin_side == "r", -0.3, 1.3),
        point_colour = NA
      )
  } else {
    # Fallback: create half-violin manually using geom_violin with positioning
    # This creates a full violin, but we'll position it to show only half
    p <- p +
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = violin_width,
        position = position_nudge(x = ifelse(violin_side == "r", 0.25, -0.25)),
        color = NA
      )
  }
  
  # Boxplot (positioned on the left, inside the violin area)
  p <- p +
    geom_boxplot(
      width = box_width,
      alpha = 0.6,
      outlier.shape = NA,
      position = position_nudge(x = -0.15),
      color = "grey30",
      linewidth = 0.5
    )
  
  # Connecting lines (if group_var provided, for paired data)
  if (!is.null(group_var)) {
    p <- p +
      geom_line(
        aes_string(group = group_var, color = fill_var),
        alpha = line_alpha,
        linewidth = 0.6,
        position = position_nudge(x = -0.25)
      )
  }
  
  # Individual points
  p <- p +
    geom_point(
      aes_string(color = fill_var),
      alpha = point_alpha,
      size = point_size,
      position = position_nudge(x = -0.25)
    )
  
  # Mean marker (white diamond)
  p <- p +
    stat_summary(
      fun = mean,
      geom = "point",
      shape = 23,
      size = 4,
      fill = "white",
      color = "black",
      stroke = 1.2,
      position = position_nudge(x = -0.25)
    )
  
  return(p)
}

# --- HELPER: BUILD MODEL FORMULAS WITH AVAILABLE FACTORS ---
build_mixed_formula <- function(dv, factors, data) {
  keep <- factors[sapply(factors, function(f) n_distinct(data[[f]], na.rm = TRUE) > 1)]
  dropped <- setdiff(factors, keep)
  rhs <- if (length(keep) > 0) paste(keep, collapse = " * ") else "1"
  list(
    formula = as.formula(paste(dv, "~", rhs, "+ (1 | pid)")),
    dropped = dropped
  )
}

# --- HELPER: COMPUTE DYNAMIC SAMPLE SIZES ---
# These functions compute sample sizes dynamically for different data subsets
# This ensures captions and headers always reflect the current data

# Get total number of participants in a dataset
get_n_participants <- function(data) {
  if (is.null(data) || nrow(data) == 0) return(0)
  n_distinct(data$pid, na.rm = TRUE)
}

# Get sample size by condition (modality, ui_mode, pressure)
get_n_by_condition <- function(data, modality_val = NULL, ui_mode_val = NULL, pressure_val = NULL) {
  if (is.null(data) || nrow(data) == 0) return(0)
  
  filtered_data <- data
  if (!is.null(modality_val)) {
    filtered_data <- filtered_data %>% filter(modality == modality_val)
  }
  if (!is.null(ui_mode_val)) {
    filtered_data <- filtered_data %>% filter(ui_mode == ui_mode_val)
  }
  if (!is.null(pressure_val)) {
    filtered_data <- filtered_data %>% filter(pressure == pressure_val)
  }
  
  n_distinct(filtered_data$pid, na.rm = TRUE)
}

# Get sample size for specific modality
get_n_by_modality <- function(data, modality_val) {
  get_n_by_condition(data, modality_val = modality_val)
}

# Get sample size for specific UI mode
get_n_by_ui_mode <- function(data, ui_mode_val) {
  get_n_by_condition(data, ui_mode_val = ui_mode_val)
}

# Get sample size with data availability check (returns formatted string)
get_n_string <- function(data, prefix = "N = ", suffix = "") {
  n <- get_n_participants(data)
  if (n == 0) return("N = 0 (no data)")
  paste0(prefix, n, suffix)
}

# Get sample size by modality with formatted string
get_n_modality_string <- function(data) {
  n_hand <- get_n_by_modality(data, "hand")
  n_gaze <- get_n_by_modality(data, "gaze")
  if (n_hand == 0 && n_gaze == 0) return("N = 0")
  if (n_hand == n_gaze) return(paste0("N = ", n_hand, " per modality"))
  paste0("N = ", n_hand, " (hand), ", n_gaze, " (gaze)")
}

# --- HELPER: APA FORMATTING FUNCTIONS ---
# Format p-values according to APA style (vectorized)
format_p_apa <- function(p) {
  if (length(p) == 0) return(character(0))
  result <- character(length(p))
  for (i in seq_along(p)) {
    if (is.na(p[i])) {
      result[i] <- "NA"
    } else if (p[i] < .001) {
      result[i] <- "< .001"
    } else {
      result[i] <- sprintf("= %.3f", p[i])
    }
  }
  return(result)
}

# Format F-statistic for APA
format_F_apa <- function(F_val, df1, df2, p) {
  sprintf("F(%d, %.1f) = %.2f, p %s", df1, df2, F_val, format_p_apa(p))
}

# Format t-statistic for APA
format_t_apa <- function(t_val, df, p) {
  sprintf("t(%.1f) = %.2f, p %s", df, t_val, format_p_apa(p))
}

# Format chi-square for APA
format_chisq_apa <- function(chisq_val, df, p) {
  sprintf("χ²(%d) = %.2f, p %s", df, chisq_val, format_p_apa(p))
}

# Calculate partial eta-squared from F-statistic (approximate)
calc_partial_eta_sq <- function(F_val, df1, df_error) {
  # η²p = (F * df1) / (F * df1 + df_error)
  if (is.na(F_val) || is.na(df1) || is.na(df_error) || df_error == 0) return(NA_real_)
  (F_val * df1) / (F_val * df1 + df_error)
}

# Interpret effect size (Cohen's d)
interpret_cohens_d <- function(d) {
  abs_d <- abs(d)
  if (is.na(abs_d)) return("NA")
  if (abs_d < 0.2) return("negligible")
  if (abs_d < 0.5) return("small")
  if (abs_d < 0.8) return("medium")
  return("large")
}

# Interpret partial eta-squared
interpret_eta_sq <- function(eta_sq) {
  if (is.na(eta_sq)) return("NA")
  if (eta_sq < 0.01) return("negligible")
  if (eta_sq < 0.06) return("small")
  if (eta_sq < 0.14) return("medium")
  return("large")
}

# Helper: Safely extract mean value from emmeans data frame
# Handles both "response" (for type="response") and "emmean" columns
safe_extract_mean <- function(emm_df, condition_col, condition_val, mean_cols = c("response", "emmean")) {
  # Find which mean column exists
  mean_col <- NULL
  for (col in mean_cols) {
    if (col %in% names(emm_df)) {
      mean_col <- col
      break
    }
  }
  
  if (is.null(mean_col)) {
    return(NA_real_)
  }
  
  # Extract value
  idx <- emm_df[[condition_col]] == condition_val
  if (sum(idx) == 0) {
    return(NA_real_)
  }
  
  value <- emm_df[[mean_col]][idx][1]
  return(if (is.na(value)) NA_real_ else value)
}

# Helper: Safely extract CI value from emmeans data frame
safe_extract_ci <- function(emm_df, condition_col, condition_val, ci_col) {
  if (is.null(ci_col) || !ci_col %in% names(emm_df)) {
    return(NA_real_)
  }
  
  idx <- emm_df[[condition_col]] == condition_val
  if (sum(idx) == 0) {
    return(NA_real_)
  }
  
  value <- emm_df[[ci_col]][idx][1]
  return(if (is.na(value)) NA_real_ else value)
}

# Helper: Format mean with CI for APA text
format_mean_ci <- function(mean_val, ci_lower_val, ci_upper_val, format_str = "%.2f", unit = "") {
  if (is.na(mean_val)) {
    return(paste0("M = [unavailable]", unit))
  }
  
  mean_str <- sprintf(format_str, mean_val)
  
  if (!is.na(ci_lower_val) && !is.na(ci_upper_val)) {
    ci_str <- paste0(", 95% CI [", sprintf(format_str, ci_lower_val), 
                     ", ", sprintf(format_str, ci_upper_val), "]")
  } else {
    ci_str <- ""
  }
  
  return(paste0("M = ", mean_str, ci_str, unit))
}

# --- DATA LOADING ---
# Load the latest clean data
# Try multiple possible paths (relative to report location or working directory)
data_paths <- c(
  "data/clean/trial_data.csv",           # If running from project root
  "../data/clean/trial_data.csv"         # If running from subdirectory
)

df_raw <- NULL
for (path in data_paths) {
  if (file.exists(path)) {
    tryCatch({
      df_raw <- read_csv(path, show_col_types = FALSE)
      cat("Loaded data from:", path, "\n")
      break
    }, error = function(e) {
      # Continue to next path
    })
  }
}

if (is.null(df_raw)) {
  stop("Could not find 'trial_data.csv'. Tried paths:\n",
       paste("  -", data_paths, collapse = "\n"),
       "\nCurrent working directory:", getwd(),
       "\nPlease ensure the data pipeline has run and the file exists.")
}

# Normalize column names
if ("participant_id" %in% names(df_raw) && !"pid" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(pid = participant_id)
}
if ("movement_time_ms" %in% names(df_raw) && !"rt_ms" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(rt_ms = movement_time_ms)
}

# Ensure required pid column exists
if (!"pid" %in% names(df_raw)) {
  stop("Required column 'pid' is missing after loading data. Available columns: ", paste(names(df_raw), collapse = ", "))
}

# --- PREPROCESSING ---
# Participant-level exclusion policy:
# The exclude_main flag and data_quality_flags_json are preserved in the data for transparency.
# Exclusion decisions are made case-by-case based on:
# - Which analysis is being performed (e.g., full 2×2×2 factorial requires all conditions)
# - Specific data quality issues (e.g., pressure_bug_detected affects factorial analyses)
# - Whether the issue affects the specific metric being analyzed
# 
# For analyses requiring full factorial (modality × ui_mode × pressure):
#   - Participants with pressure_bug_detected are excluded (they only have pressure=1)
#   - This is applied in the specific analysis sections, not globally
# 
# For other analyses (e.g., modality × ui_mode without pressure):
#   - These participants may still be usable
# 
# Document excluded participants for reference:
if ("exclude_main" %in% names(df_raw) || "data_quality_flags_json" %in% names(df_raw)) {
  if ("data_quality_flags_json" %in% names(df_raw)) {
    # Parse flags to identify specific issues
    df_raw <- df_raw %>%
      mutate(
        has_pressure_bug = ifelse(
          !is.na(data_quality_flags_json),
          grepl("pressure_bug_detected", data_quality_flags_json, fixed = TRUE),
          FALSE
        ),
        has_trajectory_missing = ifelse(
          !is.na(data_quality_flags_json),
          grepl("trajectory_missing", data_quality_flags_json, fixed = TRUE),
          FALSE
        )
      )
    
    # Report summary
    pressure_bug_pids <- df_raw %>% 
      filter(has_pressure_bug == TRUE) %>% 
      distinct(pid) %>% 
      pull(pid) %>% 
      as.character() %>% 
      sort()
    
    if (length(pressure_bug_pids) > 0) {
      cat("\n**Data Quality Note:** ", length(pressure_bug_pids), 
          " participants have pressure_bug_detected flag: ", 
          paste(pressure_bug_pids, collapse = ", "), "\n")
      cat("  These participants will be excluded from full 2×2×2 factorial analyses\n")
      cat("  (modality × ui_mode × pressure) but may be usable for other analyses.\n\n")
    }
  }
}

# Create unified trial-level QC flag
df_raw <- df_raw %>%
  mutate(
    trial_qc_ok = (
      (practice == FALSE | practice == "false" | is.na(practice)) &
      (is.na(zoom_pct) | zoom_pct == 100) &
      (is.na(is_fullscreen) | is_fullscreen == TRUE | (if("fullscreen" %in% names(.)) fullscreen == TRUE else TRUE)) &
      (is.na(tab_hidden_ms) | tab_hidden_ms < 500) &
      (is.na(focus_blur_count) | focus_blur_count == 0)
    )
  )

# Create dataframe with ALL trials (correct + incorrect) for error rate calculations
# This includes trials with valid RTs (even if incorrect) and excludes practice + QC violations
df_all_trials <- df_raw %>%
  filter(trial_qc_ok) %>%
  mutate(
    rt_s = rt_ms / 1000,
    log_rt = log(rt_ms),
    # Create factor labels for better plots
    Condition = paste(modality, ui_mode, sep = " - "),
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    ModalityLabel = str_to_title(modality),
    UILabel = str_to_title(ui_mode),
    # Ensure factors
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid),
    # Mark correct/incorrect for error calculations
    # Note: In the data, correct = TRUE for correct trials, and correct = NA for errors
    is_correct = !is.na(correct) & (correct == "true" | correct == TRUE | correct == 1)
  )

# Filter valid experimental trials (non-practice, correct, valid RTs) for performance metrics
# Note: This includes ALL participants. Exclusions for factorial analyses are applied later.
df <- df_all_trials %>%
  filter(
    is_correct == TRUE,
    rt_ms >= 150,  # Physiological minimum
    rt_ms <= 6000  # Time-out threshold
  )

# Create a version of df for full factorial analyses (excludes participants with pressure bug)
# This is used only for analyses requiring modality × ui_mode × pressure
if (exists("has_pressure_bug") && "has_pressure_bug" %in% names(df)) {
  df_factorial <- df %>%
    filter(!has_pressure_bug)  # Exclude participants with pressure bug for factorial analyses
} else {
  # If pressure bug flag not available, check by actual data coverage
  df_factorial <- df %>%
    group_by(pid) %>%
    filter(n_distinct(pressure, na.rm = TRUE) == 2) %>%  # Must have both pressure levels
    ungroup()
}

# --- PLANNED SAMPLE SIZE & POWER ---
# Power analysis summary for the 2×2×2 within-subjects design
# See POWER_ANALYSIS_PROMPT.md and power analysis documentation for full details

cat("\n### Planned Sample Size & Power\n\n")
cat("We pre-planned sample size for a 2×2×2 within-subjects design (modality × UI mode × pressure) using standard repeated-measures power analysis (Cohen, 1988) and recent guidelines for cognitive and HCI mixed-effects experiments (Brysbaert, 2019; Kumle et al., 2021; Matuschek et al., 2017). For the core UI-mode and modality main effects, we expect medium within-subject effect sizes (dz ≈ 0.4–0.6). Power calculations indicate that approximately 50 participants are sufficient to achieve 80% power for dz ≈ 0.40 at α = .05 in a two-level within-subjects contrast.\n\n")
cat("Based on these considerations, we defined **N = 48 participants (six full Williams sequences)** as our primary target for all core analyses (throughput, RT, error rate, and NASA-TLX). If recruitment allows, we plan to extend the study to **N = 64 participants (eight sequences)** to increase power for error-based measures, re-entry counts, submovement metrics, and advanced cognitive-modeling analyses (LBA, control-theory kinematics). Three-way interactions and smaller effects are treated as exploratory regardless of N.\n\n")
cat("**Current Status:** This report is based on N=`r n_distinct(df$pid)` participants. We are targeting N=64 for enhanced power in advanced analyses (LBA, control-theory kinematics).\n\n")

# --- DATA QUALITY & COVERAGE GATE ---
# Precompute coverage metrics once; reused across report
qc_participants_total <- df_raw %>%
  filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
  pull(pid) %>%
  n_distinct()

qc_participants_included <- df %>% pull(pid) %>% n_distinct()
qc_participants_all_trials <- df_all_trials %>% pull(pid) %>% n_distinct()

qc_cell_coverage <- df_all_trials %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    trials = n(),
    pids = n_distinct(.data$pid),
    .groups = "drop"
  ) %>%
  tidyr::complete(modality, ui_mode, pressure, fill = list(trials = 0, pids = 0)) %>%
  mutate(missing_cell = trials == 0 | pids == 0)

qc_missing_factors <- list(
  modality = n_distinct(df_all_trials$modality, na.rm = TRUE) < 2,
  ui_mode = n_distinct(df_all_trials$ui_mode, na.rm = TRUE) < 2,
  pressure = n_distinct(df_all_trials$pressure, na.rm = TRUE) < 2
)

qc_block_completion <- df_all_trials %>%
  filter(!is.na(block_number)) %>%
  group_by(pid) %>%
  summarise(
    blocks_logged = n_distinct(block_number),
    .groups = "drop"
  )

# --- CALCULATE ISO METRICS (Throughput) ---
# ISO 9241-9: Calculate We (Effective Width) per condition per participant
# For ISO throughput (full factorial analysis requiring modality × ui_mode × pressure),
# use df_factorial which excludes participants with pressure bug (they only have pressure=1)
# 
# Note: projected_error_px is assumed to be the target-axis projected error (signed distance
# along the movement axis, not raw radial error). This follows ISO 9241-9 specifications.
# Positive values indicate overshoot, negative values indicate undershoot.
df_iso <- df_factorial %>%
  group_by(pid, modality, ui_mode, pressure, A, W) %>%
  summarise(
    # Count trials per cell for quality control
    n_trials_cell = n(),
    # We = 4.133 * SD of Projected Error
    # projected_error_px: signed distance along target axis (px)
    sd_x = sd(projected_error_px, na.rm = TRUE),
    We = 4.133 * sd_x,
    
    # Effective ID
    IDe = log2((mean(A, na.rm = TRUE) / We) + 1),
    
    # Mean Movement Time for this condition
    MT_avg = mean(rt_s, na.rm = TRUE),
    
    # Throughput (Bits/s)
    TP = IDe / MT_avg,
    
    # Gaze Specifics
    reentries = mean(target_reentry_count, na.rm = TRUE),
    verification = mean(verification_time_ms, na.rm = TRUE),
    
    .groups = "drop"
  ) %>%
  filter(
    # ISO data quality criteria: enforce minimum trial count and valid SD
    # Minimum 3 trials per A×W cell ensures stable We and TP estimates
    n_trials_cell >= 3,
    !is.na(sd_x),
    sd_x > 0,
    # Throughput quality filters
    !is.na(TP),
    is.finite(TP),
    TP > 0,
    TP < 20
  ) %>%
  mutate(
    # Recreate labels that were lost in summarise
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    Condition = paste(modality, ui_mode, sep = " - ")
  )

# Participant-level performance summaries (used across core analyses)
df_pid_cond <- df %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(
    rt_mean = mean(rt_s, na.rm = TRUE),
    rt_median = median(rt_s, na.rm = TRUE),
    trials_rt = n(),
    .groups = "drop"
  ) %>%
  left_join(
    df_all_trials %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(
        error_rate = mean(!is_correct, na.rm = TRUE),
        trials_all = n(),
        .groups = "drop"
      ),
    by = c("pid", "modality", "ui_mode", "pressure")
  ) %>%
  left_join(
    df_iso %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(tp_mean = mean(TP, na.rm = TRUE), .groups = "drop"),
    by = c("pid", "modality", "ui_mode", "pressure")
  )

# --- STATISTICAL MODELS ---
# Helper function for diagnostics
diagnose_model_data <- function(data, model_name) {
  diag <- list()
  
  if (nrow(data) == 0) {
    diag$n_participants <- 0
    diag$n_trials <- 0
    diag$n_conditions <- 0
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$single_level_factors <- character(0)
    return(diag)
  }
  
  diag$n_participants <- n_distinct(data$pid)
  diag$n_trials <- nrow(data)
  
  # Check if required columns exist
  has_modality <- "modality" %in% names(data)
  has_ui_mode <- "ui_mode" %in% names(data)
  has_pressure <- "pressure" %in% names(data)
  
  # Check for single-level factors (causes "contrasts" error)
  single_level_factors <- character(0)
  if (has_modality && n_distinct(data$modality, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "modality")
  }
  if (has_ui_mode && n_distinct(data$ui_mode, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "ui_mode")
  }
  if (has_pressure && n_distinct(data$pressure, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "pressure")
  }
  diag$single_level_factors <- single_level_factors
  
  if (has_modality && has_ui_mode && has_pressure) {
    diag$n_conditions <- length(unique(interaction(data$modality, data$ui_mode, data$pressure, drop = TRUE)))
    
    # Check trials per condition
    condition_counts <- data %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(n = n(), .groups = "drop")
    diag$condition_counts <- condition_counts
    diag$min_trials_per_condition <- if(nrow(condition_counts) > 0) min(condition_counts$n, na.rm = TRUE) else 0
    diag$empty_conditions <- sum(condition_counts$n == 0, na.rm = TRUE)
  } else {
    diag$n_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
  }
  
  # Check for missing values in key variables
  diag$missing_tp <- if("TP" %in% names(data)) sum(is.na(data$TP)) else 0
  diag$missing_modality <- if(has_modality) sum(is.na(data$modality)) else 0
  diag$missing_ui_mode <- if(has_ui_mode) sum(is.na(data$ui_mode)) else 0
  diag$missing_pressure <- if(has_pressure) sum(is.na(data$pressure)) else 0
  
  return(diag)
}

# Model 1: Throughput
# Create filtered dataset for TP modeling (already filtered for quality in df_iso, but explicitly separate)
df_tp_model <- df_iso %>%
  filter(
    !is.na(TP),
    TP > 0,
    TP < 20
  )

model_tp <- NULL
emm_tp <- NULL
pairs_tp <- NULL
diag_tp <- NULL
model_tp_error <- NULL
model_tp_note <- NULL

# Use trial-level data for diagnostics, but aggregated data for modelling
if (nrow(df_factorial) > 0) {
  diag_tp <- diagnose_model_data(df_factorial, "Throughput (trial-level diagnostics)")
  
  if (diag_tp$n_participants <= 1) {
    model_tp_error <- paste0("Insufficient participants: N = ", diag_tp$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_tp$n_trials == 0) {
    model_tp_error <- "No valid trials in dataset."
  } else if (diag_tp$min_trials_per_condition < 3) {
    model_tp_error <- paste0("Insufficient data per condition: minimum ", diag_tp$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_tp$empty_conditions > 0) {
    model_tp_error <- paste0("Empty conditions detected: ", diag_tp$empty_conditions, " condition(s) have no data.")
  } else if (nrow(df_tp_model) == 0) {
    model_tp_error <- "No valid throughput data after quality filtering (TP > 0, TP < 20, valid We)."
  } else {
  formula_tp <- build_mixed_formula("TP", c("modality", "ui_mode", "pressure"), df_tp_model)
  if (length(formula_tp$dropped) > 0) {
    model_tp_note <- paste0("Dropped single-level factor(s): ", paste(formula_tp$dropped, collapse = ", "), ".")
  }
  model_tp <- tryCatch({
    lmer(formula_tp$formula,
         data = df_tp_model, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_tp_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_tp_error)) {
        model_tp_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_tp)) {
      
    tryCatch({
      emm_tp <- emmeans(model_tp, ~ modality * ui_mode * pressure)
      pairs_tp <- pairs(emm_tp, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_tp_error)) {
          model_tp_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_tp <- list(n_participants = 0, n_trials = 0)
  model_tp_error <- "No data available for throughput analysis."
}

# Model 2: Movement Time
model_rt <- NULL
emm_rt <- NULL
pairs_rt <- NULL
diag_rt <- NULL
model_rt_error <- NULL
model_rt_note <- NULL

if (nrow(df) > 0) {
  diag_rt <- diagnose_model_data(df, "Movement Time")
  
  if (diag_rt$n_participants <= 1) {
    model_rt_error <- paste0("Insufficient participants: N = ", diag_rt$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_rt$n_trials == 0) {
    model_rt_error <- "No valid trials in dataset."
  } else if (diag_rt$min_trials_per_condition < 3) {
    model_rt_error <- paste0("Insufficient data per condition: minimum ", diag_rt$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_rt$empty_conditions > 0) {
    model_rt_error <- paste0("Empty conditions detected: ", diag_rt$empty_conditions, " condition(s) have no data.")
  } else {
  # For full factorial RT model (modality × ui_mode × pressure), use df_factorial
  formula_rt <- build_mixed_formula("log_rt", c("modality", "ui_mode", "pressure"), df_factorial)
  if (length(formula_rt$dropped) > 0) {
    model_rt_note <- paste0("Dropped single-level factor(s): ", paste(formula_rt$dropped, collapse = ", "), ".")
  }
  model_rt <- tryCatch({
    lmer(formula_rt$formula, 
         data = df_factorial, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_rt_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_rt_error)) {
        model_rt_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_rt)) {
      
    tryCatch({
      emm_rt <- emmeans(model_rt, ~ modality * ui_mode * pressure, type = "response")
      pairs_rt <- pairs(emm_rt, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_rt_error)) {
          model_rt_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_rt <- list(n_participants = 0, n_trials = 0)
  model_rt_error <- "No data available for movement time analysis."
}

# Model 3: Error Rate
# Use df_all_trials which already has all trials (correct + incorrect)
df_errors <- df_all_trials %>%
  mutate(
    error = ifelse(is_correct, 0, 1),
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid)
  )

model_err <- NULL
emm_err <- NULL
pairs_err <- NULL
diag_err <- NULL
model_err_error <- NULL
model_err_note <- NULL

if (nrow(df_errors) > 0) {
  diag_err <- diagnose_model_data(df_errors, "Error Rate")
  
  if (diag_err$n_participants <= 1) {
    model_err_error <- paste0("Insufficient participants: N = ", diag_err$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_err$n_trials == 0) {
    model_err_error <- "No valid trials in dataset."
  } else if (diag_err$min_trials_per_condition < 3) {
    model_err_error <- paste0("Insufficient data per condition: minimum ", diag_err$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_err$empty_conditions > 0) {
    model_err_error <- paste0("Empty conditions detected: ", diag_err$empty_conditions, " condition(s) have no data.")
  } else {
    # Check for sufficient error variance (GLMM needs some errors)
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    if (error_rate < 0.01 || error_rate > 0.99) {
      model_err_error <- paste0("Insufficient error variance: error rate = ", round(error_rate * 100, 1), "%. GLMM requires some variation in outcomes.")
    } else {
  # For full factorial error model (modality × ui_mode × pressure), filter to df_factorial participants
  df_errors_factorial <- df_errors %>%
    filter(pid %in% unique(df_factorial$pid))
  
  formula_err <- build_mixed_formula("error", c("modality", "ui_mode", "pressure"), df_errors_factorial)
  if (length(formula_err$dropped) > 0) {
    model_err_note <- paste0("Dropped single-level factor(s): ", paste(formula_err$dropped, collapse = ", "), ".")
  }
  model_err <- tryCatch({
    glmer(formula_err$formula,
          data = df_errors_factorial, family = binomial(link = "logit"),
          control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
  }, error = function(e) {
        model_err_error <<- paste0("Model fitting failed: ", e$message)
        NULL
      }, warning = function(w) {
        if (is.null(model_err_error)) {
          model_err_error <<- paste0("Model fitting warning: ", w$message)
        }
    NULL
  })
  
  if (!is.null(model_err)) {
        
    tryCatch({
      emm_err <- emmeans(model_err, ~ modality * ui_mode * pressure, type = "response")
      pairs_err <- pairs(emm_err, adjust = "holm")
    }, error = function(e) {
          if (is.null(model_err_error)) {
            model_err_error <<- paste0("Could not compute estimated marginal means: ", e$message)
          }
    })
  }
    }
  }
} else {
  diag_err <- list(n_participants = 0, n_trials = 0)
  model_err_error <- "No data available for error rate analysis."
}
```

# Data Quality & Coverage Gate

::: {.callout-note}
This section prevents misleading models when cells are missing. Current data: N=`r n_distinct(df$pid)` participants.
:::

```{r qc-gate}
# Participants
# Note: df = correct trials, RT ∈ [150, 6000] ms, non-practice
qc_participants <- tibble(
  Metric = c("Total participants (raw)", "Participants with any valid trials", "Participants in df (correct, RT-filtered)"),
  Count = c(qc_participants_total, qc_participants_all_trials, qc_participants_included)
)

# Cell coverage table
qc_cells_table <- qc_cell_coverage %>%
  arrange(modality, ui_mode, pressure) %>%
  mutate(
    pressure = as.character(pressure),
    Status = ifelse(missing_cell, "MISSING", "OK")
  )

missing_factors <- names(qc_missing_factors)[unlist(qc_missing_factors)]

qc_participants %>%
  kable(caption = "Participant counts. Note: 'df' refers to correct trials, RT ∈ [150, 6000] ms, non-practice.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

qc_cells_table %>%
  kable(caption = "Condition coverage (modality × ui_mode × pressure)", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

if (length(missing_factors) > 0) {
  cat("**Missing factor levels detected:**", paste(missing_factors, collapse = ", "), "\n\n")
} else {
  cat("All factors have ≥2 levels in the data.\n\n")
}

if (nrow(qc_block_completion) > 0) {
  qc_block_completion %>%
    kable(caption = "Blocks logged per participant", align = "c") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```



# 1. Executive Summary

This report analyzes **`r n_distinct(df$pid)`** participants performing Fitts' law pointing tasks across two input modalities (Hand, Gaze) and two UI modes (Static, Adaptive).

# Results Snapshot (N = `r qc_participants_included`)

```{r results-snapshot}
# Simple contrasts: adaptive - static within modality (averaged over pressure where available)
contrast_table <- df_pid_cond %>%
  group_by(modality, ui_mode) %>%
  summarise(tp = mean(tp_mean, na.rm = TRUE),
            rt = mean(rt_mean, na.rm = TRUE),
            err = mean(error_rate, na.rm = TRUE),
            .groups = "drop") %>%
  pivot_wider(names_from = ui_mode, values_from = c(tp, rt, err)) %>%
  mutate(
    tp_diff_adapt_static = tp_adaptive - tp_static,
    rt_diff_adapt_static = rt_adaptive - rt_static,
    err_diff_adapt_static = err_adaptive - err_static
  ) %>%
  select(modality, tp_diff_adapt_static, rt_diff_adapt_static, err_diff_adapt_static)

tlx_snapshot <- df_raw %>%
  filter(!is.na(pid)) %>%
  group_by(pid, modality, ui_mode) %>%
  summarise(overall_tlx = mean(c_across(starts_with("tlx_")), na.rm = TRUE), .groups = "drop") %>%
  group_by(modality, ui_mode) %>%
  summarise(Mean_Overall_TLX = round(mean(overall_tlx, na.rm = TRUE), 1),
            .groups = "drop")

manip_snapshot <- df_raw %>%
  filter(!is.na(width_scale_factor)) %>%
  group_by(modality, ui_mode) %>%
  summarise(
    Mean_Width_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
    Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
    .groups = "drop"
  )

contrast_table %>%
  kable(caption = "RQ1 contrasts (adaptive - static)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

cat("\n*Note:* These contrasts are descriptive only; no inferential claims are made at N=`r n_distinct(df$pid)`.\n\n")

tlx_snapshot %>%
  kable(caption = "RQ2 snapshot: Overall TLX") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

manip_snapshot %>%
  kable(caption = "RQ3 manipulation check: width scaling") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

cat("\n*Note:* In the current build, width scaling was not activated; all recorded `width_scale_factor` values equal 1.0. RQ3 will be revisited once adaptive width scaling is enabled.\n\n")
```

## Key Findings

  * **Total Trials Analyzed:** `r nrow(df)` valid trials (correct responses, RT 150-6000ms)
  * **Total Trials Collected:** `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))`
  * **Overall Error Rate:** `r percent(round(1 - (sum(df$correct == TRUE | df$correct == "true" | df$correct == 1)/nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))), 3))`
  * **Mean Throughput:** `r round(mean(df_iso$TP, na.rm = TRUE), 2)` bits/s (SD = `r round(sd(df_iso$TP, na.rm = TRUE), 2)`)
  * **Mean Movement Time:** `r round(mean(df$rt_s, na.rm = TRUE), 3)`s (SD = `r round(sd(df$rt_s, na.rm = TRUE), 3)`s)

-----

# 2. Demographics

**Sample Size:** `r get_n_string(df_raw %>% distinct(pid))` participants.

```{r demographics}
# Ensure pid column exists
demog_raw <- df_raw
if ("participant_id" %in% names(demog_raw) && !"pid" %in% names(demog_raw)) {
  demog_raw <- demog_raw %>% rename(pid = participant_id)
}

demog_summary <- demog_raw %>%
  distinct(pid, .keep_all = TRUE) %>%
  select(pid, age, gender, gaming_hours_per_week, input_device) %>%
  filter(!is.na(pid))

# Overall summary
overall_stats <- demog_summary %>%
  summarise(
    `N` = n(),
    `Mean Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Age Range` = paste(round(min(age, na.rm=TRUE), 0), "-", round(max(age, na.rm=TRUE), 0)),
    `Mean Gaming (Hrs/Week)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    `SD Gaming` = round(sd(gaming_hours_per_week, na.rm=TRUE), 1)
  )

# By gender
gender_stats <- demog_summary %>%
  filter(!is.na(gender)) %>%
  group_by(gender) %>%
  summarise(
    Count = n(),
    `Avg Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Avg Gaming (Hrs)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    .groups = "drop"
  )

# Input device distribution
device_stats <- demog_summary %>%
  filter(!is.na(input_device)) %>%
  count(input_device, name = "Count") %>%
  mutate(Percentage = round(100 * Count / sum(Count), 1))

# Gaming status
gaming_status <- demog_summary %>%
  filter(!is.na(gaming_hours_per_week)) %>%
  summarise(
    median_gaming = round(median(gaming_hours_per_week, na.rm = TRUE), 1),
    pct_high_gamers = round(100 * mean(gaming_hours_per_week >= 5, na.rm = TRUE), 1),
    .groups = "drop"
  )


```

## Overall Demographics

```{r}
overall_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## By Gender

```{r}
gender_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## Input Device Distribution

```{r}
device_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

## Gaming Status

```{r}
cat("Participants were primarily non-gamers (median self-reported gaming = ", gaming_status$median_gaming, " hours/week; only ", gaming_status$pct_high_gamers, "% reported ≥5 hrs/week).\n")
```


-----

# 3. Primary Analysis: Throughput

**Research Question:** Does the Adaptive UI improve performance (Throughput) compared to Static, especially for Gaze?

**Sample Size:** `r get_n_string(df_iso)` participants with valid throughput data.

**Analysis Note:** We observe a large main effect of modality (hand > gaze) on throughput. Interaction effects are treated as exploratory.

## Summary Statistics

```{r tp-summary}
tp_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N_participants = n_distinct(pid),
    N_observations = n(),
    Mean = round(mean(TP, na.rm = TRUE), 2),
    SD = round(sd(TP, na.rm = TRUE), 2),
    Median = round(median(TP, na.rm = TRUE), 2),
    Q25 = round(quantile(TP, 0.25, na.rm = TRUE), 2),
    Q75 = round(quantile(TP, 0.75, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

tp_summary %>%
  kable(caption = paste0("Throughput (bits/s) by Condition (", get_n_string(df_iso), " participants)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-tp}
#| fig-cap: !expr 'paste0("Throughput by Modality and UI Mode (participant-level means). ", get_n_string(df_pid_cond %>% filter(!is.na(tp_mean))), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons.")'

# Prepare data for raincloud plot with mirrored half-violins
df_tp_plot <- df_pid_cond %>%
  filter(!is.na(tp_mean))

# Raincloud plot with mirrored half-violins
p_tp <- ggplot(df_tp_plot, aes(x = ui_mode, y = tp_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        # Static: half-violin extending LEFT (outward from left position)
        ggdist::stat_halfeye(
          data = df_tp_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        # Adaptive: half-violin extending RIGHT (outward from right position)
        ggdist::stat_halfeye(
          data = df_tp_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      # Fallback: full violins
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Thick black line connecting mean values between conditions
  {
    mean_data <- df_tp_plot %>%
      group_by(modality, pressure, ui_mode) %>%
      summarise(mean_value = mean(tp_mean, na.rm = TRUE), .groups = "drop") %>%
      pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
      filter(!is.na(mean_static), !is.na(mean_adaptive))
    
    if (nrow(mean_data) > 0) {
      geom_segment(
        data = mean_data,
        aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
        inherit.aes = FALSE,
        color = "black",
        linewidth = 0.9,
        alpha = 0.9
      )
    } else {
      NULL
    }
  } +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             ),
             drop = TRUE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Throughput (bits/s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_tp)
```

```{r plot-tp-emm, eval=exists("emm_tp") && !is.null(emm_tp)}
#| fig-cap: !expr 'paste0("Estimated Marginal Means for Throughput. ", get_n_string(df_iso), " participants (shown only when model fits and factors exist).")'
if (exists("emm_tp") && !is.null(emm_tp)) {
  emm_tp_df <- as.data.frame(emm_tp) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Check for CI column names (may vary by emmeans version/type)
  ci_lower <- if ("lower.CL" %in% names(emm_tp_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_tp_df)) "asymp.LCL" else NULL
  ci_upper <- if ("upper.CL" %in% names(emm_tp_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_tp_df)) "asymp.UCL" else NULL
  
  p_emm_tp <- ggplot(emm_tp_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.1, position = position_dodge(0.2)) +
    geom_point(size = 2.8, position = position_dodge(0.2))
  
  # Add error bars only if CI columns exist
  if (!is.null(ci_lower) && !is.null(ci_upper)) {
    p_emm_tp <- p_emm_tp + geom_errorbar(
      aes(ymin = .data[[ci_lower]], ymax = .data[[ci_upper]]), 
      width = 0.1, position = position_dodge(0.2)
    )
  }
  
  p_emm_tp <- p_emm_tp +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Throughput (bits/s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(legend.position = "top")
  
  print(p_emm_tp)
}
```

## Statistical Model Results

#### Planned Sample Size & Power

The throughput analysis was designed for a within-subjects 2×2×2 factorial (modality × UI mode × pressure). Our **primary effect of interest is the UI mode main effect** (adaptive vs static), which we expect to be medium in size (dz ≈ 0.4–0.6). Standard repeated-measures power calculations and guidelines (Cohen, 1988; Brysbaert, 2019) indicate that **N ≈ 50 participants** is sufficient for 80% power to detect dz ≈ 0.40. We therefore set **N = 48 (six complete Williams sequences)** as the primary design target, with the option to extend to **N = 64 (eight sequences)** if recruitment permits. Given the large number of trials per condition and the mixed-effects model (random intercepts per participant), this sample size is expected to provide **high power for UI mode and modality main effects**, while interactions are treated as secondary and more exploratory (Kumle et al., 2021; Matuschek et al., 2017).

```{r tp-model}
if (exists("model_tp") && !is.null(model_tp)) {
  cat("### Model: ", deparse(formula_tp$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_tp)) {
    cat("**Model Structure:** Random intercept only (participant-level random effects). The trial-level N (≈", diag_tp$n_trials, ") should not be mistaken for independent units in discussions of power; the effective N for inference is the number of participants (", diag_tp$n_participants, ").\n\n")
    cat("**Data Summary:** ", diag_tp$n_participants, " participants, ", diag_tp$n_trials, " trials, ", 
        diag_tp$n_conditions, " conditions, minimum ", diag_tp$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  if (!is.null(model_tp_note)) {
    cat("**Note:** ", model_tp_note, "\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_tp <- anova(model_tp, type = "III")
  print(anova_tp)
  
  # Note on interactions
  cat("\n**Analysis Note:** At N=", diag_tp$n_participants, ", 3-way interactions may be underpowered. Non-significant interaction effects should be treated as exploratory.\n\n")
  
  # Model summary
  cat("\n#### Model Summary\n")
  print(summary(model_tp))
  
  # Calculate effect sizes and generate APA-style written results
  anova_tp_df <- as.data.frame(anova_tp)
  anova_tp_df$partial_eta_sq <- mapply(calc_partial_eta_sq, 
                                        anova_tp_df$`F value`, 
                                        anova_tp_df$NumDF, 
                                        anova_tp_df$DenDF)
  
  # APA-style written results
  cat("\n#### Written Results (APA Style)\n\n")
  
  # Extract key effects
  modality_row <- anova_tp_df[grepl("^modality$", rownames(anova_tp_df), ignore.case = TRUE), ]
  ui_mode_row <- anova_tp_df[grepl("^ui_mode$|^ui.mode$", rownames(anova_tp_df), ignore.case = TRUE), ]
  mod_ui_int <- anova_tp_df[grepl("modality.*ui_mode|ui_mode.*modality", rownames(anova_tp_df), ignore.case = TRUE) & 
                            !grepl("pressure", rownames(anova_tp_df), ignore.case = TRUE), ]
  
  if (nrow(modality_row) > 0 && !is.na(modality_row$`F value`[1])) {
    F_mod <- modality_row$`F value`[1]
    df1_mod <- modality_row$NumDF[1]
    df2_mod <- modality_row$DenDF[1]
    p_mod <- modality_row$`Pr(>F)`[1]
    eta_mod <- modality_row$partial_eta_sq[1]
    
    cat("**Modality Effect:** A linear mixed-effects model revealed a ", 
        ifelse(p_mod < .05, "significant", "non-significant"),
        " main effect of input modality on throughput, ",
        format_F_apa(F_mod, df1_mod, df2_mod, p_mod),
        ", η²p = ", sprintf("%.3f", eta_mod), 
        " (", interpret_eta_sq(eta_mod), " effect). ", sep = "")
    
    # Add descriptive interpretation
        if (exists("emm_tp") && !is.null(emm_tp)) {
          emm_mod <- emmeans(model_tp, ~ modality)
          emm_mod_df <- as.data.frame(emm_mod)
          if (nrow(emm_mod_df) == 2) {
            # Safely extract means
            hand_mean <- safe_extract_mean(emm_mod_df, "modality", "hand")
            gaze_mean <- safe_extract_mean(emm_mod_df, "modality", "gaze")
            
            # Get CI column names
            ci_lower_col <- if ("lower.CL" %in% names(emm_mod_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_mod_df)) "asymp.LCL" else NULL
            ci_upper_col <- if ("upper.CL" %in% names(emm_mod_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_mod_df)) "asymp.UCL" else NULL
            
            # Extract CI values
            hand_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_lower_col) else NA_real_
            hand_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_upper_col) else NA_real_
            gaze_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_lower_col) else NA_real_
            gaze_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_upper_col) else NA_real_
            
            # Format and output
            hand_str <- format_mean_ci(hand_mean, hand_ci_lower, hand_ci_upper, "%.2f", " bits/s")
            gaze_str <- format_mean_ci(gaze_mean, gaze_ci_lower, gaze_ci_upper, "%.2f", " bits/s")
            
            cat("Hand input produced higher throughput (", hand_str, 
                ") than gaze input (", gaze_str, ").", sep = "")
          }
        }
    cat("\n\n")
  }
  
  if (nrow(ui_mode_row) > 0 && !is.na(ui_mode_row$`F value`[1])) {
    F_ui <- ui_mode_row$`F value`[1]
    df1_ui <- ui_mode_row$NumDF[1]
    df2_ui <- ui_mode_row$DenDF[1]
    p_ui <- ui_mode_row$`Pr(>F)`[1]
    eta_ui <- ui_mode_row$partial_eta_sq[1]
    
    cat("**UI Mode Effect:** The main effect of UI mode was ",
        ifelse(p_ui < .05, "significant", "non-significant"),
        ", ", format_F_apa(F_ui, df1_ui, df2_ui, p_ui),
        ", η²p = ", sprintf("%.3f", eta_ui),
        " (", interpret_eta_sq(eta_ui), " effect).", sep = "")
    
        if (exists("emm_tp") && !is.null(emm_tp)) {
          emm_ui <- emmeans(model_tp, ~ ui_mode)
          emm_ui_df <- as.data.frame(emm_ui)
          if (nrow(emm_ui_df) == 2) {
            # Safely extract means
            static_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "static")
            adaptive_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "adaptive")
            
            if (!is.na(static_mean) && !is.na(adaptive_mean)) {
              static_str <- format_mean_ci(static_mean, NA_real_, NA_real_, "%.2f", " bits/s")
              adaptive_str <- format_mean_ci(adaptive_mean, NA_real_, NA_real_, "%.2f", " bits/s")
              
              cat(" Adaptive UI (", adaptive_str, ") ",
                  ifelse(adaptive_mean > static_mean, "improved", "did not improve"),
                  " throughput compared to Static UI (", static_str, ").", sep = "")
            }
          }
        }
    cat("\n\n")
  }
  
  if (nrow(mod_ui_int) > 0 && !is.na(mod_ui_int$`F value`[1])) {
    F_int <- mod_ui_int$`F value`[1]
    df1_int <- mod_ui_int$NumDF[1]
    df2_int <- mod_ui_int$DenDF[1]
    p_int <- mod_ui_int$`Pr(>F)`[1]
    eta_int <- mod_ui_int$partial_eta_sq[1]
    
    cat("**Modality × UI Mode Interaction:** The interaction between modality and UI mode was ",
        ifelse(p_int < .05, "significant", "non-significant"),
        ", ", format_F_apa(F_int, df1_int, df2_int, p_int),
        ", η²p = ", sprintf("%.3f", eta_int),
        " (", interpret_eta_sq(eta_int), " effect).", sep = "")
    
    if (p_int >= .05) {
      cat(" This suggests that the effect of UI mode did not differ significantly between hand and gaze modalities.")
    } else {
      cat(" Follow-up simple effects analyses are recommended to interpret this interaction.")
    }
    cat("\n\n")
  }
  
  # Effect size: EMMs for hand vs gaze (collapsed over ui_mode and pressure)
  if (exists("emm_tp") && !is.null(emm_tp)) {
    cat("\n#### Effect Size: Hand vs. Gaze (Collapsed Over UI Mode and Pressure)\n")
    emm_modality <- emmeans(model_tp, ~ modality)
    emm_modality_df <- as.data.frame(emm_modality)
    ci_lower <- if ("lower.CL" %in% names(emm_modality_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_modality_df)) "asymp.LCL" else NULL
    ci_upper <- if ("upper.CL" %in% names(emm_modality_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_modality_df)) "asymp.UCL" else NULL
    
    emm_modality_table <- emm_modality_df %>%
      mutate(
        Modality = str_to_title(modality),
        `Mean TP (bits/s)` = round(emmean, 2),
        `95% CI Lower` = if (!is.null(ci_lower)) round(.data[[ci_lower]], 2) else NA_real_,
        `95% CI Upper` = if (!is.null(ci_upper)) round(.data[[ci_upper]], 2) else NA_real_
      ) %>%
      select(Modality, `Mean TP (bits/s)`, `95% CI Lower`, `95% CI Upper`)
    
    print(knitr::kable(emm_modality_table, caption = "Estimated Marginal Means for Throughput by Modality (collapsed over UI mode and pressure)"))
    
    # Compute difference
    if (nrow(emm_modality_df) == 2) {
      diff_tp <- emm_modality_df$emmean[emm_modality_df$modality == "hand"] - 
                 emm_modality_df$emmean[emm_modality_df$modality == "gaze"]
      cat("\n**Difference (Hand - Gaze):** ", round(diff_tp, 2), " bits/s\n\n")
    }
  }
  
  # Pairwise comparisons with effect sizes
  if (exists("pairs_tp") && !is.null(pairs_tp)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_tp_df <- as.data.frame(pairs_tp)
    
    # Calculate Cohen's d for pairwise comparisons
    # For mixed models, approximate d from t-statistic: d ≈ t * sqrt(2/n)
    # More accurate: use emmeans contrast with pooled SD
    if ("t.ratio" %in% names(pairs_tp_df)) {
      # Approximate Cohen's d from t-ratio (for paired comparisons)
      # d ≈ t / sqrt(n) for paired samples, but this is approximate
      # Better: use emmeans to get contrast with SE, then d = estimate / pooled_SD
      pairs_tp_df$cohens_d_approx <- pairs_tp_df$t.ratio / sqrt(diag_tp$n_participants)
      pairs_tp_df$effect_size <- sapply(pairs_tp_df$cohens_d_approx, interpret_cohens_d)
      
      # Create enhanced table
      pairs_tp_enhanced <- pairs_tp_df %>%
        mutate(
          `Cohen's d (approx)` = round(cohens_d_approx, 3),
          `Effect Size` = effect_size,
          `p-value` = format_p_apa(p.value)
        ) %>%
        select(contrast, estimate, SE, `Cohen's d (approx)`, `Effect Size`, `p-value`, df)
      
      print(knitr::kable(pairs_tp_enhanced %>% head(20), 
                         caption = "Pairwise Comparisons with Effect Sizes (Holm-adjusted p-values)"))
    } else {
      print(pairs_tp_df %>% head(20))
    }
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Throughput.**\n\n")
  
  if (!is.null(model_tp_error)) {
    cat("**Reason:** ", model_tp_error, "\n\n")
  }
  
  if (!is.null(diag_tp)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_tp$n_participants, "\n")
    cat("- Total trials: ", diag_tp$n_trials, "\n")
    cat("- Conditions: ", diag_tp$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_tp$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_tp$empty_conditions, "\n")
    
    if (length(diag_tp$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_tp$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_tp$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_tp$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 4. Movement Time Analysis (Core Confirmatory)

**Research Question:** How does movement time vary across conditions?

*This analysis is part of the core confirmatory battery for RQ1 and RQ3. Movement time is mathematically coupled with throughput (TP = ID/RT) and serves as a complementary performance metric.*

**Sample Size:** `r get_n_string(df)` participants with valid movement time data (correct trials only).

**Relationship to Throughput:** The RT patterns mirror throughput: hand is faster than gaze. Adaptive vs static and pressure do not show robust main effects on movement time at this N, consistent with the TP results.

## Summary Statistics

```{r rt-summary}
rt_summary <- df %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N_participants = n_distinct(pid),
    N_trials = n(),
    Mean = round(mean(rt_s, na.rm = TRUE), 3),
    SD = round(sd(rt_s, na.rm = TRUE), 3),
    Median = round(median(rt_s, na.rm = TRUE), 3),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

rt_summary %>%
  kable(caption = paste0("Movement Time (s) by Condition (", get_n_string(df), " participants)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-rt}
#| fig-cap: !expr 'paste0("Movement Time by Modality and UI Mode (participant-level means). ", get_n_string(df_pid_cond %>% filter(!is.na(rt_mean))), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons.")'

# Prepare data for raincloud plot
df_rt_plot <- df_pid_cond %>%
  filter(!is.na(rt_mean))

# Raincloud plot with mirrored half-violins
p_rt <- ggplot(df_rt_plot, aes(x = ui_mode, y = rt_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_rt_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_rt_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Thick black line connecting mean values between conditions
  {
    mean_data <- df_rt_plot %>%
      group_by(modality, pressure, ui_mode) %>%
      summarise(mean_value = mean(rt_mean, na.rm = TRUE), .groups = "drop") %>%
      pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
      filter(!is.na(mean_static), !is.na(mean_adaptive))
    
    if (nrow(mean_data) > 0) {
      geom_segment(
        data = mean_data,
        aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
        inherit.aes = FALSE,
        color = "black",
        linewidth = 0.9,
        alpha = 0.9
      )
    } else {
      NULL
    }
  } +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             ),
             drop = TRUE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Movement Time (s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_rt)
```

```{r plot-rt-emm, eval=exists("emm_rt") && !is.null(emm_rt)}
#| fig-cap: !expr 'paste0("Estimated Marginal Means for Movement Time. ", get_n_string(df), " participants (shown only when model fits and factors exist).")'
if (exists("emm_rt") && !is.null(emm_rt)) {
  emm_rt_df <- as.data.frame(emm_rt) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Check for CI column names (may vary by emmeans version/type)
  ci_lower <- if ("lower.CL" %in% names(emm_rt_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_rt_df)) "asymp.LCL" else NULL
  ci_upper <- if ("upper.CL" %in% names(emm_rt_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_rt_df)) "asymp.UCL" else NULL
  
  p_emm_rt <- ggplot(emm_rt_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.1, position = position_dodge(0.2)) +
    geom_point(size = 2.8, position = position_dodge(0.2))
  
  # Add error bars only if CI columns exist
  if (!is.null(ci_lower) && !is.null(ci_upper)) {
    p_emm_rt <- p_emm_rt + geom_errorbar(
      aes(ymin = .data[[ci_lower]], ymax = .data[[ci_upper]]), 
      width = 0.1, position = position_dodge(0.2)
    )
  }
  
  p_emm_rt <- p_emm_rt +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Movement Time (s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(legend.position = "top")
  
  print(p_emm_rt)
}
```

## Statistical Model Results

#### Planned Sample Size & Power

The log-RT analysis uses the same 2×2×2 within-subjects design and random-intercept LMM as the throughput analysis. Because throughput and RT are mathematically coupled (TP = ID/RT) and we expect **similar medium-sized UI mode and modality effects**, the **sample-size logic is identical**: **N = 48** is sufficient for detecting dz ≈ 0.40–0.50 differences with ≈0.80 power, and **N = 64** further strengthens power for smaller effects and interactions (Cohen, 1988). Trial-level modeling with many repeated observations per participant increases precision, but our power planning is intentionally conservative and based on participant-level effects rather than naïvely counting trials.

**Random Effects Structure:** All mixed models in this report use a random intercept for participants `(1 | pid)`, which is a conservative and stable baseline. We may test richer random-effects structures (e.g., `(1 + modality | pid)`) as a robustness check.

```{r rt-model}
if (exists("model_rt") && !is.null(model_rt)) {
  cat("### Model: ", deparse(formula_rt$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_rt)) {
    cat("**Model Structure:** Random intercept only (participant-level random effects). The trial-level N (≈", diag_rt$n_trials, ") should not be mistaken for independent units in discussions of power; the effective N for inference is the number of participants (", diag_rt$n_participants, ").\n\n")
    cat("**Data Summary:** ", diag_rt$n_participants, " participants, ", diag_rt$n_trials, " trials, ", 
        diag_rt$n_conditions, " conditions, minimum ", diag_rt$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  if (!is.null(model_rt_note)) {
    cat("**Note:** ", model_rt_note, "\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_rt <- anova(model_rt, type = "III")
  print(anova_rt)
  
  # Calculate effect sizes and generate APA-style written results
  anova_rt_df <- as.data.frame(anova_rt)
  anova_rt_df$partial_eta_sq <- mapply(calc_partial_eta_sq, 
                                        anova_rt_df$`F value`, 
                                        anova_rt_df$NumDF, 
                                        anova_rt_df$DenDF)
  
  # APA-style written results
  cat("\n#### Written Results (APA Style)\n\n")
  
  # Extract key effects
  modality_row <- anova_rt_df[grepl("^modality$", rownames(anova_rt_df), ignore.case = TRUE), ]
  ui_mode_row <- anova_rt_df[grepl("^ui_mode$|^ui.mode$", rownames(anova_rt_df), ignore.case = TRUE), ]
  mod_ui_int <- anova_rt_df[grepl("modality.*ui_mode|ui_mode.*modality", rownames(anova_rt_df), ignore.case = TRUE) & 
                            !grepl("pressure", rownames(anova_rt_df), ignore.case = TRUE), ]
  
  if (nrow(modality_row) > 0 && !is.na(modality_row$`F value`[1])) {
    F_mod <- modality_row$`F value`[1]
    df1_mod <- modality_row$NumDF[1]
    df2_mod <- modality_row$DenDF[1]
    p_mod <- modality_row$`Pr(>F)`[1]
    eta_mod <- modality_row$partial_eta_sq[1]
    
    cat("**Modality Effect:** A linear mixed-effects model on log-transformed movement time revealed a ", 
        ifelse(p_mod < .05, "significant", "non-significant"),
        " main effect of input modality, ",
        format_F_apa(F_mod, df1_mod, df2_mod, p_mod),
        ", η²p = ", sprintf("%.3f", eta_mod), 
        " (", interpret_eta_sq(eta_mod), " effect). ", sep = "")
    
    if (exists("emm_rt") && !is.null(emm_rt)) {
      emm_mod <- emmeans(model_rt, ~ modality, type = "response")
      emm_mod_df <- as.data.frame(emm_mod)
      if (nrow(emm_mod_df) == 2) {
        # Safely extract means (handles both "response" and "emmean" columns)
        hand_mean <- safe_extract_mean(emm_mod_df, "modality", "hand")
        gaze_mean <- safe_extract_mean(emm_mod_df, "modality", "gaze")
        
        # Get CI column names
        ci_lower_col <- if ("lower.CL" %in% names(emm_mod_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_mod_df)) "asymp.LCL" else NULL
        ci_upper_col <- if ("upper.CL" %in% names(emm_mod_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_mod_df)) "asymp.UCL" else NULL
        
        # Extract CI values
        hand_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_lower_col) else NA_real_
        hand_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_upper_col) else NA_real_
        gaze_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_lower_col) else NA_real_
        gaze_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_upper_col) else NA_real_
        
        # Format and output
        hand_str <- format_mean_ci(hand_mean, hand_ci_lower, hand_ci_upper, "%.3f", " s")
        gaze_str <- format_mean_ci(gaze_mean, gaze_ci_lower, gaze_ci_upper, "%.3f", " s")
        
        cat("Hand input produced faster movement times (", hand_str, 
            ") than gaze input (", gaze_str, ").", sep = "")
      }
    }
    cat("\n\n")
  }
  
  if (nrow(ui_mode_row) > 0 && !is.na(ui_mode_row$`F value`[1])) {
    F_ui <- ui_mode_row$`F value`[1]
    df1_ui <- ui_mode_row$NumDF[1]
    df2_ui <- ui_mode_row$DenDF[1]
    p_ui <- ui_mode_row$`Pr(>F)`[1]
    eta_ui <- ui_mode_row$partial_eta_sq[1]
    
    cat("**UI Mode Effect:** The main effect of UI mode on movement time was ",
        ifelse(p_ui < .05, "significant", "non-significant"),
        ", ", format_F_apa(F_ui, df1_ui, df2_ui, p_ui),
        ", η²p = ", sprintf("%.3f", eta_ui),
        " (", interpret_eta_sq(eta_ui), " effect).", sep = "")
    
        if (exists("emm_rt") && !is.null(emm_rt)) {
          emm_ui <- emmeans(model_rt, ~ ui_mode, type = "response")
          emm_ui_df <- as.data.frame(emm_ui)
          if (nrow(emm_ui_df) == 2) {
            # Safely extract means
            static_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "static")
            adaptive_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "adaptive")
            
            if (!is.na(static_mean) && !is.na(adaptive_mean)) {
              static_str <- format_mean_ci(static_mean, NA_real_, NA_real_, "%.3f", " s")
              adaptive_str <- format_mean_ci(adaptive_mean, NA_real_, NA_real_, "%.3f", " s")
              
              cat(" Adaptive UI (", adaptive_str, ") ",
                  ifelse(adaptive_mean < static_mean, "reduced", "did not reduce"),
                  " movement time compared to Static UI (", static_str, ").", sep = "")
            }
          }
        }
    cat("\n\n")
  }
  
  if (nrow(mod_ui_int) > 0 && !is.na(mod_ui_int$`F value`[1])) {
    F_int <- mod_ui_int$`F value`[1]
    df1_int <- mod_ui_int$NumDF[1]
    df2_int <- mod_ui_int$DenDF[1]
    p_int <- mod_ui_int$`Pr(>F)`[1]
    eta_int <- mod_ui_int$partial_eta_sq[1]
    
    cat("**Modality × UI Mode Interaction:** The interaction was ",
        ifelse(p_int < .05, "significant", "non-significant"),
        ", ", format_F_apa(F_int, df1_int, df2_int, p_int),
        ", η²p = ", sprintf("%.3f", eta_int),
        " (", interpret_eta_sq(eta_int), " effect).", sep = "")
    
    if (p_int >= .05) {
      cat(" The effect of UI mode did not differ significantly between modalities.")
    } else {
      cat(" Follow-up simple effects analyses are recommended.")
    }
    cat("\n\n")
  }
  
  # Pairwise comparisons
  if (exists("pairs_rt") && !is.null(pairs_rt)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_rt_df <- as.data.frame(pairs_rt)
    print(pairs_rt_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Movement Time.**\n\n")
  
  if (!is.null(model_rt_error)) {
    cat("**Reason:** ", model_rt_error, "\n\n")
  }
  
  if (!is.null(diag_rt)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_rt$n_participants, "\n")
    cat("- Total trials: ", diag_rt$n_trials, "\n")
    cat("- Conditions: ", diag_rt$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_rt$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_rt$empty_conditions, "\n")
    
    if (length(diag_rt$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_rt$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_rt$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_rt$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 5. Fitts' Law Modelling

**Research Question:** How well does the data fit Fitts' Law? (Linearity check).

#### Planned Sample Size & Power

Fitts' law analyses serve primarily to **validate the pointing task and modality differences**, not to test the core adaptation hypotheses. The ID effect on movement time is typically very large (R² > .70), and robust Fitts-law slopes are observable with as few as 10–20 participants in classic HCI work. In this study, **any final sample N ≥ 30** is more than sufficient for stable ID slopes; our planned **N = 48** places this analysis in an **over-powered, descriptive regime**. We therefore do not perform formal power calculations here and treat Fitts regression as a manipulation check and descriptive characterization of the dataset.

**Sample Size:** `r get_n_string(df_iso)` participants with valid throughput data.

*Flatter slopes indicate less sensitivity to difficulty (ballistic movement).*

```{r plot-fitts}
#| fig-cap: !expr 'paste0("Fitts Law Regression (Movement Time vs Effective Index of Difficulty). ", get_n_string(df_iso), " participants. The effective index of difficulty (IDe) is calculated using the effective target width (We) derived from the spatial distribution of selection endpoints. Shaded regions around regression lines represent 95% confidence intervals. Linear regression fits are shown separately for each modality and UI mode combination.")'
# Aggregate for regression plot
fitts_model <- df_iso %>%
  group_by(modality, ui_mode, IDe) %>%
  summarise(
    MT = mean(MT_avg, na.rm = TRUE),
    MT_se = sd(MT_avg, na.rm = TRUE) / sqrt(n()),
    N = n(),
    .groups = "drop"
  ) %>%
  filter(!is.na(IDe), !is.na(MT))

# Fit linear models for each condition
fitts_fits <- fitts_model %>%
  group_by(modality, ui_mode) %>%
  do(model = tryCatch(lm(MT ~ IDe, data = .), error = function(e) NULL)) %>%
  filter(!is.null(model)) %>%
  mutate(
    r_squared = round(summary(model)$r.squared, 3),
    slope = round(coef(model)[2], 3),
    intercept = round(coef(model)[1], 3)
  )

ggplot(fitts_model, aes(x = IDe, y = MT, color = ui_mode)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  facet_grid(. ~ modality, drop = TRUE) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
  labs(
    x = "Index of Difficulty (bits)",
    y = "Movement Time (s)",
    color = "UI Mode"
  ) +
  theme_light(base_size = 14) +
  theme(legend.position = "top")
```

```{r}
# Display R² values
if (nrow(fitts_fits) > 0) {
  cat("\n### Model Fit Statistics\n")
  fitts_fits %>%
    select(modality, ui_mode, r_squared, slope, intercept) %>%
    kable(caption = paste0("Linear Regression: MT ~ IDe (", get_n_string(df_iso), " participants)")) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```

-----

# 6. Error Rate Analysis (Core Confirmatory)

**Research Question:** How do error rates differ across conditions?

*This analysis is part of the core confirmatory battery for RQ1 and RQ3.*

**Sample Size:** `r get_n_string(df_all_trials)` participants with all trials (correct + incorrect).

```{r error-analysis}
#| fig-cap: !expr 'paste0("Error Rate by Modality and UI Mode (participant-level means). ", get_n_string(df_pid_cond %>% filter(!is.na(error_rate))), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons.")'
# Calculate condition-level summary
error_summary <- df_pid_cond %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Participants = n_distinct(pid),
    Mean_Error_Rate = round(100 * mean(error_rate, na.rm = TRUE), 2),
    SD_Error_Rate = round(100 * sd(error_rate, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

error_summary %>%
  kable(caption = paste0("Error Rates by Condition (", get_n_string(df_all_trials), " participants)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# Compute overall and modality-specific error rates for summary text
overall_error_rate <- mean(!df_all_trials$is_correct, na.rm = TRUE)
hand_error_rate <- df_all_trials %>%
  filter(modality == "hand") %>%
  summarise(rate = mean(!is_correct, na.rm = TRUE)) %>%
  pull(rate)
gaze_error_rate <- df_all_trials %>%
  filter(modality == "gaze") %>%
  summarise(rate = mean(!is_correct, na.rm = TRUE)) %>%
  pull(rate)

cat("\n**Error Rate Summary:** Overall error rate was ", round(100 * overall_error_rate, 1), "%. Errors were concentrated in gaze conditions (", round(100 * gaze_error_rate, 1), "%), while hand remained near ", round(100 * hand_error_rate, 1), "%.\n\n")

# Prepare data for raincloud plot
df_err_plot <- df_pid_cond %>%
  filter(!is.na(error_rate)) %>%
  mutate(Error_Rate = 100 * error_rate)

# Raincloud plot with mirrored half-violins
p_err <- ggplot(df_err_plot, aes(x = ui_mode, y = Error_Rate, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_err_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_err_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Thick black line connecting mean values between conditions
  {
    mean_data <- df_err_plot %>%
      group_by(modality, pressure, ui_mode) %>%
      summarise(mean_value = mean(Error_Rate, na.rm = TRUE), .groups = "drop") %>%
      pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
      filter(!is.na(mean_static), !is.na(mean_adaptive))
    
    if (nrow(mean_data) > 0) {
      geom_segment(
        data = mean_data,
        aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
        inherit.aes = FALSE,
        color = "black",
        linewidth = 0.9,
        alpha = 0.9
      )
    } else {
      NULL
    }
  } +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             ),
             drop = TRUE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Error Rate (%)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )

print(p_err)
```

## Statistical Model Results

#### Planned Sample Size & Power

For the error-rate analysis we fit a binomial GLMM with random intercepts per participant. The key contrasts are again **UI mode** and **modality**, where we expect odds-ratio effects in the **small-to-medium range** (e.g., OR ≈ 0.7–0.8 for adaptive vs static, and OR ≈ 2–3 for gaze vs hand). Binary outcomes with relatively low error rates (≈10–15%) typically require **more participants than continuous outcomes** for stable mixed-effects estimation (Kumle et al., 2021). For this analysis, we therefore treat **N = 64** as a **"good" target** that yields comfortable power for medium effects, while **N = 48** remains adequate but somewhat less stable, especially for interaction terms and rare error types. Error-based interaction effects are interpreted as exploratory, even at N = 64.

```{r error-model}
if (exists("model_err") && !is.null(model_err)) {
  cat("### Model: ", deparse(formula_err$formula), "\n\n")
  
  # Show diagnostics
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Model Structure:** Random intercept only (participant-level random effects). The trial-level N (≈", diag_err$n_trials, ") should not be mistaken for independent units in discussions of power; the effective N for inference is the number of participants (", diag_err$n_participants, ").\n\n")
    cat("**Data Summary:** ", diag_err$n_participants, " participants, ", diag_err$n_trials, " trials, ", 
        diag_err$n_conditions, " conditions, minimum ", diag_err$min_trials_per_condition, " trials per condition.\n")
    cat("**Overall Error Rate:** ", round(error_rate * 100, 1), "%\n\n")
  }
  
  if (!is.null(model_err_note)) {
    cat("**Note:** ", model_err_note, "\n\n")
  }
  
  # ANOVA table
  if (requireNamespace("car", quietly = TRUE)) {
    library(car)
    cat("#### ANOVA Table\n")
    print(Anova(model_err, type = "III"))
  }
  
  # Pairwise comparisons
  if (exists("pairs_err") && !is.null(pairs_err)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_err_df <- as.data.frame(pairs_err)
    print(pairs_err_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Error Rate.**\n\n")
  
  if (!is.null(model_err_error)) {
    cat("**Reason:** ", model_err_error, "\n\n")
  }
  
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_err$n_participants, "\n")
    cat("- Total trials: ", diag_err$n_trials, "\n")
    cat("- Conditions: ", diag_err$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_err$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_err$empty_conditions, "\n")
    cat("- Overall error rate: ", round(error_rate * 100, 1), "%\n")
    
    if (length(diag_err$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_err$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_err$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_err$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 7. Accuracy & Gaze Dynamics

**Sample Size:** `r get_n_string(df_iso)` participants with valid accuracy data.

## Effective Width ($W_e$) (Exploratory/Descriptive)

*This analysis is exploratory/descriptive only. No formal inferential tests are run in this section.*

#### Planned Sample Size & Power

Effective width (We) is analyzed at the participant × condition level with a Gaussian LMM. We expect **medium effects of modality** (gaze > hand) and **small-to-medium effects of UI mode** (adaptive slightly improving spatial precision). For within-subject effects of this magnitude, **N ≈ 48** is sufficient for ≈0.80 power (dz ≈ 0.4–0.5) according to standard repeated-measures power guidelines (Cohen, 1988). We therefore treat **N = 48** as a good target for We, with **N = 64** mainly helping if UI-mode effects turn out closer to dz ≈ 0.3.

*Lower $W_e$ indicates tighter shot grouping (higher precision).*

```{r we-summary}
#| tbl-cap: !expr 'paste0("Effective Width (px) by Condition (", get_n_string(df_iso), " participants)")'

we_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N_participants = n_distinct(pid),
    Mean_We = round(mean(We, na.rm = TRUE), 2),
    SD_We = round(sd(We, na.rm = TRUE), 2),
    .groups = "drop"
  )

knitr::kable(we_summary)
```

Effective target width was broadly similar between Static and Adaptive within each modality; gaze showed slightly larger We overall, consistent with higher variability in endpoint location.

```{r plot-we}
#| fig-cap: !expr 'paste0("Effective Target Width (Accuracy) by Modality and UI Mode. ", get_n_string(df_iso %>% group_by(pid, modality, ui_mode, pressure) %>% summarise(We_mean = mean(We, na.rm = TRUE), .groups = "drop") %>% filter(!is.na(We_mean))), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower values indicate tighter shot grouping and higher precision.")'

# Aggregate to participant-level means
df_we_plot <- df_iso %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(We_mean = mean(We, na.rm = TRUE), .groups = "drop") %>%
  filter(!is.na(We_mean))

# Raincloud plot for Effective Width
ggplot(df_we_plot, aes(x = ui_mode, y = We_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_we_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_we_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Thick black line connecting mean values between conditions
  {
    mean_data <- df_we_plot %>%
      group_by(modality, pressure, ui_mode) %>%
      summarise(mean_value = mean(We_mean, na.rm = TRUE), .groups = "drop") %>%
      pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
      filter(!is.na(mean_static), !is.na(mean_adaptive))
    
    if (nrow(mean_data) > 0) {
      geom_segment(
        data = mean_data,
        aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
        inherit.aes = FALSE,
        color = "black",
        linewidth = 0.9,
        alpha = 0.9
      )
    } else {
      NULL
    }
  } +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             ),
             drop = TRUE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Effective Width (px)",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )
```

## Endpoint Accuracy Scatter Plot

*Visualization of endpoint errors relative to target center. Each point represents one trial's endpoint position.*

```{r plot-accuracy-scatter}
#| fig-width: 12
#| fig-height: 8
#| fig-cap: !expr 'paste0("Endpoint Accuracy Scatter Plot for Gaze Modality. ", get_n_string(df %>% filter(str_to_lower(modality) == "gaze", !is.na(endpoint_x), !is.na(endpoint_y))), " participants. Each point represents one trial endpoint position relative to the target center (0,0). The red dashed circle shows the approximate target size. Points closer to the center indicate better accuracy. Dotted lines indicate zero error in X and Y directions. Faceted by pressure condition.")'
# Calculate endpoint errors relative to target center
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  # Calculate target radius (approximate from W, assuming circular targets)
  target_radius <- ifelse("W" %in% names(gaze_accuracy), 
                          mean(gaze_accuracy$W, na.rm = TRUE) / 2, 
                          20)
  
  # Create circle data for target visualization
  circle_data <- data.frame(
    x = target_radius * cos(seq(0, 2*pi, length.out = 100)),
    y = target_radius * sin(seq(0, 2*pi, length.out = 100))
  )
  
  p_accuracy <- ggplot(gaze_accuracy, aes(x = err_x, y = err_y, color = UI)) +
    # Draw target circle (centered at 0,0)
    geom_path(data = circle_data, aes(x = x, y = y), 
              inherit.aes = FALSE, color = "red", linetype = "dashed", linewidth = 1) +
    # Scatter points
    geom_point(alpha = 0.5, size = 2) +
    # Reference lines
    geom_vline(xintercept = 0, color = "grey70", linetype = "dotted") +
    geom_hline(yintercept = 0, color = "grey70", linetype = "dotted") +
    # Facet by pressure
    facet_wrap(~PressureLabel) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    coord_fixed(ratio = 1, xlim = c(-50, 50), ylim = c(-50, 50)) +
    labs(
      x = "Error X (px)",
      y = "Error Y (px)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top")
  
  print(p_accuracy)
} else {
  cat("⚠ No gaze accuracy data available for scatter plot.\n")
}
```

```{r accuracy-summary}
# Summary statistics for accuracy scatter plot
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  accuracy_summary <- gaze_accuracy %>%
    group_by(ui_mode, pressure) %>%
    summarise(
      N = n(),
      Mean_Error = round(mean(err_distance, na.rm = TRUE), 2),
      SD_Error = round(sd(err_distance, na.rm = TRUE), 2),
      Median_Error = round(median(err_distance, na.rm = TRUE), 2),
      .groups = "drop"
    )
  
  accuracy_summary %>%
    kable(caption = "Endpoint Error Distance (px) for Gaze Modality") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
} else {
  cat("⚠ No gaze accuracy data available for summary table.\n")
}
```

## The "Midas Touch" Struggle

#### Planned Sample Size & Power

Target re-entries are count-like and somewhat noisy, but we again analyze participant-level averages with an LMM (or, if needed, a Poisson GLMM). We anticipate **medium modality effects** (more re-entries for gaze) and **small-to-medium UI-mode effects** (fewer re-entries under adaptation). Given the noisier nature of this metric, a slightly larger sample is desirable if you want to treat it as confirmatory. We therefore treat **N = 48** as **adequate but exploratory** and **N = 64** as a **"good" sample size** for detecting medium within-subject effects in re-entry counts. Power reasoning follows the same logic as other continuous repeated-measures outcomes, tempered by mixed-model guidance from Kumle et al. (2021).

*Target Re-entries measure how often the cursor drifted out of the target before selection.*

Re-entries are interpreted here as a proxy for control stability; higher counts suggest more corrective movements. We will revisit this metric in the control-theory analyses (Section 10).

```{r reentry-summary}
# Check if hand modality has any non-zero reentry values
hand_has_reentry_data <- df_iso %>%
  filter(modality == "hand") %>%
  summarise(has_nonzero = any(!is.na(reentries) & reentries > 0)) %>%
  pull(has_nonzero)

if (!hand_has_reentry_data) {
  cat("⚠ **Note:** Hand modality shows zero re-entries because the legacy `target_reentry_count`\n")
  cat("   was only computed for gaze. Future data may compute re-entries from trajectory\n")
  cat("   or LBA timing fields for both modalities.\n\n")
}

reentry_summary <- df_iso %>%
  filter(!is.na(reentries)) %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N_participants = n_distinct(pid),
    Mean_Reentries = round(mean(reentries, na.rm = TRUE), 2),
    SD_Reentries = round(sd(reentries, na.rm = TRUE), 2),
    .groups = "drop"
  )

reentry_summary %>%
  kable(caption = paste0("Target Re-entries by Condition (", get_n_string(df_iso %>% filter(!is.na(reentries))), " participants)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-reentry}
#| fig-cap: !expr 'paste0("Target Re-entries (Control Stability) by Modality and UI Mode. ", get_n_string(df_iso %>% filter(!is.na(reentries)) %>% group_by(pid, modality, ui_mode, pressure) %>% summarise(reentries_mean = mean(reentries, na.rm = TRUE), .groups = "drop") %>% filter(!is.na(reentries_mean))), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower values are better.")'

# Aggregate to participant-level means
df_reentry_plot <- df_iso %>%
  filter(!is.na(reentries)) %>%
  group_by(pid, modality, ui_mode, pressure) %>%
  summarise(reentries_mean = mean(reentries, na.rm = TRUE), .groups = "drop") %>%
  filter(!is.na(reentries_mean))

# Raincloud plot for Re-entries
ggplot(df_reentry_plot, aes(x = ui_mode, y = reentries_mean, fill = ui_mode, color = ui_mode)) +
  # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
  {
    if (has_ggdist) {
      list(
        ggdist::stat_halfeye(
          data = df_reentry_plot %>% filter(ui_mode == "static"),
          aes(fill = ui_mode),
          side = "left",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = 1.3,
          point_colour = NA
        ),
        ggdist::stat_halfeye(
          data = df_reentry_plot %>% filter(ui_mode == "adaptive"),
          aes(fill = ui_mode),
          side = "right",
          alpha = 0.4,
          width = 0.35,
          .width = 0,
          justification = -0.3,
          point_colour = NA
        )
      )
    } else {
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0),
        color = NA
      )
    }
  } +
  # Boxplots inside violins (light gray for visibility)
  geom_boxplot(
    width = 0.15,
    alpha = 0.9,
    outlier.shape = NA,
    position = position_dodge(width = 0),
    fill = "grey90",
    color = "grey70",
    linewidth = 0.7,
    show.legend = FALSE
  ) +
  # Individual participant points (in columns, no jitter)
  geom_point(
    alpha = 0.5,
    size = 1.5,
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Connecting lines (between paired conditions)
  geom_line(
    aes(group = pid),
    alpha = 0.3,
    linewidth = 0.4,
    color = "grey60",
    position = position_dodge(width = 0),
    show.legend = FALSE
  ) +
  # Thick black line connecting mean values between conditions
  {
    mean_data <- df_reentry_plot %>%
      group_by(modality, pressure, ui_mode) %>%
      summarise(mean_value = mean(reentries_mean, na.rm = TRUE), .groups = "drop") %>%
      pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
      filter(!is.na(mean_static), !is.na(mean_adaptive))
    
    if (nrow(mean_data) > 0) {
      geom_segment(
        data = mean_data,
        aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
        inherit.aes = FALSE,
        color = "black",
        linewidth = 0.9,
        alpha = 0.9
      )
    } else {
      NULL
    }
  } +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             ),
             drop = TRUE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Avg Re-entries per Trial",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
  )
```

-----

# 8. Workload (NASA-TLX) (Core Confirmatory)

*Subjective workload scores (lower is better).*

**Research Question:** How does subjective workload differ across conditions? Does Adaptive UI reduce workload?

*This analysis is part of the core confirmatory battery for RQ2 and RQ3.*

**Metric Definition:** We use the unweighted NASA-TLX, computed as the mean of the six subscales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration). Each subscale is rated on a 0-100 scale, and the overall TLX score is the arithmetic mean of all six subscales. Lower values indicate lower subjective workload.

**Sample Size:** `r get_n_string(df_raw %>% filter(!is.na(pid), !is.na(tlx_mental)))` participants with TLX data.

```{r plot-tlx}
#| fig-cap: !expr 'paste0("NASA-TLX Workload Scores by Modality and UI Mode. ", get_n_string(df_raw %>% filter(!is.na(pid), !is.na(tlx_mental))), " participants. Scores range from 0-100, where lower values indicate lower subjective workload. The six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration) are shown separately. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles.")'
# Check if TLX columns exist
tlx_cols <- c("tlx_mental", "tlx_physical", "tlx_temporal", "tlx_performance", "tlx_effort", "tlx_frustration")

if(all(tlx_cols %in% names(df_raw))) {
  # Block-level aggregation (if block_number exists), else participant-level
  df_tlx <- df_raw %>%
    filter(!is.na(pid)) %>%
    {
      if ("block_number" %in% names(.)) {
        group_by(., pid, modality, ui_mode, block_number)
      } else {
        group_by(., pid, modality, ui_mode)
      }
    } %>%
    summarise(across(starts_with("tlx_"), mean, na.rm = TRUE), .groups = "drop") %>%
    pivot_longer(cols = starts_with("tlx_"), names_to = "Scale", values_to = "Score") %>%
    mutate(
      Scale = str_remove(Scale, "tlx_"),
      Scale = str_to_title(Scale),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Summary table
  tlx_summary <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(
      N_participants = n_distinct(pid),
      Mean = round(mean(Score, na.rm = TRUE), 1),
      SD = round(sd(Score, na.rm = TRUE), 1),
      .groups = "drop"
    )
  
  tlx_summary %>%
    kable(caption = paste0("NASA-TLX Scores by Condition (", get_n_string(df_raw %>% filter(!is.na(pid), !is.na(tlx_mental))), " participants, block-level where available)")) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
  # Visualization (one concise view)
  p1 <- ggplot(df_tlx, aes(x = ui_mode, y = Score, color = ui_mode, group = pid)) +
    geom_line(alpha = 0.25) +
    geom_point(alpha = 0.6, size = 1.8) +
    # Thick black line connecting mean values between conditions
    {
      mean_data <- df_tlx %>%
        group_by(modality, Scale, ui_mode) %>%
        summarise(mean_value = mean(Score, na.rm = TRUE), .groups = "drop") %>%
        pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
        filter(!is.na(mean_static), !is.na(mean_adaptive))
      
      if (nrow(mean_data) > 0) {
        geom_segment(
          data = mean_data,
          aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
          inherit.aes = FALSE,
          color = "black",
          linewidth = 0.9,
          alpha = 0.9
        )
      } else {
        NULL
      }
    } +
    facet_grid(modality ~ Scale,
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x)),
                 Scale = function(x) x
               ),
               drop = TRUE) +
    scale_color_manual(values = custom_palette_2,
                       labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    labs(
      y = "TLX Score (0-100)",
      x = "UI Mode",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 11),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank()
    )
  
  print(p1)
  
} else {
  cat("⚠ TLX Data not found in trial_data.csv\n")
  cat("Expected columns:", paste(tlx_cols, collapse = ", "), "\n")
  cat("Available columns with 'tlx':", 
      paste(grep("tlx", names(df_raw), value = TRUE, ignore.case = TRUE), collapse = ", "), "\n")
}
```

  
```{r plot-tlx-stacked}
#| fig-cap: !expr 'paste0("NASA-TLX Workload Components (Stacked Bar Chart). ", get_n_string(df_raw %>% filter(!is.na(pid), !is.na(tlx_mental))), " participants. Total height represents overall workload, with each colored segment representing one of the six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration). Lower total height indicates lower overall subjective workload.")'
if(all(tlx_cols %in% names(df_raw)) && exists("df_tlx")) {
  # Stacked bar chart (inspired by Python script)
  df_tlx_stacked <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(Mean_Score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
    mutate(
      Modality = str_to_title(modality),
      UI = str_to_title(ui_mode),
      Condition = paste(Modality, UI, sep = "\n")
    )
  
  # Create stacked bar
  p3 <- ggplot(df_tlx_stacked, aes(x = Condition, y = Mean_Score, fill = Scale)) +
    geom_bar(stat = "identity", position = "stack", alpha = 0.8) +
    scale_fill_manual(values = custom_palette_multi) +
    labs(
      y = "TLX Score (0-100)",
      x = "Condition",
      fill = "TLX Scale"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "right",
      axis.text.x = element_text(angle = 0, hjust = 0.5)
    ) +
    guides(fill = guide_legend(ncol = 1))
  
  print(p3)
}
```

## Statistical Model: Overall TLX

#### Planned Sample Size & Power

NASA-TLX scores (overall and subscales) are collected at the block level and analyzed with an LMM (random intercepts per participant; fixed effects for modality and UI mode). TLX scores tend to be reasonably reliable, and we expect **medium effects** for both modality (gaze > hand) and UI mode (adaptive < static), especially on Physical Demand and Frustration. For within-subject designs with medium effects, **≈40–50 participants** typically provide ≥0.80 power (Brysbaert, 2019). We therefore treat **N = 48** as a **good, pre-planned N** for TLX analyses. An increase to **N = 64** would mostly refine confidence intervals and interaction estimates rather than change the main power conclusions.

**Random Effects Structure:** All mixed models in this report use a random intercept for participants `(1 | pid)`, which is a conservative and stable baseline. We may test richer random-effects structures (e.g., `(1 + modality | pid)`) as a robustness check.

```{r tlx-model}
# Compute overall TLX (average of all subscales) and fit mixed model
if(all(tlx_cols %in% names(df_raw))) {
  # Prepare data for modeling: compute overall TLX per participant per condition
  df_tlx_overall <- df_raw %>%
    filter(!is.na(pid)) %>%
    {
      if ("block_number" %in% names(.)) {
        group_by(., pid, modality, ui_mode, block_number)
      } else {
        group_by(., pid, modality, ui_mode)
      }
    } %>%
    summarise(
      overall_tlx = mean(c_across(starts_with("tlx_")), na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pid = factor(pid)
    )
  
  if (nrow(df_tlx_overall) > 0 && n_distinct(df_tlx_overall$pid) > 1) {
    # Fit mixed model: overall TLX ~ modality * ui_mode + (1 | pid)
    model_tlx <- tryCatch({
      lmer(overall_tlx ~ modality * ui_mode + (1 | pid),
           data = df_tlx_overall, REML = FALSE,
           control = lmerControl(optimizer = "bobyqa"))
    }, error = function(e) {
      cat("⚠ **TLX model fitting failed:** ", e$message, "\n\n")
      NULL
    })
    
    if (!is.null(model_tlx)) {
      cat("### Model: overall_tlx ~ modality * ui_mode + (1 | pid)\n\n")
      cat("**Data Summary:** ", n_distinct(df_tlx_overall$pid), " participants, ", nrow(df_tlx_overall), " observations.\n\n")
      
      # ANOVA table
      cat("#### ANOVA Table\n")
      anova_tlx <- anova(model_tlx, type = "III")
      print(anova_tlx)
      
      # Calculate effect sizes and generate APA-style written results
      anova_tlx_df <- as.data.frame(anova_tlx)
      anova_tlx_df$partial_eta_sq <- mapply(calc_partial_eta_sq, 
                                            anova_tlx_df$`F value`, 
                                            anova_tlx_df$NumDF, 
                                            anova_tlx_df$DenDF)
      
      # APA-style written results
      cat("\n#### Written Results (APA Style)\n\n")
      
      # Extract key effects
      modality_row <- anova_tlx_df[grepl("^modality$", rownames(anova_tlx_df), ignore.case = TRUE), ]
      ui_mode_row <- anova_tlx_df[grepl("^ui_mode$|^ui.mode$", rownames(anova_tlx_df), ignore.case = TRUE), ]
      mod_ui_int <- anova_tlx_df[grepl("modality.*ui_mode|ui_mode.*modality", rownames(anova_tlx_df), ignore.case = TRUE), ]
      
      if (nrow(modality_row) > 0 && !is.na(modality_row$`F value`[1])) {
        F_mod <- modality_row$`F value`[1]
        df1_mod <- modality_row$NumDF[1]
        df2_mod <- modality_row$DenDF[1]
        p_mod <- modality_row$`Pr(>F)`[1]
        eta_mod <- modality_row$partial_eta_sq[1]
        
        cat("**Modality Effect:** A linear mixed-effects model revealed a ", 
            ifelse(p_mod < .05, "significant", "non-significant"),
            " main effect of input modality on overall NASA-TLX workload, ",
            format_F_apa(F_mod, df1_mod, df2_mod, p_mod),
            ", η²p = ", sprintf("%.3f", eta_mod), 
            " (", interpret_eta_sq(eta_mod), " effect). ", sep = "")
        
        if (exists("emm_tlx") && !is.null(emm_tlx)) {
          emm_mod <- emmeans(model_tlx, ~ modality)
          emm_mod_df <- as.data.frame(emm_mod)
          if (nrow(emm_mod_df) == 2) {
            # Safely extract means
            hand_mean <- safe_extract_mean(emm_mod_df, "modality", "hand")
            gaze_mean <- safe_extract_mean(emm_mod_df, "modality", "gaze")
            
            # Get CI column names
            ci_lower_col <- if ("lower.CL" %in% names(emm_mod_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_mod_df)) "asymp.LCL" else NULL
            ci_upper_col <- if ("upper.CL" %in% names(emm_mod_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_mod_df)) "asymp.UCL" else NULL
            
            # Extract CI values
            hand_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_lower_col) else NA_real_
            hand_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "hand", ci_upper_col) else NA_real_
            gaze_ci_lower <- if (!is.null(ci_lower_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_lower_col) else NA_real_
            gaze_ci_upper <- if (!is.null(ci_upper_col)) safe_extract_ci(emm_mod_df, "modality", "gaze", ci_upper_col) else NA_real_
            
            # Format and output
            hand_str <- format_mean_ci(hand_mean, hand_ci_lower, hand_ci_upper, "%.1f", "")
            gaze_str <- format_mean_ci(gaze_mean, gaze_ci_lower, gaze_ci_upper, "%.1f", "")
            
            cat("Gaze input produced higher workload (", gaze_str, 
                ") than hand input (", hand_str, ").", sep = "")
          }
        }
        cat("\n\n")
      }
      
      if (nrow(ui_mode_row) > 0 && !is.na(ui_mode_row$`F value`[1])) {
        F_ui <- ui_mode_row$`F value`[1]
        df1_ui <- ui_mode_row$NumDF[1]
        df2_ui <- ui_mode_row$DenDF[1]
        p_ui <- ui_mode_row$`Pr(>F)`[1]
        eta_ui <- ui_mode_row$partial_eta_sq[1]
        
        cat("**UI Mode Effect:** The main effect of UI mode on workload was ",
            ifelse(p_ui < .05, "significant", "non-significant"),
            ", ", format_F_apa(F_ui, df1_ui, df2_ui, p_ui),
            ", η²p = ", sprintf("%.3f", eta_ui),
            " (", interpret_eta_sq(eta_ui), " effect).", sep = "")
        
        if (exists("emm_tlx") && !is.null(emm_tlx)) {
          emm_ui <- emmeans(model_tlx, ~ ui_mode)
          emm_ui_df <- as.data.frame(emm_ui)
          if (nrow(emm_ui_df) == 2) {
            # Safely extract means
            static_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "static")
            adaptive_mean <- safe_extract_mean(emm_ui_df, "ui_mode", "adaptive")
            
            if (!is.na(static_mean) && !is.na(adaptive_mean)) {
              static_str <- format_mean_ci(static_mean, NA_real_, NA_real_, "%.1f", "")
              adaptive_str <- format_mean_ci(adaptive_mean, NA_real_, NA_real_, "%.1f", "")
              
              cat(" Adaptive UI (", adaptive_str, ") ",
                  ifelse(adaptive_mean < static_mean, "reduced", "did not reduce"),
                  " workload compared to Static UI (", static_str, ").", sep = "")
            }
          }
        }
        cat("\n\n")
      }
      
      if (nrow(mod_ui_int) > 0 && !is.na(mod_ui_int$`F value`[1])) {
        F_int <- mod_ui_int$`F value`[1]
        df1_int <- mod_ui_int$NumDF[1]
        df2_int <- mod_ui_int$DenDF[1]
        p_int <- mod_ui_int$`Pr(>F)`[1]
        eta_int <- mod_ui_int$partial_eta_sq[1]
        
        cat("**Modality × UI Mode Interaction:** The interaction was ",
            ifelse(p_int < .05, "significant", "non-significant"),
            ", ", format_F_apa(F_int, df1_int, df2_int, p_int),
            ", η²p = ", sprintf("%.3f", eta_int),
            " (", interpret_eta_sq(eta_int), " effect).", sep = "")
        
        if (p_int >= .05) {
          cat(" The effect of UI mode on workload did not differ significantly between modalities.")
        } else {
          cat(" Follow-up simple effects analyses are recommended.")
        }
        cat("\n\n")
      }
      
      # EMMs with 95% CIs
      if (requireNamespace("emmeans", quietly = TRUE)) {
        emm_tlx <- tryCatch({
          emmeans(model_tlx, ~ modality * ui_mode)
        }, error = function(e) {
          cat("⚠ **Could not compute EMMs:** ", e$message, "\n\n")
          NULL
        })
        
        if (!is.null(emm_tlx)) {
          cat("\n#### Estimated Marginal Means (Overall TLX by Modality × UI Mode)\n")
          emm_tlx_df <- as.data.frame(emm_tlx)
          ci_lower <- if ("lower.CL" %in% names(emm_tlx_df)) "lower.CL" else if ("asymp.LCL" %in% names(emm_tlx_df)) "asymp.LCL" else NULL
          ci_upper <- if ("upper.CL" %in% names(emm_tlx_df)) "upper.CL" else if ("asymp.UCL" %in% names(emm_tlx_df)) "asymp.UCL" else NULL
          
          emm_tlx_table <- emm_tlx_df %>%
            mutate(
              Modality = str_to_title(modality),
              `UI Mode` = str_to_title(ui_mode),
              `Mean TLX` = round(emmean, 1),
              `95% CI Lower` = if (!is.null(ci_lower)) round(.data[[ci_lower]], 1) else NA_real_,
              `95% CI Upper` = if (!is.null(ci_upper)) round(.data[[ci_upper]], 1) else NA_real_
            ) %>%
            select(Modality, `UI Mode`, `Mean TLX`, `95% CI Lower`, `95% CI Upper`)
          
          print(knitr::kable(emm_tlx_table, caption = "Estimated Marginal Means for Overall TLX by Condition (95% CI)"))
          
          # Plot EMMs
          p_emm_tlx <- ggplot(emm_tlx_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
            geom_line(size = 1.1, position = position_dodge(0.2)) +
            geom_point(size = 2.8, position = position_dodge(0.2))
          
          if (!is.null(ci_lower) && !is.null(ci_upper)) {
            p_emm_tlx <- p_emm_tlx + geom_errorbar(
              aes(ymin = .data[[ci_lower]], ymax = .data[[ci_upper]]), 
              width = 0.1, position = position_dodge(0.2)
            )
          }
          
          p_emm_tlx <- p_emm_tlx +
            scale_color_manual(values = custom_palette_2,
                                labels = c("Static", "Adaptive")) +
            labs(
              x = "Input Modality",
              y = "Overall TLX Score",
              color = "UI Mode",
              title = "Estimated Marginal Means: Overall TLX by Condition"
            ) +
            theme_minimal(base_size = 13) +
            theme(legend.position = "top")
          
          print(p_emm_tlx)
        }
      }
    }
  }
}
```

### Advanced TLX Analysis: UX Insights

**Research Questions:** 
- Which subscales drive overall workload? Are there different workload profiles for hand vs. gaze?
- Is there a performance-workload trade-off? Do participants who report lower workload perform better?
- How do workload sources differ between modalities?

*These analyses provide deeper UX insights into workload patterns and their relationship to performance.*

```{r tlx-ux-analysis}
if(all(tlx_cols %in% names(df_raw)) && exists("df_tlx_overall")) {
  # === 1. WORKLOAD PROFILE ANALYSIS ===
  cat("### Workload Profile Analysis\n\n")
  
  # Compute subscale contributions to overall workload
  df_tlx_profiles <- df_raw %>%
    filter(!is.na(pid)) %>%
    {
      if ("block_number" %in% names(.)) {
        group_by(., pid, modality, ui_mode, block_number)
      } else {
        group_by(., pid, modality, ui_mode)
      }
    } %>%
    summarise(
      overall_tlx = mean(c_across(starts_with("tlx_")), na.rm = TRUE),
      mental = mean(tlx_mental, na.rm = TRUE),
      physical = mean(tlx_physical, na.rm = TRUE),
      temporal = mean(tlx_temporal, na.rm = TRUE),
      performance = mean(tlx_performance, na.rm = TRUE),
      effort = mean(tlx_effort, na.rm = TRUE),
      frustration = mean(tlx_frustration, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  if (nrow(df_tlx_profiles) > 0) {
    # Subscale contribution (what % of total workload comes from each subscale)
    tlx_contribution <- df_tlx_profiles %>%
      group_by(modality, ui_mode) %>%
      summarise(
        N = n(),
        Mental_Pct = round(100 * mean(mental, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        Physical_Pct = round(100 * mean(physical, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        Temporal_Pct = round(100 * mean(temporal, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        Performance_Pct = round(100 * mean(performance, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        Effort_Pct = round(100 * mean(effort, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        Frustration_Pct = round(100 * mean(frustration, na.rm = TRUE) / mean(overall_tlx, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    tlx_contribution %>%
      kable(caption = "Subscale Contribution to Overall Workload (%). Shows what percentage of total workload comes from each subscale. Values >16.7% indicate above-average contribution.") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Identify dominant subscales (which subscale is highest for each condition)
    dominant_subscales <- df_tlx_profiles %>%
      pivot_longer(cols = c(mental, physical, temporal, performance, effort, frustration),
                   names_to = "Subscale", values_to = "Score") %>%
      group_by(modality, ui_mode, Subscale) %>%
      summarise(Mean_Score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
      group_by(modality, ui_mode) %>%
      slice_max(Mean_Score, n = 2) %>%
      mutate(Rank = row_number()) %>%
      pivot_wider(names_from = Rank, values_from = c(Subscale, Mean_Score), names_sep = "_")
    
    cat("\n**Dominant Workload Sources:**\n\n")
    dominant_subscales %>%
      kable(caption = "Top 2 Workload Subscales by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # === 2. WORKLOAD vs PERFORMANCE TRADE-OFF ===
    cat("\n### Workload-Performance Relationship\n\n")
    
    # Merge TLX with performance metrics
    if (exists("df_iso") && "TP" %in% names(df_iso)) {
      perf_tlx <- df_iso %>%
        filter(!is.na(pid)) %>%
        group_by(pid, modality, ui_mode) %>%
        summarise(mean_tp = mean(TP, na.rm = TRUE), .groups = "drop") %>%
        left_join(
          df_tlx_profiles %>% select(pid, modality, ui_mode, overall_tlx),
          by = c("pid", "modality", "ui_mode")
        ) %>%
        filter(!is.na(overall_tlx), !is.na(mean_tp))
      
      if (nrow(perf_tlx) > 0) {
        # Correlation analysis
        perf_tlx_cor <- perf_tlx %>%
          group_by(modality, ui_mode) %>%
          summarise(
            N = n(),
            Correlation = round(cor(overall_tlx, mean_tp, use = "complete.obs"), 3),
            .groups = "drop"
          )
        
        perf_tlx_cor %>%
          kable(caption = "Correlation Between Workload and Throughput by Condition. Negative correlation suggests lower workload is associated with better performance.") %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
        
        # Scatter plot: Workload vs Performance
        p_perf_tlx <- ggplot(perf_tlx, aes(x = overall_tlx, y = mean_tp, color = ui_mode)) +
          geom_point(alpha = 0.6, size = 2) +
          geom_smooth(method = "lm", se = TRUE, alpha = 0.2, linewidth = 1) +
          facet_grid(. ~ modality,
                     labeller = labeller(
                       modality = function(x) paste("Modality:", str_to_title(x))
                     ),
                     drop = TRUE) +
          scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
          labs(
            x = "Overall TLX Score (0-100)",
            y = "Throughput (bits/s)",
            color = "UI Mode",
            title = "Workload vs. Performance Trade-off",
            subtitle = "Does lower workload correlate with better performance?"
          ) +
          theme_minimal(base_size = 13) +
          theme(
            legend.position = "top",
            strip.text = element_text(face = "bold", size = 12),
            strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5)
          )
        
        print(p_perf_tlx)
        
        # Workload efficiency: Performance per unit of workload
        perf_tlx <- perf_tlx %>%
          mutate(workload_efficiency = mean_tp / overall_tlx)
        
        efficiency_summary <- perf_tlx %>%
          group_by(modality, ui_mode) %>%
          summarise(
            N = n(),
            Mean_Efficiency = round(mean(workload_efficiency, na.rm = TRUE), 3),
            SD_Efficiency = round(sd(workload_efficiency, na.rm = TRUE), 3),
            .groups = "drop"
          )
        
        efficiency_summary %>%
          kable(caption = "Workload Efficiency (Throughput / TLX Score). Higher values indicate better performance per unit of reported workload.") %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
      }
    }
    
    # === 3. MODALITY-SPECIFIC WORKLOAD PATTERNS ===
    cat("\n### Modality-Specific Workload Patterns\n\n")
    
    # Compare which subscales are most affected by modality
    modality_workload_diff <- df_tlx_profiles %>%
      group_by(modality, ui_mode) %>%
      summarise(
        Mental = round(mean(mental, na.rm = TRUE), 1),
        Physical = round(mean(physical, na.rm = TRUE), 1),
        Temporal = round(mean(temporal, na.rm = TRUE), 1),
        Performance = round(mean(performance, na.rm = TRUE), 1),
        Effort = round(mean(effort, na.rm = TRUE), 1),
        Frustration = round(mean(frustration, na.rm = TRUE), 1),
        .groups = "drop"
      ) %>%
      pivot_longer(cols = c(Mental, Physical, Temporal, Performance, Effort, Frustration),
                   names_to = "Subscale", values_to = "Score") %>%
      pivot_wider(names_from = modality, values_from = Score) %>%
      mutate(
        Hand_Gaze_Diff = round(hand - gaze, 1),
        Hand_Gaze_Pct = round(100 * (hand - gaze) / ((hand + gaze) / 2), 1)
      ) %>%
      arrange(desc(abs(Hand_Gaze_Diff)))
    
    cat("**Workload Differences: Hand vs. Gaze (by UI Mode)**\n\n")
    modality_workload_diff %>%
      kable(caption = "Subscale Differences Between Hand and Gaze Modalities. Positive values indicate higher workload for hand.") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # === 4. INDIVIDUAL DIFFERENCES IN WORKLOAD ===
    cat("\n### Individual Differences in Workload\n\n")
    
    # Identify participants with consistently high/low workload
    participant_workload <- df_tlx_profiles %>%
      group_by(pid) %>%
      summarise(
        Mean_Overall_TLX = mean(overall_tlx, na.rm = TRUE),
        SD_Overall_TLX = sd(overall_tlx, na.rm = TRUE),
        N_Conditions = n(),
        .groups = "drop"
      ) %>%
      arrange(desc(Mean_Overall_TLX))
    
    cat("**Participants with Highest Average Workload (Top 5):**\n\n")
    participant_workload %>%
      head(5) %>%
      kable(caption = "Top 5 Participants by Average Workload") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    cat("\n**Participants with Lowest Average Workload (Bottom 5):**\n\n")
    participant_workload %>%
      tail(5) %>%
      kable(caption = "Bottom 5 Participants by Average Workload") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Workload consistency (low SD = consistent across conditions)
    cat("\n**Workload Consistency Across Conditions:**\n")
    cat("Participants with low SD report similar workload across all conditions.\n")
    cat("Participants with high SD show large workload differences between conditions.\n\n")
    
    consistency_summary <- participant_workload %>%
      summarise(
        Mean_SD = round(mean(SD_Overall_TLX, na.rm = TRUE), 2),
        Median_SD = round(median(SD_Overall_TLX, na.rm = TRUE), 2),
        Low_Consistency = sum(SD_Overall_TLX > 15, na.rm = TRUE),
        High_Consistency = sum(SD_Overall_TLX < 5, na.rm = TRUE)
      )
    
    consistency_summary %>%
      kable(caption = "Workload Consistency Statistics") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    cat("\n**Interpretation:**\n")
    cat("- **Subscale contributions** reveal which aspects of workload are most prominent in each condition.\n")
    cat("- **Workload-performance correlations** show whether lower workload is associated with better performance.\n")
    cat("- **Workload efficiency** quantifies performance per unit of reported workload.\n")
    cat("- **Modality differences** highlight which subscales are most affected by input modality.\n")
    cat("- **Individual differences** identify participants who consistently report high/low workload.\n\n")
  }
} else {
  cat("⚠ TLX data not available for advanced UX analysis.\n")
}
```

-----

# 9. Participant Awareness & Strategy (Debrief Analysis)

**Research Question:** Did participants notice the adaptive interface? Did they change their strategy? How do awareness and strategy relate to performance?

**Sample Size:** `r get_n_string(df_raw %>% filter(!is.na(debrief_q1_adaptation_noticed) | !is.na(debrief_q2_strategy_changed)))` participants with debrief responses.

*This section analyzes post-experiment debrief responses to understand participant awareness of the adaptive interface and self-reported strategy changes.*

```{r debrief-analysis}
# Check if debrief columns exist
debrief_cols <- c("debrief_q1_adaptation_noticed", "debrief_q2_strategy_changed")

if (all(debrief_cols %in% names(df_raw))) {
  # Get unique participant-level debrief responses (debrief is per-participant, not per-trial)
  df_debrief <- df_raw %>%
    filter(!is.na(pid)) %>%
    select(pid, debrief_q1_adaptation_noticed, debrief_q2_strategy_changed) %>%
    distinct(pid, .keep_all = TRUE) %>%
    filter(!is.na(debrief_q1_adaptation_noticed) | !is.na(debrief_q2_strategy_changed))
  
  if (nrow(df_debrief) > 0) {
    cat("**Debrief Response Coverage:** ", nrow(df_debrief), " participants provided debrief responses.\n\n")
    
    # === THEMATIC ANALYSIS ===
    cat("### Thematic Analysis of Debrief Responses\n\n")
    
    # Q1: Adaptation Noticed - Categorize responses
    df_debrief_q1 <- df_debrief %>%
      filter(!is.na(debrief_q1_adaptation_noticed), debrief_q1_adaptation_noticed != "") %>%
      mutate(
        response_lower = tolower(debrief_q1_adaptation_noticed),
        # Categorize responses
        noticed_category = case_when(
          grepl("no|did not|didn't|not notice|not aware|unaware", response_lower) ~ "Not Noticed",
          grepl("yes|noticed|saw|observed|realized|detected", response_lower) ~ "Noticed",
          grepl("maybe|perhaps|possibly|uncertain|unsure|think|guess", response_lower) ~ "Uncertain",
          grepl("size|bigger|larger|smaller|target|change|different", response_lower) ~ "Noticed Size Changes",
          grepl("jitter|drift|movement|shaking|unstable", response_lower) ~ "Noticed Movement Issues",
          TRUE ~ "Other/Unclear"
        )
      )
    
    if (nrow(df_debrief_q1) > 0) {
      q1_themes <- df_debrief_q1 %>%
        count(noticed_category, sort = TRUE) %>%
        mutate(
          Pct = round(100 * n / sum(n), 1),
          Response = noticed_category
        ) %>%
        select(Response, Count = n, Pct)
      
      cat("**Q1: Did you notice the interface adapting?**\n\n")
      q1_themes %>%
        kable(caption = "Thematic Categories: Adaptation Awareness") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
      
      cat("\n**Sample Responses by Category:**\n\n")
      for (cat in unique(df_debrief_q1$noticed_category)) {
        cat("\n**", cat, ":**\n")
        sample_responses <- df_debrief_q1 %>%
          filter(noticed_category == cat) %>%
          pull(debrief_q1_adaptation_noticed) %>%
          head(3)
        for (resp in sample_responses) {
          cat("- \"", substr(resp, 1, min(150, nchar(resp))), ifelse(nchar(resp) > 150, "...", ""), "\"\n", sep = "")
        }
      }
    }
    
    # Q2: Strategy Changed - Categorize responses
    df_debrief_q2 <- df_debrief %>%
      filter(!is.na(debrief_q2_strategy_changed), debrief_q2_strategy_changed != "") %>%
      mutate(
        response_lower = tolower(debrief_q2_strategy_changed),
        # Categorize responses
        strategy_category = case_when(
          grepl("no|did not|didn't|not change|same|consistent|no conscious|regardless", response_lower) ~ "No Strategy Change",
          grepl("yes|changed|different|adapted|adjusted|modified|shifted", response_lower) ~ "Strategy Changed",
          grepl("maybe|perhaps|possibly|uncertain|unsure|think|guess|not really", response_lower) ~ "Uncertain/Minimal",
          grepl("faster|speed|quicker|rushed|hurried", response_lower) ~ "Focused on Speed",
          grepl("accuracy|precise|careful|slower|took time", response_lower) ~ "Focused on Accuracy",
          grepl("easier|larger|bigger|target", response_lower) ~ "Adapted to Easier Targets",
          TRUE ~ "Other/Unclear"
        )
      )
    
    if (nrow(df_debrief_q2) > 0) {
      q2_themes <- df_debrief_q2 %>%
        count(strategy_category, sort = TRUE) %>%
        mutate(
          Pct = round(100 * n / sum(n), 1),
          Response = strategy_category
        ) %>%
        select(Response, Count = n, Pct)
      
      cat("\n\n**Q2: Did you change your strategy during the experiment?**\n\n")
      q2_themes %>%
        kable(caption = "Thematic Categories: Strategy Changes") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
      
      cat("\n**Sample Responses by Category:**\n\n")
      for (cat in unique(df_debrief_q2$strategy_category)) {
        cat("\n**", cat, ":**\n")
        sample_responses <- df_debrief_q2 %>%
          filter(strategy_category == cat) %>%
          pull(debrief_q2_strategy_changed) %>%
          head(3)
        for (resp in sample_responses) {
          cat("- \"", substr(resp, 1, min(150, nchar(resp))), ifelse(nchar(resp) > 150, "...", ""), "\"\n", sep = "")
        }
      }
    }
    
    # === RELATIONSHIP TO PERFORMANCE ===
    cat("\n\n### Relationship to Performance\n\n")
    
    # Merge debrief with performance data
    # Get throughput from df_iso if available, or from df_pid_cond
    perf_tp <- NULL
    if (exists("df_iso") && "TP" %in% names(df_iso)) {
      perf_tp <- df_iso %>%
        filter(!is.na(pid), !is.na(TP)) %>%
        group_by(pid) %>%
        summarise(mean_tp = mean(TP, na.rm = TRUE), .groups = "drop")
    } else if (exists("df_pid_cond") && "tp_mean" %in% names(df_pid_cond)) {
      perf_tp <- df_pid_cond %>%
        filter(!is.na(pid), !is.na(tp_mean)) %>%
        group_by(pid) %>%
        summarise(mean_tp = mean(tp_mean, na.rm = TRUE), .groups = "drop")
    }
    
    # Get RT and error rate from df
    perf_other <- df %>%
      filter(!is.na(pid)) %>%
      group_by(pid) %>%
      summarise(
        mean_rt_s = mean(rt_s, na.rm = TRUE),
        mean_error_rate = mean(!correct, na.rm = TRUE),
        .groups = "drop"
      )
    
    # Combine performance metrics
    if (!is.null(perf_tp)) {
      df_perf_debrief <- perf_tp %>%
        full_join(perf_other, by = "pid")
    } else {
      df_perf_debrief <- perf_other %>%
        mutate(mean_tp = NA_real_)
    }
    
    df_perf_debrief <- df_perf_debrief %>%
      left_join(
        df_debrief_q1 %>% select(pid, noticed_category),
        by = "pid"
      ) %>%
      left_join(
        df_debrief_q2 %>% select(pid, strategy_category),
        by = "pid"
      )
    
    # Compare performance by awareness
    if (sum(!is.na(df_perf_debrief$noticed_category)) > 0) {
      cat("**Performance by Adaptation Awareness:**\n\n")
      
      perf_by_awareness <- df_perf_debrief %>%
        filter(!is.na(noticed_category)) %>%
        group_by(noticed_category) %>%
        summarise(
          N = n(),
          Mean_TP = round(mean(mean_tp, na.rm = TRUE), 2),
          SD_TP = round(sd(mean_tp, na.rm = TRUE), 2),
          Mean_RT = round(mean(mean_rt_s, na.rm = TRUE), 3),
          SD_RT = round(sd(mean_rt_s, na.rm = TRUE), 3),
          Mean_Error = round(mean(mean_error_rate, na.rm = TRUE), 3),
          SD_Error = round(sd(mean_error_rate, na.rm = TRUE), 3),
          .groups = "drop"
        )
      
      perf_by_awareness %>%
        kable(caption = "Performance Metrics by Adaptation Awareness Category") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    }
    
    # Compare performance by strategy
    if (sum(!is.na(df_perf_debrief$strategy_category)) > 0) {
      cat("\n**Performance by Strategy Category:**\n\n")
      
      perf_by_strategy <- df_perf_debrief %>%
        filter(!is.na(strategy_category)) %>%
        group_by(strategy_category) %>%
        summarise(
          N = n(),
          Mean_TP = round(mean(mean_tp, na.rm = TRUE), 2),
          SD_TP = round(sd(mean_tp, na.rm = TRUE), 2),
          Mean_RT = round(mean(mean_rt_s, na.rm = TRUE), 3),
          SD_RT = round(sd(mean_rt_s, na.rm = TRUE), 3),
          Mean_Error = round(mean(mean_error_rate, na.rm = TRUE), 3),
          SD_Error = round(sd(mean_error_rate, na.rm = TRUE), 3),
          .groups = "drop"
        )
      
      perf_by_strategy %>%
        kable(caption = "Performance Metrics by Strategy Category") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    }
    
    # Visualization: Performance by awareness
    if (sum(!is.na(df_perf_debrief$noticed_category)) >= 2) {
      df_plot_awareness <- df_perf_debrief %>%
        filter(!is.na(noticed_category)) %>%
        filter(noticed_category %in% c("Noticed", "Not Noticed", "Noticed Size Changes"))
      
      if (nrow(df_plot_awareness) > 0) {
        p1 <- ggplot(df_plot_awareness, aes(x = noticed_category, y = mean_tp, fill = noticed_category)) +
          geom_violin(alpha = 0.4, trim = FALSE) +
          geom_boxplot(width = 0.2, alpha = 0.9, outlier.shape = NA, fill = "grey90", color = "grey70") +
          geom_point(alpha = 0.5, size = 2, position = position_jitter(width = 0.1)) +
          scale_fill_brewer(palette = "Set2") +
          labs(
            x = "Adaptation Awareness",
            y = "Mean Throughput (bits/s)",
            title = "Performance by Adaptation Awareness"
          ) +
          theme_minimal(base_size = 13) +
          theme(legend.position = "none")
        
        print(p1)
      }
    }
    
    cat("\n**Interpretation:**\n")
    cat("- Participants who noticed adaptation may have different performance patterns.\n")
    cat("- Strategy changes (e.g., focusing on speed vs. accuracy) may relate to performance outcomes.\n")
    cat("- These relationships are exploratory and should be interpreted with caution due to self-report biases.\n\n")
    
  } else {
    cat("⚠ No debrief responses found in dataset.\n")
  }
} else {
  cat("⚠ Debrief columns not found in dataset.\n")
}
```

-----

# 10. Learning Curves & Practice Effects

**Research Question:** How does performance change within each condition? Do learning rates differ by condition?

**Sample Size:** `r get_n_string(df_all_trials)` participants with trial-level data.

**Note:** These learning curves serve as a quality check that participants improved modestly and reached a plateau; we do not treat these as primary inferential outcomes. This analysis is exploratory/QC only.

*This section shows learning curves aligned by condition start (accounting for Williams counterbalancing). For block-level trends, see Section 12.*

```{r learning-curves}
# Calculate learning curves aligned by condition (not absolute trial number)
# With Williams counterbalancing, different participants experience conditions at different times
# So we align by "trial within condition" rather than absolute trial number

# For error rates, we need ALL trials (correct + incorrect)
# For movement time, we use only correct trials with valid RTs

# Option 1: Use trial_in_block if available (cleanest approach)
if ("trial_in_block" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      error_rate = 1 - mean(is_correct, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = mean(error_rate, na.rm = TRUE),
      error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      rt_avg = mean(rt_s, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_avg, na.rm = TRUE),
      rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_block", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_block"
  x_label <- "Trial Position in Block"
} else {
  # Option 2: Calculate position within condition by grouping consecutive trials
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = 1 - mean(is_correct, na.rm = TRUE),
      error_se = sd(1 - is_correct, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_s, na.rm = TRUE),
      rt_se = sd(rt_s, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_condition", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_condition"
  x_label <- "Trial Position in Condition"
}

# For throughput, we need to work with df_iso and join trial information
# Create approximate throughput learning by joining trial numbers
if ("trial_number" %in% names(df_raw)) {
  # Join df_iso with trial numbers from original data
  # Ensure pressure types match (df_iso has factor, df_raw has numeric)
  df_raw_for_join <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, trial_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),  # Convert to character for joining
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct()
  
  df_iso_for_join <- df_iso %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    )
  
  df_iso_with_trials <- df_raw_for_join %>%
    left_join(df_iso_for_join, by = c("pid", "modality", "ui_mode", "pressure", "A", "W")) %>%
    filter(!is.na(TP), !is.na(trial_number))
  
  if (nrow(df_iso_with_trials) > 0) {
    df_learning_tp <- df_iso_with_trials %>%
      mutate(
        trial_bin = cut(trial_number, breaks = seq(0, max(trial_number, na.rm = TRUE) + 1, 
                                                   length.out = 11), include.lowest = TRUE),
        trial_bin_num = as.numeric(trial_bin)
      ) %>%
      group_by(trial_bin_num, modality, ui_mode, pressure, pid) %>%
      summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
      group_by(trial_bin_num, modality, ui_mode, pressure) %>%
      summarise(
        TP_mean = mean(TP_avg, na.rm = TRUE),
        TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
        .groups = "drop"
      )
  } else {
    df_learning_tp <- data.frame()
  }
} else {
  df_learning_tp <- data.frame()
}

# Movement time learning curve (aligned by condition position)
if (nrow(df_learning_aligned) > 0) {
  # Check what conditions we have
  learning_summary_table <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      `N Positions` = n(),
      `Mean RT (s)` = round(mean(rt_mean, na.rm = TRUE), 3),
      `Mean Error Rate` = round(mean(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF")
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean RT (s)`, `Mean Error Rate`)
  
  learning_summary_table %>%
    kable(caption = paste0("Learning Curve Data Summary by Condition (", get_n_string(df_all_trials), " participants)")) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-rt}
#| fig-cap: !expr 'paste0("Learning Curves: Movement Time Within Condition. ", get_n_string(df), " participants. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI.")'

if (nrow(df_learning_aligned) > 0) {
  # Create plot with dynamic x variable
  p1 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = rt_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points)
    geom_point(alpha = 0.4, size = 1.5) +
    # Smoothed trend line
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, 
               labeller = labeller(
                 pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF"),
                 modality = function(x) str_to_title(x)
               ),
               drop = TRUE) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    labs(
      title = "Learning Curves: Movement Time Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Movement Time (s)",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p1)
}
```
  
```{r error-summary-learning}
if (nrow(df_learning_aligned) > 0) {
  # Error rate learning curve (aligned by condition position)
  # Check error rate data availability
  error_summary <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      n = n(),
      mean_error = round(mean(error_mean, na.rm = TRUE), 4),
      min_error = round(min(error_mean, na.rm = TRUE), 4),
      max_error = round(max(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
      `N Positions` = n,
      `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01),
      `Min Error Rate` = scales::percent(min_error, accuracy = 0.01),
      `Max Error Rate` = scales::percent(max_error, accuracy = 0.01)
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean Error Rate`, `Min Error Rate`, `Max Error Rate`)
  
  error_summary %>%
    kable(caption = "Error Rate Summary by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-error}
#| fig-cap: "Learning Curves: Error Rate Within Condition. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI."

if (nrow(df_learning_aligned) > 0) {
  # Ensure we have data for both UI modes in each condition
  # If error rates are very low, use a different scale or show raw values
  p2 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = error_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points) - make more visible
    geom_point(alpha = 0.6, size = 2, shape = 16) +
    # Smoothed trend line - only if we have enough data points
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, 
               labeller = labeller(
                 pressure = function(x) {
                   x_char <- as.character(x)
                   ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
                 },
                 modality = function(x) str_to_title(x)
               ),
               drop = TRUE) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
    labs(
      title = "Learning Curves: Error Rate Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Error Rate",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p2)
} else {
  cat("⚠ Insufficient data for learning curve visualization.\n")
}
```

*Note: Data aligned by position within condition to account for Williams counterbalancing. For block-level trends, see Section 12: Block Order & Temporal Effects.*

-----

# 11. Movement Quality Metrics

## Submovement Analysis

**Research Question:** Does adaptive UI reduce movement corrections? How do submovements relate to performance?

*Submovements indicate intermittent control - fewer submovements suggest smoother, more ballistic movements.*

#### Planned Sample Size & Power

Submovement count is a noisier movement-quality metric and is currently based on pre-computed peaks. We anticipate **small-to-medium effects** of UI mode (adaptive reducing corrective movements) and medium effects of modality, but with considerable between-participant variability. For such count-based metrics, simulation-based power analysis is strongly recommended (e.g., using the approach in Kumle et al., 2021). As a rule of thumb, **N = 64–72** would be needed to treat submovement differences as confirmatory (especially for UI-mode effects), whereas **N = 48** is more appropriate for exploratory visualization and effect-size estimation rather than strict NHST.

**Data Availability Note:** Submovement metrics are available for a subset of the sample (see counts below). Results in this section are descriptive engineering diagnostics.
- Participants with `submovement_count` (legacy, pre-computed): N = `r get_n_string(df %>% filter(!is.na(submovement_count)))`
- Participants with `submovement_count_recomputed` (from trajectory data): N = `r get_n_string(df %>% filter(!is.na(submovement_count_recomputed)))`
- Participants with full `trajectory` JSON data: N = `r get_n_string(df_raw %>% filter((practice == "false" | practice == FALSE | is.na(practice)), !is.na(trajectory), trajectory != "", trajectory != "null"))`

```{r submovement-analysis}
# Prefer recomputed submovement count (computed from trajectory for both modalities)
# Fall back to legacy submovement_count if recomputed is not available
submov_col <- if ("submovement_count_recomputed" %in% names(df)) {
  "submovement_count_recomputed"
} else if ("submovement_count" %in% names(df)) {
  "submovement_count"
} else {
  NULL
}

if (!is.null(submov_col)) {
  df_submov <- df %>%
    filter(!is.na(.data[[submov_col]]), .data[[submov_col]] >= 0)
  
  if (nrow(df_submov) > 0) {
    # Summary statistics
    submov_summary <- df_submov %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_participants = n_distinct(pid),
        N_trials = n(),
        Mean = round(mean(.data[[submov_col]], na.rm = TRUE), 2),
        SD = round(sd(.data[[submov_col]], na.rm = TRUE), 2),
        Median = round(median(.data[[submov_col]], na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    submov_summary %>%
      kable(caption = paste0("Submovement Count by Condition (", get_n_string(df_submov), " participants, using ", submov_col, ")")) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  }
}
```

```{r plot-submovement}
# Use the same submov_col determined in the previous chunk
#| fig-cap: !expr 'if(exists("submov_col") && !is.null(submov_col) && exists("df_submov") && nrow(df_submov) > 0) paste0("Submovement Count (Movement Quality) by Modality and UI Mode. ", get_n_string(df_submov), " participants (using ", submov_col, "). Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower indicates smoother, more ballistic movements.") else "Submovement Count plot (no data available)"'

if (exists("submov_col") && !is.null(submov_col) && exists("df_submov") && nrow(df_submov) > 0) {
    # Check if hand modality has any non-zero values
    hand_has_data <- df_submov %>%
      filter(modality == "hand") %>%
      summarise(has_nonzero = any(.data[[submov_col]] > 0)) %>%
      pull(has_nonzero)
    
    if (!hand_has_data && submov_col == "submovement_count") {
      cat("⚠ **Note:** Hand modality shows zero submovements because the legacy `submovement_count`\n")
      cat("   was only computed for gaze. Future data will use `submovement_count_recomputed`\n")
      cat("   computed from trajectory for both modalities.\n\n")
    }
    
    # Aggregate to participant-level means for raincloud plot
    df_submov_plot <- df_submov %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(submov_mean = mean(.data[[submov_col]], na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(submov_mean))
    
    # Check if hand modality has all zeros - if so, filter to only gaze
    hand_all_zero <- df_submov_plot %>%
      filter(modality == "hand") %>%
      summarise(all_zero = all(submov_mean == 0, na.rm = TRUE)) %>%
      pull(all_zero)
    
    if (!is.na(hand_all_zero) && hand_all_zero && "gaze" %in% unique(df_submov_plot$modality)) {
      df_submov_plot <- df_submov_plot %>% filter(modality == "gaze")
      cat("ℹ **Note:** Hand modality shows zero submovements (smooth movements). Plot shows gaze modality only.\n\n")
    }
    
    # Raincloud plot for Submovement Count
    p1 <- ggplot(df_submov_plot, aes(x = ui_mode, y = submov_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_submov_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_submov_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_submov_plot %>%
          group_by(modality, pressure, ui_mode) %>%
          summarise(mean_value = mean(submov_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_grid(modality ~ pressure, 
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Submovement Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
}
```

```{r plot-submovement-id}
#| fig-cap: !expr 'paste0("Submovements vs. Index of Difficulty. ", get_n_string(df %>% filter(!is.na(submovement_count) | !is.na(submovement_count_recomputed))), " participants. How movement corrections scale with task difficulty. Linear regression with 95% confidence intervals.")'

# Prefer recomputed submovement count (computed from trajectory for both modalities)
# Fall back to legacy submovement_count if recomputed is not available
submov_col <- if ("submovement_count_recomputed" %in% names(df)) {
  "submovement_count_recomputed"
} else if ("submovement_count" %in% names(df)) {
  "submovement_count"
} else {
  NULL
}

if (!is.null(submov_col)) {
  df_submov <- df %>%
    filter(!is.na(.data[[submov_col]]), .data[[submov_col]] >= 0)
  
  if (nrow(df_submov) > 0) {
    # Check which modalities have data
    modalities_with_data <- unique(df_submov$modality)
    
    # Check if hand modality has any non-zero values
    hand_has_nonzero <- df_submov %>%
      filter(modality == "hand") %>%
      summarise(has_nonzero = any(.data[[submov_col]] > 0)) %>%
      pull(has_nonzero)
    
    # Check if hand modality has any data at all (including zeros)
    hand_has_any_data <- "hand" %in% modalities_with_data
    
    if (!hand_has_any_data) {
      cat("ℹ **Note:** No submovement data for Hand modality.\n\n")
    } else if (!hand_has_nonzero && submov_col == "submovement_count") {
      cat("⚠ **Note:** Hand modality shows zero submovements because the legacy `submovement_count`\n")
      cat("   was only computed for gaze. Future data will use `submovement_count_recomputed`\n")
      cat("   computed from trajectory for both modalities.\n\n")
    } else if (!hand_has_nonzero && submov_col == "submovement_count_recomputed") {
      cat("ℹ **Note:** Hand modality shows zero submovements, indicating very smooth movements\n")
      cat("   with no detected velocity peaks (submovements). This is valid data.\n\n")
    }
    
    # Submovements vs. Difficulty
    # Check if IDe exists, otherwise use ID
    if ("IDe" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(IDe)) %>%
        mutate(difficulty = IDe)
    } else if ("ID" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(ID)) %>%
        mutate(difficulty = ID)
    } else {
      df_submov_id <- data.frame()
    }
    
    if (nrow(df_submov_id) > 0) {
      # Filter to only modalities with non-zero data
      modalities_with_variation <- df_submov_id %>%
        group_by(modality) %>%
        summarise(has_variation = any(.data[[submov_col]] > 0, na.rm = TRUE), .groups = "drop") %>%
        filter(has_variation) %>%
        pull(modality)
      
      if (length(modalities_with_variation) > 0) {
        df_submov_id <- df_submov_id %>% filter(modality %in% modalities_with_variation)
        
        if (!"hand" %in% modalities_with_variation && "gaze" %in% modalities_with_variation) {
          cat("ℹ **Note:** Hand modality shows zero submovements. Plot shows gaze modality only.\n\n")
        }
      }
      
      if (nrow(df_submov_id) > 0) {
        p2 <- ggplot(df_submov_id, aes(x = difficulty, y = .data[[submov_col]], color = ui_mode)) +
          geom_point(alpha = 0.3, size = 1) +
          geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
          facet_grid(modality ~ pressure, 
                     labeller = labeller(
                       pressure = function(x) paste("Pressure:", x),
                       modality = function(x) str_to_title(x)
                     ),
                     drop = TRUE) +
          scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
          labs(
            title = "Submovements vs. Index of Difficulty",
            subtitle = "How movement corrections scale with task difficulty",
            x = "Index of Difficulty (bits)",
            y = "Submovement Count",
            color = "UI Mode"
          ) +
          theme_minimal(base_size = 14) +
          theme(legend.position = "top", strip.text = element_text(face = "bold"))
        
        print(p2)
      } else {
        cat("⚠ No submovement data with variation available for this plot.\n\n")
      }
    } else {
      cat("⚠ No valid difficulty data available for submovement analysis.\n")
    }
  } else {
    cat("⚠ No valid submovement data available.\n")
  }
} else {
  cat("⚠ Neither submovement_count nor submovement_count_recomputed column found in dataset.\n")
}
```

## Verification Time Analysis

**Research Question:** How much time is spent "stopping" vs. "moving"? Does adaptive UI reduce verification time?

**Sample Size:** `r get_n_string(df %>% filter(!is.na(verification_time_ms), verification_time_ms > 0))` participants with verification time data.

#### Planned Sample Size & Power

Verification time (from first target entry to final selection) is conceptually closer to a decision-phase measure and serves as a bridge to future LBA modeling. We again expect **medium modality effects** and **small-to-medium UI-mode effects**, and we analyze it via an LMM. Because this outcome is continuous and based on many trials per participant, **N = 48** is a **good target** for medium effects, and **N = 64** provides added stability for smaller UI-mode differences or more complex interaction patterns. The same repeated-measures power guidelines apply as for RT and TP (Cohen, 1988).

*Verification time represents the "precise stopping" phase, separate from the ballistic movement phase.*

```{r verification-time}
if ("verification_time_ms" %in% names(df)) {
  df_verify <- df %>%
    filter(!is.na(verification_time_ms), verification_time_ms > 0, verification_time_ms <= 6000)
  
  if (nrow(df_verify) > 0) {
    df_verify <- df_verify %>%
      mutate(
        verification_s = verification_time_ms / 1000,
        movement_s = rt_s - verification_s,
        verify_ratio = verification_time_ms / rt_ms,
        # Ensure PressureLabel exists
        PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF")
      )
    
    # Summary statistics
    verify_summary <- df_verify %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_participants = n_distinct(pid),
        N_trials = n(),
        Mean_Verify = round(mean(verification_s, na.rm = TRUE), 3),
        Mean_MT = round(mean(rt_s, na.rm = TRUE), 3),
        Mean_Ratio = round(mean(verify_ratio, na.rm = TRUE), 3),
        .groups = "drop"
      )
    
    verify_summary %>%
      kable(caption = paste0("Verification Time by Condition (", get_n_string(df_verify), " participants)")) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Aggregate to participant-level means for raincloud plot
    df_verify_plot <- df_verify %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(verification_s_mean = mean(verification_s, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(verification_s_mean))
    
    # Raincloud plot for Verification Time
    p1 <- ggplot(df_verify_plot, aes(x = ui_mode, y = verification_s_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_verify_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_verify_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_verify_plot %>%
          group_by(modality, pressure, ui_mode) %>%
          summarise(mean_value = mean(verification_s_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_grid(modality ~ pressure, labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Verification Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
    
    # Verification ratio (what proportion of total time is verification) - raincloud style
    df_verify_ratio_plot <- df_verify %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(verify_ratio_mean = mean(verify_ratio, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(verify_ratio_mean))
    
    p2 <- ggplot(df_verify_ratio_plot, aes(x = ui_mode, y = verify_ratio_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_verify_ratio_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_verify_ratio_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_verify_ratio_plot %>%
          group_by(modality, pressure, ui_mode) %>%
          summarise(mean_value = mean(verify_ratio_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_grid(modality ~ pressure, 
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      scale_y_continuous(labels = scales::percent) +
      labs(
        x = "UI Mode",
        y = "Verification Ratio",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p2)
    
    # === DWELL TIME ANALYSIS ===
    cat("\n### Target Dwell Time\n\n")
    
    if (all(c("time_in_target_total_ms", "first_entry_time_ms") %in% names(df_verify))) {
      df_dwell <- df_verify %>%
        filter(
          !is.na(time_in_target_total_ms),
          !is.na(first_entry_time_ms),
          time_in_target_total_ms >= 0,
          time_in_target_total_ms <= 10000,  # Reasonable upper bound
          first_entry_time_ms >= 0
        ) %>%
        mutate(
          dwell_s = time_in_target_total_ms / 1000,
          first_entry_s = first_entry_time_ms / 1000,
          dwell_ratio = time_in_target_total_ms / rt_ms
        )
      
      if (nrow(df_dwell) > 0) {
        # Summary statistics
        dwell_summary <- df_dwell %>%
          group_by(modality, ui_mode, pressure) %>%
          summarise(
            N_participants = n_distinct(pid),
            N_trials = n(),
            Mean_Dwell_s = round(mean(dwell_s, na.rm = TRUE), 3),
            SD_Dwell_s = round(sd(dwell_s, na.rm = TRUE), 3),
            Median_Dwell_s = round(median(dwell_s, na.rm = TRUE), 3),
            Mean_Dwell_Ratio = round(mean(dwell_ratio, na.rm = TRUE), 3),
            .groups = "drop"
          )
        
        dwell_summary %>%
          kable(caption = paste0("Target Dwell Time by Condition (", get_n_string(df_dwell), " participants). Dwell time is the total time spent inside the target before confirmation.")) %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
        
        # Raincloud plot for dwell time
        df_dwell_plot <- df_dwell %>%
          group_by(pid, modality, ui_mode, pressure) %>%
          summarise(dwell_s_mean = mean(dwell_s, na.rm = TRUE), .groups = "drop") %>%
          filter(!is.na(dwell_s_mean))
        
        if (nrow(df_dwell_plot) > 0) {
          p3 <- ggplot(df_dwell_plot, aes(x = ui_mode, y = dwell_s_mean, fill = ui_mode, color = ui_mode)) +
            {
              if (has_ggdist) {
                list(
                  ggdist::stat_halfeye(
                    data = df_dwell_plot %>% filter(ui_mode == "static"),
                    aes(fill = ui_mode),
                    side = "left",
                    alpha = 0.4,
                    width = 0.35,
                    .width = 0,
                    justification = 1.3,
                    point_colour = NA
                  ),
                  ggdist::stat_halfeye(
                    data = df_dwell_plot %>% filter(ui_mode == "adaptive"),
                    aes(fill = ui_mode),
                    side = "right",
                    alpha = 0.4,
                    width = 0.35,
                    .width = 0,
                    justification = -0.3,
                    point_colour = NA
                  )
                )
              } else {
                geom_violin(alpha = 0.4, trim = FALSE, scale = "width", width = 0.35, position = position_dodge(width = 0), color = NA)
              }
            } +
            geom_boxplot(width = 0.15, alpha = 0.9, outlier.shape = NA, position = position_dodge(width = 0), fill = "grey90", color = "grey70", linewidth = 0.7, show.legend = FALSE) +
            geom_point(alpha = 0.5, size = 1.5, position = position_dodge(width = 0), show.legend = FALSE) +
            geom_line(aes(group = pid), alpha = 0.3, linewidth = 0.4, color = "grey60", position = position_dodge(width = 0), show.legend = FALSE) +
            {
              mean_data <- df_dwell_plot %>%
                group_by(modality, pressure, ui_mode) %>%
                summarise(mean_value = mean(dwell_s_mean, na.rm = TRUE), .groups = "drop") %>%
                pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
                filter(!is.na(mean_static), !is.na(mean_adaptive))
              
              if (nrow(mean_data) > 0) {
                geom_segment(data = mean_data, aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive), inherit.aes = FALSE, color = "black", linewidth = 0.9, alpha = 0.9)
              } else {
                NULL
              }
            } +
            facet_grid(modality ~ pressure, 
                       labeller = labeller(
                         modality = function(x) paste("Modality:", str_to_title(x)),
                         pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                       ),
                       drop = TRUE) +
            scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
            scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
            scale_x_discrete(labels = c("Static", "Adaptive")) +
            labs(
              x = "UI Mode",
              y = "Target Dwell Time (s)",
              fill = "UI Mode",
              title = "Target Dwell Time by Condition"
            ) +
            theme_minimal(base_size = 13) +
            theme(
              legend.position = "top",
              strip.text = element_text(face = "bold", size = 12),
              strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
            )
          
          print(p3)
        }
      } else {
        cat("⚠ No valid dwell time data available.\n")
      }
    } else {
      cat("⚠ Dwell time columns (time_in_target_total_ms, first_entry_time_ms) not found.\n")
    }
    
    # === VERIFICATION PHASE DECOMPOSITION ===
    cat("\n### Verification Phase Decomposition\n\n")
    
    if (all(c("verification_start_time_ms", "verification_end_time_ms", "confirm_event_time_ms", "first_entry_time_ms") %in% names(df_verify))) {
      df_phase <- df_verify %>%
        filter(
          !is.na(verification_start_time_ms),
          !is.na(verification_end_time_ms),
          !is.na(confirm_event_time_ms),
          !is.na(first_entry_time_ms),
          verification_start_time_ms >= 0,
          verification_end_time_ms >= verification_start_time_ms,
          confirm_event_time_ms >= verification_end_time_ms
        ) %>%
        mutate(
          # Phase 1: Time to first entry (movement phase)
          movement_phase_s = first_entry_time_ms / 1000,
          # Phase 2: Verification phase (from first entry to verification start)
          entry_to_verify_s = (verification_start_time_ms - first_entry_time_ms) / 1000,
          # Phase 3: Verification to confirmation
          verify_to_confirm_s = (confirm_event_time_ms - verification_end_time_ms) / 1000,
          # Total verification time (should match verification_time_ms)
          total_verify_s = (verification_end_time_ms - verification_start_time_ms) / 1000
        ) %>%
        filter(
          entry_to_verify_s >= 0,
          verify_to_confirm_s >= 0,
          total_verify_s >= 0
        )
      
      if (nrow(df_phase) > 0) {
        # Summary by phase
        phase_summary <- df_phase %>%
          group_by(modality, ui_mode, pressure) %>%
          summarise(
            N_participants = n_distinct(pid),
            N_trials = n(),
            Mean_Movement_Phase = round(mean(movement_phase_s, na.rm = TRUE), 3),
            Mean_Entry_to_Verify = round(mean(entry_to_verify_s, na.rm = TRUE), 3),
            Mean_Verify_to_Confirm = round(mean(verify_to_confirm_s, na.rm = TRUE), 3),
            Mean_Total_Verify = round(mean(total_verify_s, na.rm = TRUE), 3),
            .groups = "drop"
          )
        
        phase_summary %>%
          kable(caption = paste0("Movement Phase Decomposition (", get_n_string(df_phase), " participants). Breakdown of movement time into phases: movement to first entry, entry to verification start, and verification to confirmation.")) %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
        
        # Confirmation source analysis
        if ("confirm_event_source" %in% names(df_phase)) {
          confirm_source_summary <- df_phase %>%
            filter(!is.na(confirm_event_source), confirm_event_source != "") %>%
            group_by(modality, ui_mode, pressure, confirm_event_source) %>%
            summarise(
              N_trials = n(),
              Pct = round(100 * n() / nrow(df_phase %>% filter(!is.na(confirm_event_source), confirm_event_source != "")), 1),
              .groups = "drop"
            )
          
          if (nrow(confirm_source_summary) > 0) {
            confirm_source_summary %>%
              kable(caption = "Confirmation Event Source by Condition. What triggered the final confirmation?") %>%
              kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
          }
        }
      } else {
        cat("⚠ No valid phase decomposition data available.\n")
      }
    } else {
      cat("⚠ Phase decomposition columns not found.\n")
    }
    
  } else {
    cat("⚠ No valid verification time data available.\n")
  }
} else {
  cat("⚠ verification_time_ms column not found in dataset.\n")
}
```

-----

# 12. Error Patterns & Types

**Research Question:** What types of errors occur? Do error patterns differ by condition?

**Sample Size:** `r get_n_string(df_raw %>% filter((practice == 'false' | practice == FALSE | is.na(practice)), !is.na(err_type), err_type != ''))` participants with error type data.

```{r error-types}
if ("err_type" %in% names(df_raw)) {
  # Get all experimental trials for context
  df_all_exp <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice))
  
  # Get only error trials (where err_type is defined)
  df_error_types <- df_all_exp %>%
    filter(!is.na(err_type), err_type != "") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      err_type = factor(err_type, levels = c("miss", "timeout", "slip"))
    )
  
  if (nrow(df_error_types) > 0) {
    # Summary table: Error type counts and percentages by condition
    error_type_summary <- df_error_types %>%
      group_by(modality, ui_mode, pressure, err_type) %>%
      summarise(Count = n(), .groups = "drop") %>%
      group_by(modality, ui_mode, pressure) %>%
      mutate(
        Total_Errors = sum(Count),
        Pct_Of_Errors = round(100 * Count / Total_Errors, 1)
      ) %>%
      ungroup()
    
    error_type_summary %>%
      kable(caption = paste0("Error Type Distribution by Condition (", get_n_string(df_error_types), " participants, ", nrow(df_error_types), " error trials)")) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Calculate error type percentages BY MODALITY (among all errors for that modality)
    error_by_modality <- df_error_types %>%
      group_by(modality, err_type) %>%
      summarise(count = n(), .groups = "drop") %>%
      group_by(modality) %>%
      mutate(
        total_errors = sum(count),
        pct = round(100 * count / total_errors, 1)
      ) %>%
      ungroup()
    
    # Extract percentages for interpretive summary
    gaze_misses <- error_by_modality %>% filter(modality == "gaze", err_type == "miss")
    gaze_miss_pct <- if(nrow(gaze_misses) > 0) gaze_misses$pct[1] else 0
    
    hand_misses <- error_by_modality %>% filter(modality == "hand", err_type == "miss")
    hand_miss_pct <- if(nrow(hand_misses) > 0) hand_misses$pct[1] else 0
    
    # Overall error rates by modality
    overall_error_rates <- df_all_exp %>%
      group_by(modality) %>%
      summarise(
        total_trials = n(),
        error_trials = sum(!is.na(err_type) & err_type != ""),
        error_rate = round(100 * error_trials / total_trials, 1),
        .groups = "drop"
      )
    
    gaze_error_rate <- overall_error_rates %>% filter(modality == "gaze") %>% pull(error_rate)
    hand_error_rate <- overall_error_rates %>% filter(modality == "hand") %>% pull(error_rate)
    
    # Get error type distributions for more detailed summary
    gaze_slips <- error_by_modality %>% filter(modality == "gaze", err_type == "slip")
    gaze_slip_pct <- if(nrow(gaze_slips) > 0) gaze_slips$pct[1] else 0
    
    cat("\n**Error Type Summary:** ")
    cat("Overall error rates were ", gaze_error_rate, "% for gaze and ", hand_error_rate, "% for hand. ")
    cat("Error patterns differed substantially by modality: gaze errors were predominantly slips (", round(gaze_slip_pct, 1), "%), while hand errors were predominantly misses (", round(hand_miss_pct, 1), "%). ")
    cat("This pattern is consistent with the modality characteristics—gaze is more prone to accidental selections (slips) due to the Midas touch problem, while hand pointing is more prone to missing targets. ")
    cat("Adaptive UI did not yet show a clear reduction in any specific error type at N=", n_distinct(df_error_types$pid), ".\n\n")
  } else {
    cat("⚠ No error type data available.\n\n")
  }
}
```



-----

# 13. Block Order & Temporal Effects

**Research Question:** Are there order effects? Does performance improve or degrade over blocks?

**Sample Size:** `r get_n_string(df_all_trials %>% filter(!is.na(block_number)))` participants with block-level data.

**Note:** This section is exploratory/QC only. These analyses serve as quality checks for temporal trends and are not treated as primary inferential outcomes.

```{r block-effects}
# Performance by block number
# Note: TP is only in df_iso, so we'll use movement time and error rate
# Error rates need ALL trials, movement time uses only correct trials

# Error rates from all trials
df_blocks_errors <- df_all_trials %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    error_rate = 1 - mean(is_correct, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    error_mean = mean(error_rate, na.rm = TRUE),
    error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Movement time from correct trials only
df_blocks_rt <- df %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    rt_avg = mean(rt_s, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    rt_mean = mean(rt_avg, na.rm = TRUE),
    rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Combine for convenience
df_blocks <- df_blocks_rt %>%
  left_join(df_blocks_errors, by = c("block_number", "modality", "ui_mode", "pressure"))

# Try to get throughput by block from df_iso
# Join df_iso with block information
if ("block_number" %in% names(df_raw)) {
  df_blocks_tp <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, block_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct() %>%
    left_join(
      df_iso %>% mutate(
        pressure = as.character(pressure),
        modality = as.character(modality),
        ui_mode = as.character(ui_mode),
        pid = as.character(pid)
      ),
      by = c("pid", "modality", "ui_mode", "pressure", "A", "W")
    ) %>%
    filter(!is.na(TP), !is.na(block_number)) %>%
    group_by(block_number, modality, ui_mode, pressure, pid) %>%
    summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
    group_by(block_number, modality, ui_mode, pressure) %>%
    summarise(
      TP_mean = mean(TP_avg, na.rm = TRUE),
      TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
} else {
  df_blocks_tp <- data.frame()
}
```


```{r plot-blocks-rt}
#| fig-cap: "Performance Across Blocks: Movement Time. Movement time by block number. Lower is better. Shaded regions show ±1 SE."

# Movement time by block
p2 <- ggplot(df_blocks, aes(x = block_number, y = rt_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = rt_mean - rt_se, ymax = rt_mean + rt_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  labs(
    title = "Performance Across Blocks: Movement Time",
    subtitle = "Movement time by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Movement Time (s)",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p2)

# Error rate by block
# Check what conditions we have for blocks
block_summary_table <- df_blocks %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    n_blocks = n(),
    mean_error = round(mean(error_mean, na.rm = TRUE), 4),
    .groups = "drop"
  ) %>%
  mutate(
    Modality = str_to_title(modality),
    `UI Mode` = str_to_title(ui_mode),
    Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
    `N Blocks` = n_blocks,
    `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01)
  ) %>%
  select(Modality, `UI Mode`, Pressure, `N Blocks`, `Mean Error Rate`)

block_summary_table %>%
  kable(caption = "Block-Level Data Summary by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-blocks-error}
#| fig-cap: "Performance Across Blocks: Error Rate. Error rate by block number. Lower is better. Shaded regions show ±1 SE."

p3 <- ggplot(df_blocks, aes(x = block_number, y = error_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = error_mean - error_se, ymax = error_mean + error_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
  labs(
    title = "Performance Across Blocks: Error Rate",
    subtitle = "Error rate by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Error Rate",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p3)
```

-----

# 14. Spatial Patterns & Heatmaps (Exploratory/Descriptive)

**Research Question:** Are there spatial biases in performance? Do some screen regions show better/worse performance?

*This analysis is exploratory/descriptive visualization only. No formal inferential tests are run in this section.*

**Sample Size:** `r get_n_string(df_all_trials %>% filter(!is.na(target_center_x), !is.na(target_center_y)))` participants with spatial position data.

**Note:** These spatial visualizations are exploratory and serve as descriptive quality checks. They are not treated as primary inferential outcomes. At N=`r n_distinct(df_all_trials %>% filter(!is.na(target_center_x), !is.na(target_center_y)) %>% pull(pid))`, interpretation is limited, but these plots may be useful for understanding XR-specific spatial patterns (e.g., top vs bottom of visual field).

## Performance by Target Position

```{r spatial-heatmap}
# Create spatial performance heatmap
# Error rates need ALL trials, movement time uses only correct trials
if ("target_center_x" %in% names(df_all_trials) && "target_center_y" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_spatial_errors <- df_all_trials %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_error = 1 - mean(is_correct, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Movement time from correct trials only
  df_spatial_rt <- df %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_rt = mean(rt_s, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Combine
  df_spatial <- df_spatial_rt %>%
    left_join(df_spatial_errors, by = c("x_bin_num", "y_bin_num", "modality", "ui_mode")) %>%
    mutate(n_trials = pmax(n_trials.x, n_trials.y, na.rm = TRUE)) %>%
    select(-n_trials.x, -n_trials.y)
  
  if (nrow(df_spatial) > 0) {
    # Movement time heatmap
    p1 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_rt)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, 
                 labeller = labeller(
                   modality = function(x) str_to_title(x),
                   ui_mode = function(x) str_to_title(x)
                 ),
                 drop = TRUE) +
      scale_fill_viridis_c(name = "MT (s)", option = "plasma", direction = -1) +
      labs(
        title = "Spatial Performance Heatmap: Movement Time",
        subtitle = "Darker colors indicate faster movement times. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p1)
    
    # Error rate heatmap
    p2 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_error)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, 
                 labeller = labeller(
                   modality = function(x) str_to_title(x),
                   ui_mode = function(x) str_to_title(x)
                 ),
                 drop = TRUE) +
      scale_fill_viridis_c(name = "Error\nRate", option = "inferno", direction = 1) +
      labs(
        title = "Spatial Performance Heatmap: Error Rate",
        subtitle = "Darker colors indicate higher error rates. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p2)
  } else {
    cat("⚠ Insufficient spatial data for heatmap visualization.\n")
  }
} else {
  cat("⚠ Target position columns (target_center_x, target_center_y) not found.\n")
}
```

## Error Density Heatmap

*Where do endpoint errors occur? Are there systematic spatial biases?*

```{r error-density-heatmap}
# Error density heatmap for gaze modality
# Recalculate error data to ensure we have it
if ("endpoint_x" %in% names(df) && "target_center_x" %in% names(df)) {
  df_error_spatial <- df %>%
    filter(
      !is.na(endpoint_x), !is.na(endpoint_y),
      !is.na(target_center_x), !is.na(target_center_y),
      correct == TRUE | correct == "true" | correct == 1
    ) %>%
    mutate(
      err_x = as.numeric(endpoint_x) - as.numeric(target_center_x),
      err_y = as.numeric(endpoint_y) - as.numeric(target_center_y)
    )
  
  # Focus on gaze modality
  df_error_gaze <- df_error_spatial %>%
    filter(str_to_lower(modality) == "gaze") %>%
    filter(!is.na(err_x), !is.na(err_y), is.finite(err_x), is.finite(err_y))
} else {
  df_error_gaze <- data.frame()
}

if (nrow(df_error_gaze) > 0) {
  # Check actual data range
  err_x_range <- range(df_error_gaze$err_x, na.rm = TRUE)
  err_y_range <- range(df_error_gaze$err_y, na.rm = TRUE)
  
  # Use actual data range, but cap extreme outliers
  x_limit <- min(100, max(abs(err_x_range), na.rm = TRUE) * 1.2)
  y_limit <- min(100, max(abs(err_y_range), na.rm = TRUE) * 1.2)
  
  # Filter to reasonable range
  df_error_gaze <- df_error_gaze %>%
    filter(
      abs(err_x) <= x_limit,
      abs(err_y) <= y_limit
    )
  
  if (nrow(df_error_gaze) > 0) {
    # 2D density heatmap
    p1 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
      stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
      geom_vline(xintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_fill_viridis_c(name = "Density", option = "plasma") +
      coord_fixed(ratio = 1) +
      labs(
        title = "Endpoint Error Density: Gaze Modality",
        subtitle = paste("Heatmap shows where endpoints cluster relative to target center (0,0).",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p1)
    
    # Hexbin plot - COMMENTED OUT due to scaling issues
    # # Hexbin plot - use actual data range for limits
    # # Calculate number of bins based on data
    # n_bins <- min(20, max(5, round(sqrt(nrow(df_error_gaze)) / 2)))
    # 
    # # Get actual data limits for setting axis ranges
    # x_min <- min(df_error_gaze$err_x, na.rm = TRUE)
    # x_max <- max(df_error_gaze$err_x, na.rm = TRUE)
    # y_min <- min(df_error_gaze$err_y, na.rm = TRUE)
    # y_max <- max(df_error_gaze$err_y, na.rm = TRUE)
    # 
    # # Add some padding
    # x_pad <- (x_max - x_min) * 0.1
    # y_pad <- (y_max - y_min) * 0.1
    # 
    # p2 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
    #   geom_hex(bins = n_bins, alpha = 0.8) +
    #   geom_vline(xintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   geom_hline(yintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
    #   scale_fill_viridis_c(name = "Count", option = "plasma", na.value = "white") +
    #   coord_fixed(ratio = 1, xlim = c(x_min - x_pad, x_max + x_pad), 
    #               ylim = c(y_min - y_pad, y_max + y_pad)) +
    #   labs(
    #     title = "Endpoint Error Distribution: Gaze Modality (Hexbin)",
    #     subtitle = paste("Hexagonal binning shows error density. Red lines indicate target center.",
    #                     "N =", nrow(df_error_gaze), "trials. Data range: X [", 
    #                     round(x_min, 1), ",", round(x_max, 1), "], Y [",
    #                     round(y_min, 1), ",", round(y_max, 1), "] px."),
    #     x = "Error X (px)",
    #     y = "Error Y (px)"
    #   ) +
    #   theme_minimal(base_size = 14) +
    #   theme(
    #     legend.position = "right",
    #     strip.text = element_text(face = "bold")
    #   )
    # 
    # print(p2)
    
    # Always show scatter plot as well for comparison
    p3 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y, color = ui_mode)) +
      geom_point(alpha = 0.5, size = 1.5) +
      geom_vline(xintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      coord_fixed(ratio = 1, xlim = c(-x_limit, x_limit), ylim = c(-y_limit, y_limit)) +
      labs(
        title = "Endpoint Error Scatter: Gaze Modality",
        subtitle = paste("Individual trial endpoints. Red lines indicate target center.",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p3)
  } else {
    cat("⚠ No error data available after filtering.\n")
  }
} else {
  cat("⚠ Insufficient error spatial data for heatmap visualization.\n")
}
```

-----

# 15. Adaptive UI Mechanism Analysis

## Width Scaling (Target Size Adaptation)

**Research Question:** Does the adaptive UI dynamically change target sizes? How does width scaling relate to performance?

**Sample Size:** `r get_n_string(df_raw %>% filter((practice == 'false' | practice == FALSE | is.na(practice)), !is.na(nominal_width_px)))` participants with width scaling data.

**Status:** In the current dataset, the width scaling mechanism was disabled/misconfigured; all recorded `width_scale_factor` values equal 1.0. Results here serve as a template for future analysis once scaling is active.

*The adaptive UI may scale target widths based on performance. This section examines whether and how target sizes are adjusted.*

```{r width-scaling-analysis}
# Check if width scaling fields exist
if (all(c("nominal_width_px", "displayed_width_px", "width_scale_factor") %in% names(df_raw))) {
  df_width <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(nominal_width_px),
      !is.na(displayed_width_px)
    ) %>%
    mutate(
      # Calculate scale factor if not present
      width_scale_factor = ifelse(
        is.na(width_scale_factor) | width_scale_factor == 0,
        displayed_width_px / nominal_width_px,
        width_scale_factor
      ),
      width_difference = displayed_width_px - nominal_width_px,
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(width_scale_factor),
      is.finite(width_scale_factor),
      width_scale_factor > 0,
      width_scale_factor < 5  # Filter extreme outliers
    )
  
  if (nrow(df_width) > 0) {
    # Check if any scaling actually occurred
    has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
    
    if (!has_scaling) {
      cat("**Note:** No target width scaling was observed in this dataset.\n")
      cat("All `width_scale_factor` values are 1.0 (no scaling applied).\n\n")
      cat("This indicates that the adaptive policy did not trigger during data collection.\n")
      cat("Possible reasons:\n")
      cat("- Hysteresis gate threshold not met (requires N consecutive slow/error trials)\n")
      cat("- Performance thresholds (RT p75, error burst) not exceeded\n")
      cat("- Adaptive policy not properly configured or enabled\n")
      cat("- Participants performed well enough that adaptation was not needed\n\n")
      
      # Still show the summary table for completeness
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N_participants = n_distinct(pid),
          N_trials = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = paste0("Target Width Scaling by Condition (", get_n_string(df_width), " participants, No Scaling Observed)")) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    } else {
      # Summary statistics (when scaling did occur)
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N_participants = n_distinct(pid),
          N_trials = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = paste0("Target Width Scaling by Condition (", get_n_string(df_width), " participants)")) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    }
  } else {
    cat("⚠ No valid width scaling data available.\n")
  }
} else {
  cat("⚠ Width scaling columns not found in dataset.\n")
}
```

```{r plot-width-scaling}
#| fig-cap: !expr 'paste0("Target Width Scale Factor by Condition. ", get_n_string(df_width), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Scale factor = 1.0 means no scaling (nominal size). Values > 1.0 indicate enlarged targets.")'

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Check which modalities have data
  modalities_with_data <- unique(df_width$modality)
  
  # Aggregate to participant-level means for raincloud plot
  df_width_plot <- df_width %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    summarise(width_scale_factor_mean = mean(width_scale_factor, na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(width_scale_factor_mean))
  
  # Ensure all modalities are represented in the plot data (even if empty)
  all_modalities <- c("hand", "gaze")
  missing_modalities <- setdiff(all_modalities, modalities_with_data)
  
  if (length(missing_modalities) > 0 && length(modalities_with_data) > 0) {
    cat("ℹ **Note:** No width scaling data for", paste(missing_modalities, collapse = ", "), "modality.\n\n")
  }
  
  # Only show plot if there's actual variation (not all 1.0)
  # If all values are 1.0, the plot is not informative
  if (has_scaling && nrow(df_width_plot) > 0) {
    p1 <- ggplot(df_width_plot, aes(x = ui_mode, y = width_scale_factor_mean, fill = ui_mode, color = ui_mode)) +
      geom_hline(yintercept = 1.0, linetype = "dashed", color = "red", linewidth = 0.8) +
    # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
    {
      if (has_ggdist) {
        list(
          ggdist::stat_halfeye(
            data = df_width_plot %>% filter(ui_mode == "static"),
            aes(fill = ui_mode),
            side = "left",
            alpha = 0.4,
            width = 0.35,
            .width = 0,
            justification = 1.3,
            point_colour = NA
          ),
          ggdist::stat_halfeye(
            data = df_width_plot %>% filter(ui_mode == "adaptive"),
            aes(fill = ui_mode),
            side = "right",
            alpha = 0.4,
            width = 0.35,
            .width = 0,
            justification = -0.3,
            point_colour = NA
          )
        )
      } else {
        geom_violin(
          alpha = 0.4,
          trim = FALSE,
          scale = "width",
          width = 0.35,
          position = position_dodge(width = 0),
          color = NA
        )
      }
    } +
    # Boxplots inside violins (light gray for visibility)
    geom_boxplot(
      width = 0.15,
      alpha = 0.9,
      outlier.shape = NA,
      position = position_dodge(width = 0),
      fill = "grey90",
      color = "grey70",
      linewidth = 0.7,
      show.legend = FALSE
    ) +
    # Individual participant points (in columns, no jitter)
    geom_point(
      alpha = 0.5,
      size = 1.5,
      position = position_dodge(width = 0),
      show.legend = FALSE
    ) +
    # Connecting lines (between paired conditions)
    geom_line(
      aes(group = pid),
      alpha = 0.3,
      linewidth = 0.4,
      color = "grey60",
      position = position_dodge(width = 0),
      show.legend = FALSE
    ) +
    # Thick black line connecting mean values between conditions
    {
      mean_data <- df_width_plot %>%
        group_by(modality, pressure, ui_mode) %>%
        summarise(mean_value = mean(width_scale_factor_mean, na.rm = TRUE), .groups = "drop") %>%
        pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
        filter(!is.na(mean_static), !is.na(mean_adaptive))
      
      if (nrow(mean_data) > 0) {
        geom_segment(
          data = mean_data,
          aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
          inherit.aes = FALSE,
          color = "black",
          linewidth = 0.9,
          alpha = 0.9
        )
      } else {
        NULL
      }
    } +
    facet_grid(modality ~ pressure, 
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x)),
                 pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
               ),
               drop = TRUE) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0.5, 1.5), breaks = seq(0.5, 1.5, 0.25)) +
    labs(
      x = "UI Mode",
      y = "Width Scale Factor",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 12),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
    )
    
    print(p1)
  } else {
    cat("\n**Note:** Width scale factor plot is not shown because all values are 1.0 (no scaling occurred).\n")
    cat("Showing a plot of constant values would not be informative. The adaptive policy did not trigger during data collection.\n\n")
  }
}
```

```{r plot-width-scaling-over-time}
#| fig-cap: "Width Scaling Over Time (by Trial Number). Shows how target scaling changes throughout the experiment. LOESS smoothing with 95% CI."

if (exists("df_width") && nrow(df_width) > 0 && "trial_number" %in% names(df_width)) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Width scaling over time - show even if no scaling occurred
  df_width_time <- df_width %>%
    filter(!is.na(trial_number), trial_number > 0, trial_number <= 500)
  
  if (nrow(df_width_time) > 0) {
    # Only show the over-time plot if scaling actually occurred
    # If all values are 1.0, the plot is just a flat line which isn't informative
    if (has_scaling) {
      p2 <- ggplot(df_width_time, aes(x = trial_number, y = width_scale_factor, color = ui_mode)) +
        geom_hline(yintercept = 1.0, linetype = "dashed", color = "grey50", linewidth = 0.5) +
        geom_point(alpha = 0.2, size = 1) +
        geom_smooth(method = "loess", span = 0.3, se = TRUE, alpha = 0.2, linewidth = 1.2) +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   ),
                   drop = TRUE) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_y_continuous(limits = c(0.5, 1.5), breaks = seq(0.5, 1.5, 0.25)) +
        labs(
          x = "Trial Number",
          y = "Width Scale Factor",
          color = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
      
      print(p2)
    } else {
      cat("\n**Note:** Width scaling over time plot is not shown because all scale factors are 1.0 (no scaling occurred).\n")
      cat("Showing a plot of constant values would not be informative. The adaptive policy did not trigger during the experiment.\n\n")
    }
  }
}
```

```{r plot-width-vs-performance}
#| fig-cap: "Width Scale Factor vs. Movement Time. Does target scaling improve performance? Linear regression with 95% CI."

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  # Join with performance data
  df_width_perf <- df_width %>%
    filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
    mutate(rt_s = rt_ms / 1000)
  
  # Only show plot if there's actual variation in width scale factor
  if (has_scaling && nrow(df_width_perf) > 0) {
    # Check how much variation exists
    scale_range <- range(df_width_perf$width_scale_factor, na.rm = TRUE)
    scale_sd <- sd(df_width_perf$width_scale_factor, na.rm = TRUE)
    
    p3 <- ggplot(df_width_perf, aes(x = width_scale_factor, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.3, size = 1.5) +
      geom_smooth(method = "lm", se = TRUE, alpha = 0.2, linewidth = 1.2) +
      geom_vline(xintercept = 1.0, linetype = "dashed", color = "grey50", linewidth = 0.5) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_continuous(
        limits = c(max(0.5, scale_range[1] - 0.1), min(1.5, scale_range[2] + 0.1)),
        breaks = scales::pretty_breaks(n = 5)
      ) +
      labs(
        x = "Width Scale Factor",
        y = "Movement Time (s)",
        color = "UI Mode",
        subtitle = paste0("Scale factor range: ", round(scale_range[1], 2), " - ", round(scale_range[2], 2), 
                          " (SD = ", round(scale_sd, 3), "). Negative slope indicates faster RTs with larger targets.")
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        plot.subtitle = element_text(face = "italic", color = "gray40", size = 11, hjust = 0.5)
      )
    
    print(p3)
    
    # Add interpretation note
    cat("\n**Interpretation:** This plot shows the relationship between target width scaling and movement time.\n")
    cat("- A **negative slope** indicates that larger targets (scale factor > 1.0) lead to faster movement times.\n")
    cat("- A **positive slope** would indicate that larger targets lead to slower movement times (unexpected).\n")
    cat("- The dashed vertical line at x = 1.0 marks the baseline (no scaling).\n\n")
  } else {
    cat("\n**Note:** Width scale factor vs. performance plot is not shown because all width scale factors are 1.0 (no scaling occurred).\n\n")
    cat("**Why this matters:** This plot would show whether larger targets (scale factor > 1.0) improve performance by reducing movement time.\n")
    cat("However, since the adaptive policy did not trigger during data collection, all targets remained at their nominal size.\n")
    cat("As a result, there is no variation in the width scale factor, making it impossible to assess the performance relationship.\n\n")
    cat("**Possible reasons for no scaling:**\n")
    cat("- Hysteresis gate threshold not met (requires N consecutive slow/error trials)\n")
    cat("- Performance thresholds (RT p75, error burst) not exceeded\n")
    cat("- Participants performed well enough that adaptation was not needed\n")
    cat("- Adaptive policy not properly configured or enabled\n\n")
  }
}
```

## Alignment Gate Metrics

**Research Question:** If alignment gates are used, how do they affect performance? How often are false triggers detected?

*Alignment gates may be used to ensure proper cursor alignment before selection. This section examines their usage and effectiveness.*

```{r alignment-gate-analysis}
# Check if alignment gate fields exist
if (all(c("alignment_gate_enabled", "alignment_gate_false_triggers") %in% names(df_raw))) {
  df_gate <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      alignment_gate_enabled == TRUE | alignment_gate_enabled == "true"
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    )
  
  if (nrow(df_gate) > 0) {
    # Summary statistics
    gate_summary <- df_gate %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_False_Triggers = round(mean(alignment_gate_false_triggers, na.rm = TRUE), 2),
        SD_False_Triggers = round(sd(alignment_gate_false_triggers, na.rm = TRUE), 2),
        Mean_Recovery_Time = round(mean(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        SD_Recovery_Time = round(sd(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        Mean_Mean_Recovery_Time = round(mean(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        SD_Mean_Recovery_Time = round(sd(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    gate_summary %>%
      kable(caption = "Alignment Gate Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Interpretive summary
    overall_false_triggers <- mean(df_gate$alignment_gate_false_triggers, na.rm = TRUE)
    static_false_triggers <- df_gate %>%
      filter(ui_mode == "static") %>%
      summarise(mean = mean(alignment_gate_false_triggers, na.rm = TRUE)) %>%
      pull(mean)
    adaptive_false_triggers <- df_gate %>%
      filter(ui_mode == "adaptive") %>%
      summarise(mean = mean(alignment_gate_false_triggers, na.rm = TRUE)) %>%
      pull(mean)
    
    cat("\n**Alignment Gate Interpretation:** False triggers were ", ifelse(overall_false_triggers < 0.5, "rare", ifelse(overall_false_triggers < 2, "moderate", "frequent")), 
        " (mean = ", round(overall_false_triggers, 2), " per trial). ", 
        ifelse(abs(static_false_triggers - adaptive_false_triggers) < 0.1, 
               "Adaptive UI did not show a meaningful change in false trigger rate compared to Static.", 
               paste0("Adaptive UI showed a ", ifelse(adaptive_false_triggers < static_false_triggers, "reduction", "increase"), 
                      " in false triggers (", round(adaptive_false_triggers, 2), " vs ", round(static_false_triggers, 2), 
                      ".")), "\n\n")
  } else {
    # Check if columns exist but feature was disabled
    if (all(c("alignment_gate_enabled", "alignment_gate_false_triggers") %in% names(df_raw))) {
      enabled_count <- sum(df_raw$alignment_gate_enabled == TRUE | df_raw$alignment_gate_enabled == "true", na.rm = TRUE)
      disabled_count <- sum(df_raw$alignment_gate_enabled == FALSE | df_raw$alignment_gate_enabled == "false", na.rm = TRUE)
      cat("⚠ **Alignment gate feature was not enabled during data collection.**\n\n")
      cat("**Status:**\n")
      cat("- Alignment gate columns exist in dataset (columns: `alignment_gate_enabled`, `alignment_gate_false_triggers`, `alignment_gate_recovery_time_ms`, `alignment_gate_mean_recovery_time_ms`)\n")
      cat("- Trials with `alignment_gate_enabled = TRUE`: ", enabled_count, "\n")
      cat("- Trials with `alignment_gate_enabled = FALSE`: ", disabled_count, "\n")
      cat("- Trials with null values: ", sum(is.na(df_raw$alignment_gate_enabled)), "\n\n")
      cat("**Explanation:** Alignment gates are an experimental feature (P1) that is disabled by default.\n")
      cat("The feature requires hand input and hover-in-target for ≥80ms before selection.\n")
      cat("To enable alignment gates, set `experimental.alignmentGate = true` in `app/src/config.ts`.\n")
    } else {
      cat("⚠ Alignment gate columns not found in dataset.\n")
    }
  }
} else {
  cat("⚠ Alignment gate columns not found in dataset.\n")
}
```

```{r plot-alignment-gate}
#| fig-cap: "Alignment Gate False Triggers by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - false triggers
  if (sum(!is.na(df_gate$alignment_gate_false_triggers)) > 0) {
    # Aggregate to participant-level means
    df_gate_plot <- df_gate %>%
      filter(!is.na(alignment_gate_false_triggers)) %>%
      group_by(pid, modality, ui_mode, pressure) %>%
      summarise(false_triggers_mean = mean(alignment_gate_false_triggers, na.rm = TRUE), .groups = "drop") %>%
      filter(!is.na(false_triggers_mean))
    
    # Check if gaze modality has all zeros - alignment gates are typically hand-only
    gaze_all_zero <- df_gate_plot %>%
      filter(modality == "gaze") %>%
      summarise(all_zero = all(false_triggers_mean == 0, na.rm = TRUE)) %>%
      pull(all_zero)
    
    if (!is.na(gaze_all_zero) && gaze_all_zero && "hand" %in% unique(df_gate_plot$modality)) {
      df_gate_plot <- df_gate_plot %>% filter(modality == "hand")
      cat("ℹ **Note:** Gaze modality shows zero false triggers (alignment gates are hand-only). Plot shows hand modality only.\n\n")
    }
    
    # Filter to only conditions with actual data (let facet_grid drop empty panels)
    df_gate_plot <- df_gate_plot %>%
      filter(!is.na(false_triggers_mean)) %>%
      mutate(
        modality = factor(modality, levels = c("hand", "gaze")),
        pressure = factor(pressure),
        ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
      )
    
    p1 <- ggplot(df_gate_plot, aes(x = ui_mode, y = false_triggers_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_gate_plot %>% filter(ui_mode == "static", !is.na(false_triggers_mean)),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_gate_plot %>% filter(ui_mode == "adaptive", !is.na(false_triggers_mean)),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_gate_plot %>% filter(!is.na(false_triggers_mean)) %>%
          group_by(modality, pressure, ui_mode) %>%
          summarise(mean_value = mean(false_triggers_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_grid(modality ~ pressure, 
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "False Trigger Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

```{r plot-alignment-recovery}
#| fig-cap: "Alignment Gate Recovery Time by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - recovery time
  # Check if any modality has recovery time data
  has_recovery_data <- sum(!is.na(df_gate$alignment_gate_recovery_time_ms)) > 0
  
  if (has_recovery_data) {
    df_gate_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_recovery_time_ms), alignment_gate_recovery_time_ms > 0)
    
    # Check which modalities have data
    modalities_with_data <- unique(df_gate_recovery$modality)
    all_modalities <- unique(df_gate$modality)
    missing_modalities <- setdiff(all_modalities, modalities_with_data)
    
    if (length(missing_modalities) > 0) {
      cat("ℹ **Note:** No recovery time data for", paste(missing_modalities, collapse = ", "), "modality.\n")
      cat("   This indicates the alignment gate always passed (no false triggers) for these trials.\n\n")
    }
    
    if (nrow(df_gate_recovery) > 0) {
      # Aggregate to participant-level means
      df_gate_recovery_plot <- df_gate_recovery %>%
        group_by(pid, modality, ui_mode, pressure) %>%
        summarise(recovery_time_mean = mean(alignment_gate_recovery_time_ms, na.rm = TRUE), .groups = "drop") %>%
        filter(!is.na(recovery_time_mean))
      
      # Ensure all modality/pressure combinations are represented
      # Filter to only conditions with actual data (let facet_grid drop empty panels)
      df_gate_recovery_plot <- df_gate_recovery_plot %>%
        filter(!is.na(recovery_time_mean)) %>%
        mutate(
          modality = factor(modality, levels = c("hand", "gaze")),
          pressure = factor(pressure),
          ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
        )
      
      p2 <- ggplot(df_gate_recovery_plot, 
                   aes(x = ui_mode, y = recovery_time_mean, fill = ui_mode, color = ui_mode)) +
        # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
        {
          if (has_ggdist) {
            list(
              ggdist::stat_halfeye(
                data = df_gate_recovery_plot %>% filter(ui_mode == "static", !is.na(recovery_time_mean)),
                aes(fill = ui_mode),
                side = "left",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = 1.3,
                point_colour = NA
              ),
              ggdist::stat_halfeye(
                data = df_gate_recovery_plot %>% filter(ui_mode == "adaptive", !is.na(recovery_time_mean)),
                aes(fill = ui_mode),
                side = "right",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = -0.3,
                point_colour = NA
              )
            )
          } else {
            geom_violin(
              alpha = 0.4,
              trim = FALSE,
              scale = "width",
              width = 0.35,
              position = position_dodge(width = 0),
              color = NA
            )
          }
        } +
        # Boxplots inside violins (light gray for visibility)
        geom_boxplot(
          width = 0.15,
          alpha = 0.9,
          outlier.shape = NA,
          position = position_dodge(width = 0),
          fill = "grey90",
          color = "grey70",
          linewidth = 0.7,
          show.legend = FALSE
        ) +
        # Individual participant points (in columns, no jitter)
        geom_point(
          alpha = 0.5,
          size = 1.5,
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Connecting lines (between paired conditions)
        geom_line(
          aes(group = pid),
          alpha = 0.3,
          linewidth = 0.4,
          color = "grey60",
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Thick black line connecting mean values between conditions
        {
          mean_data <- df_gate_recovery_plot %>% filter(!is.na(recovery_time_mean)) %>%
            group_by(modality, pressure, ui_mode) %>%
            summarise(mean_value = mean(recovery_time_mean, na.rm = TRUE), .groups = "drop") %>%
            pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
            filter(!is.na(mean_static), !is.na(mean_adaptive))
          
          if (nrow(mean_data) > 0) {
            geom_segment(
              data = mean_data,
              aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
              inherit.aes = FALSE,
              color = "black",
              linewidth = 0.9,
              alpha = 0.9
            )
          } else {
            NULL
          }
        } +
        facet_grid(modality ~ pressure, 
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   ),
                   drop = TRUE) +
        scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 13) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
        )
      
      print(p2)
    }
  }
}
```

```{r plot-alignment-mean-recovery}
#| fig-cap: "Alignment Gate Mean Recovery Time by Condition. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower is better."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - mean recovery time (averaged across all recoveries in trial)
  # Check if any modality has mean recovery time data
  has_mean_recovery_data <- sum(!is.na(df_gate$alignment_gate_mean_recovery_time_ms)) > 0
  
  if (has_mean_recovery_data) {
    df_gate_mean_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_mean_recovery_time_ms), alignment_gate_mean_recovery_time_ms > 0)
    
    # Check which modalities have data
    modalities_with_data <- unique(df_gate_mean_recovery$modality)
    all_modalities <- unique(df_gate$modality)
    missing_modalities <- setdiff(all_modalities, modalities_with_data)
    
    if (length(missing_modalities) > 0) {
      cat("ℹ **Note:** No mean recovery time data for", paste(missing_modalities, collapse = ", "), "modality.\n")
      cat("   This indicates the alignment gate always passed (no false triggers) for these trials.\n\n")
    }
    
    if (nrow(df_gate_mean_recovery) > 0) {
      # Aggregate to participant-level means
      df_gate_mean_recovery_plot <- df_gate_mean_recovery %>%
        group_by(pid, modality, ui_mode, pressure) %>%
        summarise(mean_recovery_time_mean = mean(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), .groups = "drop") %>%
        filter(!is.na(mean_recovery_time_mean))
      
      # Ensure all modality/pressure combinations are represented
      # Filter to only conditions with actual data (let facet_grid drop empty panels)
      df_gate_mean_recovery_plot <- df_gate_mean_recovery_plot %>%
        filter(!is.na(mean_recovery_time_mean)) %>%
        mutate(
          modality = factor(modality, levels = c("hand", "gaze")),
          pressure = factor(pressure),
          ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
        )
      
      p3 <- ggplot(df_gate_mean_recovery_plot, 
                   aes(x = ui_mode, y = mean_recovery_time_mean, fill = ui_mode, color = ui_mode)) +
        # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
        {
          if (has_ggdist) {
            list(
              ggdist::stat_halfeye(
                data = df_gate_mean_recovery_plot %>% filter(ui_mode == "static", !is.na(mean_recovery_time_mean)),
                aes(fill = ui_mode),
                side = "left",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = 1.3,
                point_colour = NA
              ),
              ggdist::stat_halfeye(
                data = df_gate_mean_recovery_plot %>% filter(ui_mode == "adaptive", !is.na(mean_recovery_time_mean)),
                aes(fill = ui_mode),
                side = "right",
                alpha = 0.4,
                width = 0.35,
                .width = 0,
                justification = -0.3,
                point_colour = NA
              )
            )
          } else {
            geom_violin(
              alpha = 0.4,
              trim = FALSE,
              scale = "width",
              width = 0.35,
              position = position_dodge(width = 0),
              color = NA
            )
          }
        } +
        # Boxplots inside violins (light gray for visibility)
        geom_boxplot(
          width = 0.15,
          alpha = 0.9,
          outlier.shape = NA,
          position = position_dodge(width = 0),
          fill = "grey90",
          color = "grey70",
          linewidth = 0.7,
          show.legend = FALSE
        ) +
        # Individual participant points (in columns, no jitter)
        geom_point(
          alpha = 0.5,
          size = 1.5,
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Connecting lines (between paired conditions)
        geom_line(
          aes(group = pid),
          alpha = 0.3,
          linewidth = 0.4,
          color = "grey60",
          position = position_dodge(width = 0),
          show.legend = FALSE
        ) +
        # Thick black line connecting mean values between conditions
        {
          mean_data <- df_gate_mean_recovery_plot %>% filter(!is.na(mean_recovery_time_mean)) %>%
            group_by(modality, pressure, ui_mode) %>%
            summarise(mean_value = mean(mean_recovery_time_mean, na.rm = TRUE), .groups = "drop") %>%
            pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
            filter(!is.na(mean_static), !is.na(mean_adaptive))
          
          if (nrow(mean_data) > 0) {
            geom_segment(
              data = mean_data,
              aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
              inherit.aes = FALSE,
              color = "black",
              linewidth = 0.9,
              alpha = 0.9
            )
          } else {
            NULL
          }
        } +
        facet_grid(modality ~ pressure, 
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   ),
                   drop = TRUE) +
        scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Mean Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 13) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
        )
      
      print(p3)
    }
  }
}
```

## Task Type Analysis

**Research Question:** Are there different task types (point vs. drag)? How does performance differ across task types?

*If the experiment includes different task types, this section examines performance differences.*

```{r task-type-analysis}
# Check if task_type field exists
if ("task_type" %in% names(df_raw)) {
  df_task <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(task_type),
      task_type != ""
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure),
      task_type = factor(task_type)
    )
  
  if (nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
    # Summary statistics
    task_summary <- df_task %>%
      group_by(task_type, modality, ui_mode) %>%
      summarise(
        N_Trials = n(),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        SD_RT = round(sd(rt_ms, na.rm = TRUE), 1),
        Error_Rate = round(100 * mean(is.na(correct) | correct == FALSE | correct == "false", na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    task_summary %>%
      kable(caption = "Performance by Task Type") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else if (nrow(df_task) > 0) {
    cat("⚠ Only one task type found:", unique(df_task$task_type), "\n")
  } else {
    cat("⚠ No valid task type data available.\n")
  }
} else {
  cat("⚠ task_type column not found in dataset.\n")
}
```

```{r plot-task-type-rt}
#| fig-cap: "Movement Time by Task Type. Raincloud plot: half-violins with boxplots inside, individual points. Comparison of performance across different task types (if multiple exist). Lower is better."

if (exists("df_task") && nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
  # Filter for valid RT and aggregate to participant-level
  df_task_rt_plot <- df_task %>%
    filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
    mutate(rt_s = rt_ms / 1000) %>%
    group_by(pid, modality, task_type, ui_mode) %>%
    summarise(rt_s_mean = mean(rt_s, na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(rt_s_mean))
  
  if (nrow(df_task_rt_plot) > 0) {
    p1 <- ggplot(df_task_rt_plot, aes(x = task_type, y = rt_s_mean, fill = ui_mode, color = ui_mode)) +
      # Use regular violins with proper dodging for side-by-side comparison
      geom_violin(
        alpha = 0.4,
        trim = FALSE,
        scale = "width",
        width = 0.35,
        position = position_dodge(width = 0.9),
        color = NA
      ) +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0.9),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0.9),
        show.legend = FALSE
      ) +
      facet_wrap(~modality, labeller = labeller(
        modality = function(x) paste("Modality:", str_to_title(x))
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Task Type",
        y = "Movement Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

#### Planned Sample Size & Power

Path-length efficiency (actual path / straight-line amplitude) is analyzed at the trial level but interpreted as a within-subject continuous outcome, with expected **medium modality differences** (longer, less efficient paths for gaze) and **small-to-medium UI-mode effects**. We treat **N = 48** as a **reasonable "good N"** for detecting medium effects (dz ≈ 0.4–0.5), and **N = 64** as an ideal target if path efficiency becomes more central to the argument. At both Ns, this analysis is secondary to the core throughput and RT results.

```{r drag-distance-analysis}
# Compute path length from trajectory and derive efficiency metrics
# Note: For pointing tasks, path length is the actual cursor travel distance (px), computed
# from trajectory data (not straight-line amplitude A). Path ratio and efficiency are unitless.
# This analysis requires trajectory data - early participants may not have it

library(jsonlite)
library(purrr)

# Helper function to compute path length from trajectory JSON
path_length <- function(traj_json) {
  if (is.na(traj_json) || traj_json == "" || traj_json == "[]" || traj_json == "null") {
    return(NA_real_)
  }
  pts <- tryCatch(fromJSON(traj_json), error = function(e) NULL)
  if (is.null(pts) || length(pts) == 0 || (is.data.frame(pts) && nrow(pts) < 2)) {
    return(NA_real_)
  }
  # Handle both list and data.frame formats
  if (is.data.frame(pts)) {
    dx <- diff(pts$x)
    dy <- diff(pts$y)
  } else if (is.list(pts) && length(pts) > 0 && "x" %in% names(pts[[1]])) {
    x_vals <- sapply(pts, function(p) p$x)
    y_vals <- sapply(pts, function(p) p$y)
    dx <- diff(x_vals)
    dy <- diff(y_vals)
  } else {
    return(NA_real_)
  }
  sum(sqrt(dx^2 + dy^2), na.rm = TRUE)
}

# Prepare data with computed path length and derived metrics
if ("trajectory" %in% names(df_raw) && "A" %in% names(df_raw)) {
  df_drag <- df_raw %>%
    filter(
      trial_qc_ok,  # Use unified QC flag (practice, zoom, fullscreen, tab hidden, focus blur)
      correct == TRUE | correct == "true" | correct == 1,  # Only successful trials
      !is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000,
      !is.na(A), A > 0,
      # Trajectory-specific QC: require usable trajectories
      if("traj_usable" %in% names(.)) traj_usable == TRUE else TRUE
    ) %>%
    mutate(
      rt_s = rt_ms / 1000,
      # Compute path length from trajectory
      path_length_computed = map_dbl(trajectory, path_length),
      # Use existing drag_distance if numeric and valid, otherwise use computed
      # Convert drag_distance to numeric first to handle character/string values
      drag_distance_raw = if ("drag_distance" %in% names(.)) {
        suppressWarnings(as.numeric(drag_distance))
      } else {
        NA_real_
      },
      # Prefer computed path length, fall back to drag_distance if valid
      drag_distance = ifelse(
        !is.na(path_length_computed) & path_length_computed > 0,
        path_length_computed,
        ifelse(!is.na(drag_distance_raw) & drag_distance_raw > 0, drag_distance_raw, path_length_computed)
      ),
      # Derived metrics
      ratio = drag_distance / A,  # Path ratio (≥1, higher = less efficient)
      eff = A / drag_distance,    # Path efficiency (0-1], higher = more efficient
      excess = drag_distance - A, # Excess distance (px, 0 = straight)
      speed = drag_distance / rt_s, # Effective speed (px/s)
      # Flag outliers
      bad_traj = ratio < 1 | ratio > 5 | is.na(ratio),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(drag_distance),
      drag_distance > 0,
      !bad_traj  # Exclude invalid trajectories
    )
  
  if (nrow(df_drag) > 0) {
    # Summary statistics with derived metrics
    drag_summary <- df_drag %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_Path_Length = round(mean(drag_distance, na.rm = TRUE), 1),
        Mean_Amplitude = round(mean(A, na.rm = TRUE), 1),
        Mean_Ratio = round(mean(ratio, na.rm = TRUE), 2),
        Mean_Efficiency = round(mean(eff, na.rm = TRUE), 3),
        Mean_Excess = round(mean(excess, na.rm = TRUE), 1),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    drag_summary %>%
      kable(caption = "Path Length and Efficiency Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else {
    cat("⚠ No valid trajectory data available for path length computation.\n")
    cat("Note: Path length analysis requires trajectory data. Early participants may not have trajectory logs.\n")
    cat("This analysis will be limited to participants with trajectory data.\n")
  }
} else {
  cat("⚠ Required columns (trajectory, A) not found for path length analysis.\n")
  cat("Path length metrics require trajectory data to compute actual cursor travel distance.\n")
}
```

```{r plot-path-length-hexbin}
#| fig-cap: "Path Length vs. Movement Time (Log-Log Scale). 2D density plot showing the relationship between actual cursor path length and movement time. GAM smooth captures nonlinearity. Log scales handle right-skewed distributions and heteroscedasticity."

if (exists("df_drag") && nrow(df_drag) > 0) {
  # Try to load hexbin, fall back to density2d if not available
  has_hexbin <- requireNamespace("hexbin", quietly = TRUE)
  
  df_plot <- df_drag %>%
    filter(!is.na(drag_distance), drag_distance > 0, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    if (has_hexbin) {
      library(hexbin)
      # Note: geom_hex creates hexagons in data space, which may appear slightly stretched
      # on log scales. This is expected behavior. For better control, we use a single bins parameter.
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_hex(bins = 35, alpha = 0.7) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma", trans = "log10", name = "Count") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   ),
                   drop = TRUE) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), name = "UI Mode") +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          legend.box = "horizontal",
          legend.direction = "horizontal",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    } else {
      # Fallback: use density2d and points
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_point(alpha = 0.1, size = 0.8) +
        stat_density2d(aes(fill = ..level..), geom = "polygon", alpha = 0.3, contour = TRUE) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma", name = "Density") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   ),
                   drop = TRUE) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), name = "UI Mode") +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          legend.box = "horizontal",
          legend.direction = "horizontal",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    }
    
    print(p1)
  }
}

```{r plot-path-efficiency}
#| fig-cap: "Path Efficiency vs. Movement Time. Path efficiency (A / path length) indicates how straight the movement was. Higher efficiency (closer to 1.0) means straighter paths. This plot shows whether inefficient movements lead to longer movement times, and whether adaptive UI improves efficiency."

if (exists("df_drag") && nrow(df_drag) > 0) {
  df_plot <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    p2 <- ggplot(df_plot, aes(x = eff, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.15, size = 1) +
      geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                  alpha = 0.3, linewidth = 1.1, method.args = list(family = "gaussian")) +
      geom_vline(xintercept = 0.9, linetype = "dashed", alpha = 0.4, linewidth = 0.5) +
      scale_y_log10(labels = scales::label_number()) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Path Efficiency (A / path length)",
        y = "Movement Time (s, log10)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p2)
  }
}
```

```{r plot-path-ratio-by-id}
#| fig-cap: "Path Ratio by Index of Difficulty. Mean path ratio (path length / amplitude) binned by ID quartiles. Shows whether excess path length increases with task difficulty, and whether adaptive UI reduces this effect. Higher ratio indicates less efficient (more curved) movements."

if (exists("df_drag") && nrow(df_drag) > 0 && "ID" %in% names(df_drag)) {
  df_filtered <- df_drag %>%
    filter(!is.na(ID), !is.na(ratio), ratio > 0)
  
  if (nrow(df_filtered) > 0) {
    # Compute quantiles and ensure breaks are unique
    id_quantiles <- quantile(df_filtered$ID, probs = seq(0, 1, 0.25), na.rm = TRUE, names = FALSE)
    id_quantiles <- unique(sort(id_quantiles))
    
    # Need at least 2 unique break points for cut() to work
    # cut() creates length(breaks) - 1 intervals, so we need length(breaks) - 1 labels
    if (length(id_quantiles) >= 2) {
      # Determine how many bins we can create based on unique quantile values
      n_unique_quantiles <- length(id_quantiles)
      # We need n_unique_quantiles break points to create n_unique_quantiles - 1 intervals
      
      if (n_unique_quantiles >= 5) {
        # Can create 4 bins (quartiles)
        breaks <- id_quantiles
        labels <- c("Q1 (Low)", "Q2", "Q3", "Q4 (High)")  # 4 labels for 4 intervals
      } else if (n_unique_quantiles >= 4) {
        # Can create 3 bins
        breaks <- c(id_quantiles[1], id_quantiles[2], id_quantiles[n_unique_quantiles])
        labels <- c("Low", "Medium", "High")  # 3 labels for 3 intervals
      } else if (n_unique_quantiles >= 3) {
        # Can create 2 bins
        breaks <- c(id_quantiles[1], id_quantiles[n_unique_quantiles])
        labels <- c("Low", "High")  # 2 labels for 2 intervals
      } else {
        # Only 2 unique values - can only create 1 bin, which is not useful
        breaks <- NULL
        labels <- NULL
      }
      
      # Only proceed if we have valid breaks and labels match intervals
      if (!is.null(breaks) && length(breaks) >= 2 && length(breaks) == length(labels) + 1) {
        df_binned <- df_filtered %>%
          mutate(
            ID_bin = cut(ID, 
                         breaks = breaks,
                         include.lowest = TRUE,
                         labels = labels)
          ) %>%
          filter(!is.na(ID_bin)) %>%
          group_by(modality, pressure, ui_mode, ID_bin) %>%
          summarise(
            n = n(),
            mean_ratio = mean(ratio, na.rm = TRUE),
            se_ratio = sd(ratio, na.rm = TRUE) / sqrt(n()),
            mean_eff = mean(eff, na.rm = TRUE),
            .groups = "drop"
          )
        
        if (nrow(df_binned) > 0 && sum(df_binned$n) > 0) {
          p3 <- ggplot(df_binned, aes(x = ID_bin, y = mean_ratio, group = ui_mode, color = ui_mode)) +
            geom_line(linewidth = 1, alpha = 0.8) +
            geom_point(size = 2.5) +
            geom_errorbar(aes(ymin = mean_ratio - se_ratio, ymax = mean_ratio + se_ratio),
                          width = 0.1, linewidth = 0.5, alpha = 0.6) +
            geom_hline(yintercept = 1.0, linetype = "dashed", alpha = 0.3, linewidth = 0.5) +
            facet_grid(modality ~ pressure,
                       labeller = labeller(
                         modality = function(x) paste("Modality:", str_to_title(x)),
                         pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                       ),
                       drop = TRUE) +
            scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
            labs(
              x = "Index of Difficulty (binned)",
              y = "Mean Path Ratio (path length / amplitude)",
              color = "UI Mode"
            ) +
            theme_minimal(base_size = 14) +
            theme(
              legend.position = "top",
              strip.text = element_text(face = "bold", size = 12),
              strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
              panel.grid.minor = element_blank(),
              axis.text.x = element_text(angle = 45, hjust = 1)
            )
          
          print(p3)
        } else {
          cat("⚠ Insufficient data for ID binning plot.\n")
        }
      } else {
        cat("⚠ Cannot create ID bins: insufficient variation or invalid break points.\n")
        cat("Skipping ID binning plot.\n")
      }
    } else {
      cat("⚠ Insufficient ID variation for binning (all values are similar).\n")
      cat("Skipping ID binning plot.\n")
    }
  } else {
    cat("⚠ No valid ID/ratio data for binning plot.\n")
  }
}
```

```{r plot-path-efficiency-individual}
#| fig-cap: "Individual Differences in Path Efficiency. Thin lines show per-participant mean efficiency by UI mode. Thick line and large point show condition mean. Shows whether adaptive UI consistently improves efficiency across participants."

if (exists("df_drag") && nrow(df_drag) > 0 && "pid" %in% names(df_drag)) {
  df_pid <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1) %>%
    group_by(pid, modality, pressure, ui_mode) %>%
    summarise(
      mean_eff = mean(eff, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 5)  # Only participants with sufficient data
  
  if (nrow(df_pid) > 0) {
    p4 <- ggplot(df_pid, aes(x = ui_mode, y = mean_eff, group = pid)) +
      geom_line(alpha = 0.2, linewidth = 0.5) +
      geom_point(alpha = 0.3, size = 1.5) +
      stat_summary(aes(group = 1), fun = mean, geom = "line", linewidth = 1.2, color = "black") +
      stat_summary(aes(group = 1), fun = mean, geom = "point", size = 3, color = "black", shape = 21, fill = "white") +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Mean Path Efficiency (A / path length)",
        caption = "Thin lines: individual participants. Thick line: condition mean."
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "none",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p4)
  }
}
```

-----

# 16. Gaze-Specific Analysis: Hover/Dwell Time (Exploratory/Descriptive)

**Research Question:** How does hover/dwell time vary across gaze conditions? Does adaptive UI affect dwell time before confirmation?

*This analysis is exploratory/descriptive only. No formal inferential tests are run in this section at this stage.*

#### Planned Sample Size & Power

Hover/dwell time is modeled only for **gaze trials** with fixed effects for UI mode and pressure. Because this shrinks the effective dataset and the expected UI-mode effects may be **small-to-medium** (dz ≈ 0.3–0.5), we treat this analysis as **exploratory unless N ≥ 64**. At **N = 48**, the study is adequately powered for medium effects but underpowered for smaller ones; at **N = 64**, we expect ≈0.80 power even if the UI-mode effect is closer to dz ≈ 0.35, based on standard repeated-measures calculations and mixed-model heuristics (Cohen, 1988; Kumle et al., 2021).

**Sample Size:** `r get_n_string(df_raw %>% filter((practice == "false" | practice == FALSE | is.na(practice)), modality == "gaze", !is.na(hover_ms), hover_ms > 0))` participants with gaze hover/dwell data.

**Note:** This analysis is exploratory. CIs may be wide and results should be treated as preliminary.

*Hover/dwell time represents the duration the cursor remains in the target before confirmation in gaze trials. This metric is specific to gaze modality and reflects the "Midas touch" problem—the need for deliberate confirmation to avoid unintended selections.*

```{r hover-analysis}
# Analyze hover_ms for gaze trials only
if ("hover_ms" %in% names(df_raw)) {
  df_hover <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      modality == "gaze",
      !is.na(hover_ms),
      hover_ms > 0,
      hover_ms <= 6000  # Reasonable upper bound
    ) %>%
    mutate(
      hover_s = hover_ms / 1000,
      modality = factor(modality, levels = c("gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure),
      pid = factor(pid)
    )
  
  if (nrow(df_hover) > 0 && n_distinct(df_hover$pid) > 0) {
    # Summary statistics
    hover_summary <- df_hover %>%
      group_by(ui_mode, pressure) %>%
      summarise(
        N_participants = n_distinct(pid),
        N_trials = n(),
        Mean_Hover_ms = round(mean(hover_ms, na.rm = TRUE), 1),
        SD_Hover_ms = round(sd(hover_ms, na.rm = TRUE), 1),
        Median_Hover_ms = round(median(hover_ms, na.rm = TRUE), 1),
        Q25 = round(quantile(hover_ms, 0.25, na.rm = TRUE), 1),
        Q75 = round(quantile(hover_ms, 0.75, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    hover_summary %>%
      kable(caption = paste0("Hover/Dwell Time (ms) by Condition - Gaze Modality (", get_n_string(df_hover), " participants)")) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Compute adaptive vs static difference for summary
    hover_means <- df_hover %>%
      group_by(ui_mode) %>%
      summarise(mean_hover = mean(hover_ms, na.rm = TRUE), .groups = "drop")
    
    static_mean <- hover_means %>% filter(ui_mode == "static") %>% pull(mean_hover)
    adaptive_mean <- hover_means %>% filter(ui_mode == "adaptive") %>% pull(mean_hover)
    
    if (length(static_mean) > 0 && length(adaptive_mean) > 0) {
      diff_ms <- adaptive_mean - static_mean
      cat("\n**Hover Time Summary:** Adaptive UI ", ifelse(diff_ms < 0, "reduced", "increased"), 
          " dwell time by approximately ", round(abs(diff_ms), 0), " ms (Static: ", round(static_mean, 0), 
          " ms, Adaptive: ", round(adaptive_mean, 0), " ms).\n\n")
    } else {
      cat("\n**Hover Time Summary:** Interpretation may be limited due to sample size.\n\n")
    }
  } else {
    cat("⚠ No valid hover/dwell time data available for gaze trials.\n")
  }
} else {
  cat("⚠ hover_ms column not found in dataset.\n")
}
```

```{r plot-hover}
#| fig-cap: !expr 'if(exists("df_hover") && nrow(df_hover) > 0) paste0("Hover/Dwell Time (ms) by UI Mode - Gaze Modality. ", get_n_string(df_hover), " participants. Raincloud plot: mirrored half-violins (Static←left, Adaptive→right) with boxplots inside, individual points in columns, connecting lines show paired comparisons. Lower indicates faster confirmation.") else "Hover/Dwell Time plot (no data available)"'

if (exists("df_hover") && nrow(df_hover) > 0) {
  # Aggregate to participant-level means for raincloud plot
  df_hover_plot <- df_hover %>%
    group_by(pid, ui_mode, pressure) %>%
    summarise(hover_ms_mean = mean(hover_ms, na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(hover_ms_mean))
  
  if (nrow(df_hover_plot) > 0) {
    # Raincloud plot for Hover Time
    p_hover <- ggplot(df_hover_plot, aes(x = ui_mode, y = hover_ms_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_hover_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_hover_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_hover_plot %>%
          group_by(pressure, ui_mode) %>%
          summarise(mean_value = mean(hover_ms_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_wrap(~pressure, labeller = labeller(
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Hover/Dwell Time (ms)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p_hover)
  }
}
```

-----

::: {.callout-note collapse=true}
## Advanced analyses

- Hierarchical LBA (verification-time RTs) - see Section 16
- Control-theory kinematics (velocity profiles, submovement decomposition) - see Section 17
:::

**Implementation Notes:**
- LBA requires RT data from the verification phase (time from target entry to selection)
- Model fitting can be done using `RWiener` or `rtdists` packages
- Key parameters to estimate: drift rate (v), threshold (b), starting point (A), non-decision time (t0)
- Hypothesis: Adaptive conditions should show lower threshold (b), indicating less caution needed

-----

# 17. Linear Ballistic Accumulator (LBA) Analysis

**Research Question:** Can we model the verification phase (time from target entry to selection) using LBA parameters? Do adaptive conditions show different decision thresholds?

*Linear Ballistic Accumulator models decompose reaction time into decision and non-decision components. For gaze-based interaction, we hypothesize that adaptive UI reduces decision threshold (b), indicating less caution needed when targets are easier to acquire.*

#### Sample Size & Power

The hierarchical LBA analysis is run on verification-time RTs with parameters (v, b, A, t₀) varying by modality and UI mode. Power and parameter recovery in diffusion/accumulator models depend more on **trials per participant** than on sheer N, but group-level comparisons still require a sufficient number of participants. Studies on parameter recovery for DDM/LBA and related models generally recommend **≥100 trials per condition** and **at least 30–40 participants** for stable hierarchical estimates. Our design (≈24 trials × 8 conditions ≈ 192 trials per participant) is strong on the trial side. For **group-level parameter differences**, a **target of N ≥ 64** is advisable for narrower credible intervals on parameter contrasts.

```{r lba-analysis, eval=file.exists("analysis/results/lba_parameters.json")}
# Check if LBA analysis has been run
lba_results_file <- "analysis/results/lba_parameters.json"

if (file.exists(lba_results_file)) {
  # Load LBA parameters
  lba_params <- jsonlite::fromJSON(lba_results_file)
  
  cat("**LBA Analysis Results**\n\n")
  cat("Parameters estimated using hierarchical Bayesian LBA model (PyMC).\n\n")
  
  # Display parameters by condition
  cat("**LBA Parameters by Modality and UI Mode:**\n\n")
  
  # Create summary table
  lba_summary <- data.frame()
  for (mod in names(lba_params)) {
    for (ui_mode in names(lba_params[[mod]])) {
      params <- lba_params[[mod]][[ui_mode]]
      lba_summary <- rbind(lba_summary, data.frame(
        Modality = mod,
        UI_Mode = ui_mode,
        t0_mu = round(params$t0_mu, 3),
        vc_base_mu = round(params$vc_base_mu, 3),
        vc_slope_mu = round(params$vc_slope_mu, 3),
        gap_int_mu = round(params$gap_int_mu, 3),
        gap_slope_mu = round(params$gap_slope_mu, 3),
        ve_mu = round(params$ve_mu, 3)
      ))
    }
  }
  
  print(knitr::kable(lba_summary, caption = "LBA Parameter Estimates"))
  
  # Check for trace file and diagnostics
  trace_file <- "analysis/results/lba_trace.nc"
  if (file.exists(trace_file)) {
    cat("\n**Model Diagnostics:**\n")
    cat("- MCMC trace saved to: `lba_trace.nc`\n")
    cat("- Trace plots available: `lba_trace_plot.png`\n")
    cat("- Parameter summary: `lba_parameters_summary.csv`\n\n")
    cat("**Note:** Review trace plots and R-hat diagnostics to assess convergence.\n\n")
  }
  
  # Interpretation
  cat("**Parameter Interpretation:**\n")
  cat("- **t0 (non-decision time):** Time for stimulus encoding and motor execution, varies by modality and UI mode\n")
  cat("- **vc_base (drift rate base):** Baseline accumulation rate for correct responses\n")
  cat("- **vc_slope (drift rate slope):** How drift rate changes with task difficulty (ID)\n")
  cat("- **gap_int (threshold gap intercept):** Baseline decision threshold above start point\n")
  cat("- **gap_slope (threshold gap slope):** How threshold changes with pressure (speed-accuracy tradeoff)\n")
  cat("- **ve (error drift rate):** Accumulation rate for error responses\n\n")
  
} else {
  cat("**LBA Analysis Status:**\n\n")
  cat("⚠️ LBA analysis has not been run yet.\n\n")
  cat("**To run LBA analysis:**\n")
  cat("```bash\n")
  cat("python3 analysis/py/lba.py --input data/clean/ --output analysis/results/\n")
  cat("```\n\n")
  cat("**Note:** Requires Python 3.8+ (pandas 2.x requirement). Use `python3` if your default `python` is Python 3.7 or earlier.\n\n")
  cat("**Requirements:**\n")
  cat("- PyMC installed: `pip install pymc arviz`\n")
  cat("- Cleaned trial data in `data/clean/`\n")
  cat("- Verification time data (verification_time_ms column)\n\n")
  cat("**Data Check:**\n")
  verification_data_available <- if(exists("df") && "verification_time_ms" %in% names(df)) {
    sum(!is.na(df$verification_time_ms) & df$verification_time_ms > 0, na.rm = TRUE)
  } else {
    0
  }
  cat("- Verification time data available: ", verification_data_available, " trials\n")
}
```

```{r lba-exgauss-check, eval=file.exists("analysis/figures/exgauss_overall.png")}
# Check if ex-Gaussian analysis has been run
if (file.exists("analysis/figures/exgauss_overall.png")) {
  cat("**Ex-Gaussian Distribution Analysis**\n\n")
  cat("RT distribution tails have been analyzed using ex-Gaussian fitting.\n\n")
  cat("**Plots available:**\n")
  cat("- Overall distribution: `exgauss_overall.png`\n")
  
  if (file.exists("analysis/figures/exgauss_modality_gaze.png")) {
    cat("- Gaze modality: `exgauss_modality_gaze.png`\n")
  }
  if (file.exists("analysis/figures/exgauss_modality_hand.png")) {
    cat("- Hand modality: `exgauss_modality_hand.png`\n")
  }
  
  if (file.exists("analysis/figures/exgauss_parameters.json")) {
    exgauss_params <- jsonlite::fromJSON("analysis/figures/exgauss_parameters.json")
    cat("\n**Ex-Gaussian Parameters:**\n")
    cat("- μ (Gaussian mean): ", round(exgauss_params$mu, 3), " s\n")
    cat("- σ (Gaussian std): ", round(exgauss_params$sigma, 3), " s\n")
    cat("- τ (Exponential rate): ", round(exgauss_params$tau, 3), " s\n\n")
  }
  
  cat("\n**To regenerate ex-Gaussian analysis:**\n")
  cat("```bash\n")
  cat("python3 analysis/py/exgauss_check.py --input data/clean/ --output analysis/figures/\n")
  cat("```\n\n")
}
```

-----

# 18. Control Theory Analysis: Submovement Models

**Research Question:** How does the control loop efficiency differ across conditions? Do adaptive interventions reduce movement corrections?

#### Sample Size & Power

Trajectory-based kinematic metrics (velocity profiles, jerk, normalized jerk, primary vs corrective phases) are rich but correlated and often noisier than basic RT/TP measures. Because they are derived from the same trial-level data, their within-subject effect sizes are likely **small-to-medium**, with substantial individual differences. For these analyses, **N = 64** is a good target for stronger inferential claims about UI-mode improvements in movement smoothness or control-loop efficiency. As with LBA, **simulation-based power analyses tailored to your specific metrics** would be ideal but are beyond the scope of this report (Kumle et al., 2021).

Submovement metrics in this report include pre-computed `submovement_count` (see Section 10). Full trajectory-based control-theory models (jerk, duration-normalized jerk, primary vs corrective phases) can be implemented using trajectory logging data.

*The Optimized Submovement Model [@meyer1988] posits that pointing movements are composed of a primary ballistic impulse followed by n corrective submovements. The Submovement Count (N_sub) serves as a proxy for the efficiency of the control loop. In gaze-based interaction, simulated lag and saccadic blindness force users into an intermittent control regime, theoretically increasing N_sub.*

**Power Analysis Summary:**
- **N=64 target** provides good power for medium main effects (dz≈0.41, power≈0.80)
- **Interactions may be underpowered** unless large (treat as exploratory)
- **60fps trajectory data** improves measurement precision but doesn't increase effective N
- **Key considerations:** Use duration-normalized smoothness metrics, control for multiple comparisons (FDR), pre-specify outcomes
- See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed recommendations

```{r control-theory-process, eval=("trajectory" %in% names(df_raw))}
# Check if trajectory data is available and process it
# Note: Full trajectory processing is computationally intensive
# For now, we'll use pre-computed metrics if available, or process a sample

df_traj_available <- df_raw %>%
  filter(
    practice == "false" | practice == FALSE | is.na(practice),
    !is.na(trajectory),
    trajectory != "",
    trajectory != "null",
    trajectory != "[]"
  )

if (nrow(df_traj_available) > 0) {
  cat("✅ **Trajectory Data Available**\n\n")
  cat("**Note:** Full trajectory processing requires parsing JSON and computing derivatives.\n")
  cat("For this report, we use pre-computed `submovement_count` from Section 10.\n")
  cat("Advanced trajectory processing (velocity profiles, jerk) can be implemented\n")
  cat("using the `analysis/r/process_trajectory.R` script for detailed analyses.\n\n")
  cat("- N trials with trajectory:", nrow(df_traj_available), "\n")
  cat("- Participants:", n_distinct(df_traj_available$pid), "\n\n")
  
  # For now, use existing submovement_count data
  # Full trajectory processing would go here (see process_trajectory.R script)
  df_with_traj <- df
  
  cat("**Current Analysis:** Using pre-computed metrics from Section 10.\n")
  cat("**Future Enhancement:** Full trajectory processing available in `analysis/r/process_trajectory.R`\n\n")
} else {
  cat("⚠️ **No trajectory data available**\n\n")
  cat("Trajectory data is required for advanced control theory analysis.\n")
  cat("This section will show basic submovement_count analysis from Section 10.\n\n")
  df_with_traj <- df
}
```

```{r control-theory-setup}
# Setup: Determine which submovement column to use
# This chunk runs first to set up variables for subsequent chunks
submov_col <- if ("submovement_count_recomputed" %in% names(df)) {
  "submovement_count_recomputed"
} else if ("submovement_count" %in% names(df)) {
  "submovement_count"
} else {
  NULL
}

# Create df_ct for use in subsequent chunks
if (!is.null(submov_col)) {
  df_ct <- df %>%
    filter(!is.na(.data[[submov_col]]), .data[[submov_col]] >= 0)
} else {
  df_ct <- data.frame()  # Empty data frame
}
```

### Submovement Count (Control Loop Efficiency)

```{r control-theory-descriptive, eval=!is.null(submov_col) && exists("df_ct") && nrow(df_ct) > 0}
# Descriptive Statistics for Control Theory Metrics
# Using pre-computed submovement_count from Section 10

# Summary by condition
submov_summary <- df_ct %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N_participants = n_distinct(pid),
    N_trials = n(),
    `Mean Submovements` = round(mean(.data[[submov_col]], na.rm = TRUE), 2),
    `SD Submovements` = round(sd(.data[[submov_col]], na.rm = TRUE), 2),
    `Median Submovements` = round(median(.data[[submov_col]], na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

submov_summary %>%
  kable(caption = paste0("Submovement Count by Condition (", 
                         get_n_string(df_ct), " participants, using ", submov_col, ")")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```

**Interpretation:** Lower submovement counts indicate smoother, more ballistic movements. Adaptive UI is expected to reduce corrective submovements by expanding targets.

```{r plot-control-theory-submovements, eval=!is.null(submov_col) && exists("df_ct") && nrow(df_ct) > 0}
#| fig-cap: !expr 'if(exists("df_ct") && nrow(df_ct) > 0) paste0("Submovement Count (Control Loop Efficiency) by Modality and UI Mode. ", get_n_string(df_ct), " participants. Lower values indicate smoother, more ballistic movements.") else "Submovement plot (no data available)"'

if (!is.null(submov_col) && exists("df_ct") && nrow(df_ct) > 0) {
  df_ct_plot <- df_ct %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    summarise(submov_mean = mean(.data[[submov_col]], na.rm = TRUE), .groups = "drop") %>%
    filter(!is.na(submov_mean))
  
  # Check if hand modality has all zeros - if so, filter to only gaze
  hand_all_zero <- df_ct_plot %>%
    filter(modality == "hand") %>%
    summarise(all_zero = all(submov_mean == 0, na.rm = TRUE)) %>%
    pull(all_zero)
  
  if (!is.na(hand_all_zero) && hand_all_zero && "gaze" %in% unique(df_ct_plot$modality)) {
    df_ct_plot <- df_ct_plot %>% filter(modality == "gaze")
    cat("ℹ **Note:** Hand modality shows zero submovements (smooth movements). Plot shows gaze modality only.\n\n")
  }
  
  if (nrow(df_ct_plot) > 0) {
    # Raincloud plot for Submovement Count (same style as Section 10)
    p1 <- ggplot(df_ct_plot, aes(x = ui_mode, y = submov_mean, fill = ui_mode, color = ui_mode)) +
      # Mirrored half-violins: Static extends LEFT (outward), Adaptive extends RIGHT (outward)
      {
        if (has_ggdist) {
          list(
            ggdist::stat_halfeye(
              data = df_ct_plot %>% filter(ui_mode == "static"),
              aes(fill = ui_mode),
              side = "left",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = 1.3,
              point_colour = NA
            ),
            ggdist::stat_halfeye(
              data = df_ct_plot %>% filter(ui_mode == "adaptive"),
              aes(fill = ui_mode),
              side = "right",
              alpha = 0.4,
              width = 0.35,
              .width = 0,
              justification = -0.3,
              point_colour = NA
            )
          )
        } else {
          geom_violin(
            alpha = 0.4,
            trim = FALSE,
            scale = "width",
            width = 0.35,
            position = position_dodge(width = 0),
            color = NA
          )
        }
      } +
      # Boxplots inside violins (light gray for visibility)
      geom_boxplot(
        width = 0.15,
        alpha = 0.9,
        outlier.shape = NA,
        position = position_dodge(width = 0),
        fill = "grey90",
        color = "grey70",
        linewidth = 0.7,
        show.legend = FALSE
      ) +
      # Individual participant points (in columns, no jitter)
      geom_point(
        alpha = 0.5,
        size = 1.5,
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Connecting lines (between paired conditions)
      geom_line(
        aes(group = pid),
        alpha = 0.3,
        linewidth = 0.4,
        color = "grey60",
        position = position_dodge(width = 0),
        show.legend = FALSE
      ) +
      # Thick black line connecting mean values between conditions
      {
        mean_data <- df_ct_plot %>%
          group_by(modality, pressure, ui_mode) %>%
          summarise(mean_value = mean(submov_mean, na.rm = TRUE), .groups = "drop") %>%
          pivot_wider(names_from = ui_mode, values_from = mean_value, names_prefix = "mean_") %>%
          filter(!is.na(mean_static), !is.na(mean_adaptive))
        
        if (nrow(mean_data) > 0) {
          geom_segment(
            data = mean_data,
            aes(x = 1, xend = 2, y = mean_static, yend = mean_adaptive),
            inherit.aes = FALSE,
            color = "black",
            linewidth = 0.9,
            alpha = 0.9
          )
        } else {
          NULL
        }
      } +
      facet_grid(modality ~ pressure, 
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 ),
                 drop = TRUE) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Submovement Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 13) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey85", fill = NA, linewidth = 0.4)
      )
    
    print(p1)
  }
}
```

### Statistical Model: Submovement Count

```{r control-theory-models, eval=!is.null(submov_col) && exists("df_ct") && nrow(df_ct) > 0 && n_distinct(df_ct$pid) > 1}
# Statistical Models for Control Theory Metrics (Submovement Count)

if (!is.null(submov_col) && exists("df_ct") && nrow(df_ct) > 0) {
  df_ct_model <- df_ct %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure),
      pid = factor(pid),
      # Create a standard column name for the model
      submov_count = .data[[submov_col]],
      log_submov = log(.data[[submov_col]] + 1)
    )
  
  # Check if we have variation in submovements
  # If hand has all zeros, we may need to analyze gaze separately or use a different approach
  hand_all_zero <- all(df_ct_model$submov_count[df_ct_model$modality == "hand"] == 0, na.rm = TRUE)
  gaze_has_variation <- sum(df_ct_model$submov_count[df_ct_model$modality == "gaze"] > 0, na.rm = TRUE) > 0
  
  if (n_distinct(df_ct_model$pid) > 1) {
    cat("### Model: Submovement Count\n\n")
    
    if (hand_all_zero && gaze_has_variation) {
      cat("**Note:** Hand modality shows zero submovements (smooth, ballistic movements).\n")
      cat("Gaze modality shows ", round(mean(df_ct_model$submov_count[df_ct_model$modality == "gaze"], na.rm = TRUE), 1), 
          " submovements on average.\n")
      cat("Modeling gaze-only data to test UI mode and pressure effects.\n\n")
      
      # Model gaze-only data
      df_gaze_only <- df_ct_model %>%
        filter(modality == "gaze")
      
      if (nrow(df_gaze_only) > 0 && n_distinct(df_gaze_only$pid) > 1) {
        model_submov <- tryCatch({
          lmer(log_submov ~ ui_mode * pressure + (1 | pid),
               data = df_gaze_only, REML = FALSE,
               control = lmerControl(optimizer = "bobyqa"))
        }, error = function(e) {
          cat("⚠ **Model fitting failed:** ", e$message, "\n\n")
          NULL
        })
        
        model_type <- "gaze-only"
      } else {
        model_submov <- NULL
        model_type <- NULL
      }
    } else {
      # Model all data (if hand has some variation)
      model_submov <- tryCatch({
        lmer(log_submov ~ modality * ui_mode * pressure + (1 | pid),
             data = df_ct_model, REML = FALSE,
             control = lmerControl(optimizer = "bobyqa"))
      }, error = function(e) {
        cat("⚠ **Model fitting failed:** ", e$message, "\n\n")
        NULL
      })
      
      model_type <- "full"
    }
    
    if (!is.null(model_submov)) {
      if (model_type == "gaze-only") {
        cat("**Model:** log(submovement_count + 1) ~ ui_mode * pressure + (1 | pid) [Gaze modality only]\n\n")
        cat("**Data Summary:** ", n_distinct(df_gaze_only$pid), " participants, ", nrow(df_gaze_only), " trials (gaze only).\n\n")
        cat("**Rationale:** Hand modality shows zero submovements (smooth movements), so analysis focuses on gaze where submovements are present.\n\n")
      } else {
        cat("**Model:** log(submovement_count + 1) ~ modality * ui_mode * pressure + (1 | pid)\n\n")
        cat("**Data Summary:** ", n_distinct(df_ct_model$pid), " participants, ", nrow(df_ct_model), " trials.\n\n")
      }
      
      # ANOVA
      cat("#### ANOVA Table\n")
      anova_submov <- anova(model_submov, type = "III")
      print(anova_submov)
      
      # Calculate effect sizes
      anova_submov_df <- as.data.frame(anova_submov)
      anova_submov_df$partial_eta_sq <- mapply(calc_partial_eta_sq, 
                                                anova_submov_df$`F value`, 
                                                anova_submov_df$NumDF, 
                                                anova_submov_df$DenDF)
      
      # APA-style results
      cat("\n#### Written Results (APA Style)\n\n")
      
      if (model_type == "gaze-only") {
        # Gaze-only model: test ui_mode and pressure effects
        ui_mode_row <- anova_submov_df[grepl("^ui_mode$|^ui.mode$", rownames(anova_submov_df), ignore.case = TRUE), ]
        pressure_row <- anova_submov_df[grepl("^pressure$", rownames(anova_submov_df), ignore.case = TRUE), ]
        ui_press_int <- anova_submov_df[grepl("ui_mode.*pressure|pressure.*ui_mode", rownames(anova_submov_df), ignore.case = TRUE), ]
        
        # Modality comparison (descriptive only, since hand is all zeros)
        cat("**Modality Comparison (Descriptive):** Hand input produced zero submovements across all conditions, indicating smooth, ballistic movements. Gaze input produced ", 
            sprintf("%.1f", mean(df_ct_model$submov_count[df_ct_model$modality == "gaze"], na.rm = TRUE)),
            " submovements on average (SD = ", 
            sprintf("%.1f", sd(df_ct_model$submov_count[df_ct_model$modality == "gaze"], na.rm = TRUE)),
            "), consistent with intermittent control due to lag and saccadic blindness.\n\n")
        
        if (nrow(ui_mode_row) > 0 && !is.na(ui_mode_row$`F value`[1])) {
          F_ui <- ui_mode_row$`F value`[1]
          df1_ui <- ui_mode_row$NumDF[1]
          df2_ui <- ui_mode_row$DenDF[1]
          p_ui <- ui_mode_row$`Pr(>F)`[1]
          eta_ui <- ui_mode_row$partial_eta_sq[1]
          
          cat("**UI Mode Effect (Gaze):** A linear mixed-effects model on log-transformed submovement count for gaze modality revealed a ",
              ifelse(p_ui < .05, "significant", "non-significant"),
              " main effect of UI mode, ",
              format_F_apa(F_ui, df1_ui, df2_ui, p_ui),
              ", η²p = ", sprintf("%.3f", eta_ui),
              " (", interpret_eta_sq(eta_ui), " effect). ", sep = "")
          
          # Descriptive interpretation
          emm_ui <- emmeans(model_submov, ~ ui_mode, type = "response")
          emm_ui_df <- as.data.frame(emm_ui)
          if (nrow(emm_ui_df) == 2) {
            static_mean <- exp(emm_ui_df$emmean[emm_ui_df$ui_mode == "static"]) - 1
            adaptive_mean <- exp(emm_ui_df$emmean[emm_ui_df$ui_mode == "adaptive"]) - 1
            cat("Adaptive UI ", ifelse(adaptive_mean < static_mean, "reduced", "did not reduce"),
                " submovements (M = ", sprintf("%.2f", adaptive_mean), 
                ") compared to Static UI (M = ", sprintf("%.2f", static_mean), ") in gaze modality.", sep = "")
          }
          cat("\n\n")
        }
        
        if (nrow(pressure_row) > 0 && !is.na(pressure_row$`F value`[1])) {
          F_press <- pressure_row$`F value`[1]
          df1_press <- pressure_row$NumDF[1]
          df2_press <- pressure_row$DenDF[1]
          p_press <- pressure_row$`Pr(>F)`[1]
          eta_press <- pressure_row$partial_eta_sq[1]
          
          cat("**Pressure Effect (Gaze):** The main effect of pressure on submovement count was ",
              ifelse(p_press < .05, "significant", "non-significant"),
              ", ", format_F_apa(F_press, df1_press, df2_press, p_press),
              ", η²p = ", sprintf("%.3f", eta_press),
              " (", interpret_eta_sq(eta_press), " effect).\n\n", sep = "")
        }
        
        if (nrow(ui_press_int) > 0 && !is.na(ui_press_int$`F value`[1])) {
          F_int <- ui_press_int$`F value`[1]
          df1_int <- ui_press_int$NumDF[1]
          df2_int <- ui_press_int$DenDF[1]
          p_int <- ui_press_int$`Pr(>F)`[1]
          eta_int <- ui_press_int$partial_eta_sq[1]
          
          cat("**UI Mode × Pressure Interaction:** The interaction was ",
              ifelse(p_int < .05, "significant", "non-significant"),
              ", ", format_F_apa(F_int, df1_int, df2_int, p_int),
              ", η²p = ", sprintf("%.3f", eta_int),
              " (", interpret_eta_sq(eta_int), " effect).\n\n", sep = "")
        }
      } else {
        # Full model: test all effects including modality
        modality_row <- anova_submov_df[grepl("^modality$", rownames(anova_submov_df), ignore.case = TRUE), ]
        ui_mode_row <- anova_submov_df[grepl("^ui_mode$|^ui.mode$", rownames(anova_submov_df), ignore.case = TRUE), ]
        mod_ui_int <- anova_submov_df[grepl("modality.*ui_mode|ui_mode.*modality", rownames(anova_submov_df), ignore.case = TRUE) & 
                                      !grepl("pressure", rownames(anova_submov_df), ignore.case = TRUE), ]
        
        if (nrow(modality_row) > 0 && !is.na(modality_row$`F value`[1])) {
          F_mod <- modality_row$`F value`[1]
          df1_mod <- modality_row$NumDF[1]
          df2_mod <- modality_row$DenDF[1]
          p_mod <- modality_row$`Pr(>F)`[1]
          eta_mod <- modality_row$partial_eta_sq[1]
          
          cat("**Modality Effect:** A linear mixed-effects model on log-transformed submovement count revealed a ", 
              ifelse(p_mod < .05, "significant", "non-significant"),
              " main effect of input modality, ",
              format_F_apa(F_mod, df1_mod, df2_mod, p_mod),
              ", η²p = ", sprintf("%.3f", eta_mod), 
              " (", interpret_eta_sq(eta_mod), " effect). ", sep = "")
          
          # Descriptive interpretation
          emm_mod <- emmeans(model_submov, ~ modality, type = "response")
          emm_mod_df <- as.data.frame(emm_mod)
          if (nrow(emm_mod_df) == 2) {
            hand_mean <- exp(emm_mod_df$emmean[emm_mod_df$modality == "hand"]) - 1
            gaze_mean <- exp(emm_mod_df$emmean[emm_mod_df$modality == "gaze"]) - 1
            cat("Gaze input produced ", ifelse(gaze_mean > hand_mean, "more", "fewer"),
                " submovements (M = ", sprintf("%.2f", gaze_mean), 
                ") than hand input (M = ", sprintf("%.2f", hand_mean), ").", sep = "")
          }
          cat("\n\n")
        }
        
        if (nrow(ui_mode_row) > 0 && !is.na(ui_mode_row$`F value`[1])) {
          F_ui <- ui_mode_row$`F value`[1]
          df1_ui <- ui_mode_row$NumDF[1]
          df2_ui <- ui_mode_row$DenDF[1]
          p_ui <- ui_mode_row$`Pr(>F)`[1]
          eta_ui <- ui_mode_row$partial_eta_sq[1]
          
          cat("**UI Mode Effect:** The main effect of UI mode on submovement count was ",
              ifelse(p_ui < .05, "significant", "non-significant"),
              ", ", format_F_apa(F_ui, df1_ui, df2_ui, p_ui),
              ", η²p = ", sprintf("%.3f", eta_ui),
              " (", interpret_eta_sq(eta_ui), " effect). ", sep = "")
          
          # Descriptive interpretation
          emm_ui <- emmeans(model_submov, ~ ui_mode, type = "response")
          emm_ui_df <- as.data.frame(emm_ui)
          if (nrow(emm_ui_df) == 2) {
            static_mean <- exp(emm_ui_df$emmean[emm_ui_df$ui_mode == "static"]) - 1
            adaptive_mean <- exp(emm_ui_df$emmean[emm_ui_df$ui_mode == "adaptive"]) - 1
            cat("Adaptive UI ", ifelse(adaptive_mean < static_mean, "reduced", "did not reduce"),
                " submovements (M = ", sprintf("%.2f", adaptive_mean), 
                ") compared to Static UI (M = ", sprintf("%.2f", static_mean), ").", sep = "")
          }
          cat("\n\n")
        }
        
        if (nrow(mod_ui_int) > 0 && !is.na(mod_ui_int$`F value`[1])) {
          F_int <- mod_ui_int$`F value`[1]
          df1_int <- mod_ui_int$NumDF[1]
          df2_int <- mod_ui_int$DenDF[1]
          p_int <- mod_ui_int$`Pr(>F)`[1]
          eta_int <- mod_ui_int$partial_eta_sq[1]
          
          cat("**Modality × UI Mode Interaction:** The interaction was ",
              ifelse(p_int < .05, "significant", "non-significant"),
              ", ", format_F_apa(F_int, df1_int, df2_int, p_int),
              ", η²p = ", sprintf("%.3f", eta_int),
              " (", interpret_eta_sq(eta_int), " effect).", sep = "")
          
          if (p_int >= .05) {
            cat(" The effect of UI mode on submovement count did not differ significantly between modalities.")
          } else {
            cat(" Follow-up simple effects analyses are recommended.")
          }
          cat("\n\n")
        }
      }
    } else {
      cat("⚠ **Model could not be fitted.**\n")
      if (exists("hand_all_zero") && hand_all_zero) {
        cat("**Note:** Hand modality shows zero submovements. Consider analyzing gaze-only data or using a different model specification.\n")
      }
    }
  }
}
```

**Implementation Notes:**
- Basic submovement analysis is already in Section 10 (Movement Quality Metrics)
- **Trajectory data is now available** in the `trajectory` column (JSON string, logged at ~60fps)
- Current `submovement_count` is pre-calculated in `FittsTask.tsx` using velocity peaks
- **Power:** N=48 sufficient for main effects (dz≈0.41, power≈0.80); interactions underpowered (treat as exploratory)
- **Key considerations:**
  - Use duration-normalized smoothness metrics (jerk is duration-sensitive)
  - Control for multiple comparisons (FDR) if testing many kinematic features
  - Pre-specify a small set of theoretically motivated outcomes
  - 60fps improves measurement precision but doesn't increase effective N
- **See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed power analysis and recommendations**

**Potential Issues to Check:**
- Verify that `submovement_count` calculation in `FittsTask.tsx` matches the Optimized Submovement Model definition
- Check if velocity profile data is needed or if pre-calculated counts are sufficient
- Ensure submovement detection algorithm handles both hand and gaze modalities correctly

-----

# 19. Summary & Conclusions

## Key Findings Summary

```{r summary-table}
# Create a comprehensive summary table
summary_table <- bind_rows(
  # Throughput
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Throughput (bits/s)",
      Mean = round(mean(TP, na.rm = TRUE), 2),
      SD = round(sd(TP, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Movement Time
  df %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Movement Time (s)",
      Mean = round(mean(rt_s, na.rm = TRUE), 3),
      SD = round(sd(rt_s, na.rm = TRUE), 3),
      .groups = "drop"
    ),
  # Error Rate
  df_errors %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Error Rate (%)",
      Mean = round(100 * mean(error, na.rm = TRUE), 2),
      SD = round(100 * sd(error, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Effective Width
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Effective Width (px)",
      Mean = round(mean(We, na.rm = TRUE), 2),
      SD = round(sd(We, na.rm = TRUE), 2),
      .groups = "drop"
    )
) %>%
  arrange(Metric, modality, ui_mode)

summary_table %>%
  kable(caption = paste0("Summary of Key Metrics by Condition (N=", n_distinct(df$pid), ")")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

## Data Quality Notes

- **Participants:** `r n_distinct(df$pid)`
- **Valid Trials:** `r nrow(df)` (out of `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))` total experimental trials)
- **Exclusion Rate:** `r percent(round(1 - nrow(df) / nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice))), 3))` (due to errors, timeouts, or invalid RTs)
- **Trials per Participant:** Mean = `r round(mean(table(df$pid)), 1)`, Range = `r paste(round(min(table(df$pid)), 0), "-", round(max(table(df$pid)), 0))`

**Target Sample:** N=64 participants for enhanced power in advanced analyses (LBA, control-theory kinematics).

For detailed exclusion criteria, see `EXCLUSION_CRITERIA.md`. For technical audit details, see `AUDIT_REPORT.md`.

*Report generated on `r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`*