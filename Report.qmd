
---
title: "XR Adaptive Modality: Experiment Report"
author: "Mohammad Dastgheib"
date: last-modified
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    code-fold: true
    self-contained: true
    fig-width: 10
    fig-height: 6
    html-math-method: mathjax
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(htmltools)
library(scales)
library(ggsci)  # For pal_npg() function
library(lme4)
library(lmerTest)
library(emmeans)

# --- COLOR PALETTE ---
# Use Nature Publishing Group (NPG) palette from scales package
npg_pal <- pal_npg("nrc")(10)  # Get 10 colors from the palette

# For 2-level factors (e.g., static/adaptive), use first 2 colors
custom_palette_2 <- npg_pal[1:2]

# For multi-level factors (e.g., TLX scales with 6 levels), use first 6 colors
custom_palette_multi <- npg_pal[1:6]

# --- DATA LOADING ---
# Load the latest clean data
# Try multiple possible paths (relative to report location or working directory)
data_paths <- c(
  "data/clean/trial_data.csv",           # If running from project root
  "../data/clean/trial_data.csv"         # If running from subdirectory
)

df_raw <- NULL
for (path in data_paths) {
  if (file.exists(path)) {
    tryCatch({
      df_raw <- read_csv(path, show_col_types = FALSE)
      cat("Loaded data from:", path, "\n")
      break
    }, error = function(e) {
      # Continue to next path
    })
  }
}

if (is.null(df_raw)) {
  stop("Could not find 'trial_data.csv'. Tried paths:\n",
       paste("  -", data_paths, collapse = "\n"),
       "\nCurrent working directory:", getwd(),
       "\nPlease ensure the data pipeline has run and the file exists.")
}

# Normalize column names
if ("participant_id" %in% names(df_raw) && !"pid" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(pid = participant_id)
}
if ("movement_time_ms" %in% names(df_raw) && !"rt_ms" %in% names(df_raw)) {
  df_raw <- df_raw %>% rename(rt_ms = movement_time_ms)
}

# --- PREPROCESSING ---
# Create dataframe with ALL trials (correct + incorrect) for error rate calculations
# This includes trials with valid RTs (even if incorrect) and excludes only practice trials
df_all_trials <- df_raw %>%
  filter(
    practice == "false" | practice == FALSE | is.na(practice)
  ) %>%
  mutate(
    rt_s = rt_ms / 1000,
    log_rt = log(rt_ms),
    # Create factor labels for better plots
    Condition = paste(modality, ui_mode, sep = " - "),
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    ModalityLabel = str_to_title(modality),
    UILabel = str_to_title(ui_mode),
    # Ensure factors
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid),
    # Mark correct/incorrect for error calculations
    # Note: In the data, correct = TRUE for correct trials, and correct = NA for errors
    is_correct = !is.na(correct) & (correct == "true" | correct == TRUE | correct == 1)
  )

# Filter valid experimental trials (non-practice, correct, valid RTs) for performance metrics
df <- df_all_trials %>%
  filter(
    is_correct == TRUE,
    rt_ms >= 150,  # Physiological minimum
    rt_ms <= 6000  # Time-out threshold
  )

# --- CALCULATE ISO METRICS (Throughput) ---
# ISO 9241-9: Calculate We (Effective Width) per condition per participant
df_iso <- df %>%
  group_by(pid, modality, ui_mode, pressure, A, W) %>%
  summarise(
    # We = 4.133 * SD of Projected Error
    sd_x = sd(projected_error_px, na.rm = TRUE),
    We = 4.133 * sd_x,
    
    # Effective ID
    IDe = log2((mean(A) / We) + 1),
    
    # Mean Movement Time for this condition
    MT_avg = mean(rt_s, na.rm = TRUE),
    
    # Throughput (Bits/s)
    TP = IDe / MT_avg,
    
    # Gaze Specifics
    reentries = mean(target_reentry_count, na.rm = TRUE),
    verification = mean(verification_time_ms, na.rm = TRUE),
    
    .groups = "drop"
  ) %>%
  filter(!is.na(TP), TP > 0, TP < 20) %>%  # Reasonable TP range
  mutate(
    # Recreate labels that were lost in summarise
    PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF"),
    Condition = paste(modality, ui_mode, sep = " - ")
  )

# --- STATISTICAL MODELS ---
# Helper function for diagnostics
diagnose_model_data <- function(data, model_name) {
  diag <- list()
  
  if (nrow(data) == 0) {
    diag$n_participants <- 0
    diag$n_trials <- 0
    diag$n_conditions <- 0
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$single_level_factors <- character(0)
    return(diag)
  }
  
  diag$n_participants <- n_distinct(data$pid)
  diag$n_trials <- nrow(data)
  
  # Check if required columns exist
  has_modality <- "modality" %in% names(data)
  has_ui_mode <- "ui_mode" %in% names(data)
  has_pressure <- "pressure" %in% names(data)
  
  # Check for single-level factors (causes "contrasts" error)
  single_level_factors <- character(0)
  if (has_modality && n_distinct(data$modality, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "modality")
  }
  if (has_ui_mode && n_distinct(data$ui_mode, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "ui_mode")
  }
  if (has_pressure && n_distinct(data$pressure, na.rm = TRUE) < 2) {
    single_level_factors <- c(single_level_factors, "pressure")
  }
  diag$single_level_factors <- single_level_factors
  
  if (has_modality && has_ui_mode && has_pressure) {
    diag$n_conditions <- length(unique(interaction(data$modality, data$ui_mode, data$pressure, drop = TRUE)))
    
    # Check trials per condition
    condition_counts <- data %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(n = n(), .groups = "drop")
    diag$condition_counts <- condition_counts
    diag$min_trials_per_condition <- if(nrow(condition_counts) > 0) min(condition_counts$n, na.rm = TRUE) else 0
    diag$empty_conditions <- sum(condition_counts$n == 0, na.rm = TRUE)
  } else {
    diag$n_conditions <- 0
    diag$condition_counts <- data.frame()
    diag$min_trials_per_condition <- 0
    diag$empty_conditions <- 0
  }
  
  # Check for missing values in key variables
  diag$missing_tp <- if("TP" %in% names(data)) sum(is.na(data$TP)) else 0
  diag$missing_modality <- if(has_modality) sum(is.na(data$modality)) else 0
  diag$missing_ui_mode <- if(has_ui_mode) sum(is.na(data$ui_mode)) else 0
  diag$missing_pressure <- if(has_pressure) sum(is.na(data$pressure)) else 0
  
  return(diag)
}

# Model 1: Throughput
model_tp <- NULL
emm_tp <- NULL
pairs_tp <- NULL
diag_tp <- NULL
model_tp_error <- NULL

if (nrow(df_iso) > 0) {
  diag_tp <- diagnose_model_data(df_iso, "Throughput")
  
  if (diag_tp$n_participants <= 1) {
    model_tp_error <- paste0("Insufficient participants: N = ", diag_tp$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_tp$n_trials == 0) {
    model_tp_error <- "No valid trials in dataset."
  } else if (length(diag_tp$single_level_factors) > 0) {
    model_tp_error <- paste0("Single-level factor(s) detected: ", paste(diag_tp$single_level_factors, collapse = ", "), 
                             ". All factors (modality, ui_mode, pressure) must have at least 2 levels for the model to fit. ",
                             "This typically happens when data collection is incomplete (e.g., only pressure=1 data collected so far).")
  } else if (diag_tp$min_trials_per_condition < 3) {
    model_tp_error <- paste0("Insufficient data per condition: minimum ", diag_tp$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_tp$empty_conditions > 0) {
    model_tp_error <- paste0("Empty conditions detected: ", diag_tp$empty_conditions, " condition(s) have no data.")
  } else {
  model_tp <- tryCatch({
    lmer(TP ~ modality * ui_mode * pressure + (1 | pid), 
         data = df_iso, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_tp_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_tp_error)) {
        model_tp_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_tp)) {
      # Check for convergence warnings
      conv_warnings <- warnings()
      if (length(conv_warnings) > 0) {
        model_tp_error <- paste0("Convergence warnings detected. Model may be unreliable.")
      }
      
    tryCatch({
      emm_tp <- emmeans(model_tp, ~ modality * ui_mode * pressure)
      pairs_tp <- pairs(emm_tp, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_tp_error)) {
          model_tp_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_tp <- list(n_participants = 0, n_trials = 0)
  model_tp_error <- "No data available for throughput analysis."
}

# Model 2: Movement Time
model_rt <- NULL
emm_rt <- NULL
pairs_rt <- NULL
diag_rt <- NULL
model_rt_error <- NULL

if (nrow(df) > 0) {
  diag_rt <- diagnose_model_data(df, "Movement Time")
  
  if (diag_rt$n_participants <= 1) {
    model_rt_error <- paste0("Insufficient participants: N = ", diag_rt$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_rt$n_trials == 0) {
    model_rt_error <- "No valid trials in dataset."
  } else if (length(diag_rt$single_level_factors) > 0) {
    model_rt_error <- paste0("Single-level factor(s) detected: ", paste(diag_rt$single_level_factors, collapse = ", "), 
                             ". All factors (modality, ui_mode, pressure) must have at least 2 levels for the model to fit. ",
                             "This typically happens when data collection is incomplete (e.g., only pressure=1 data collected so far).")
  } else if (diag_rt$min_trials_per_condition < 3) {
    model_rt_error <- paste0("Insufficient data per condition: minimum ", diag_rt$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_rt$empty_conditions > 0) {
    model_rt_error <- paste0("Empty conditions detected: ", diag_rt$empty_conditions, " condition(s) have no data.")
  } else {
  model_rt <- tryCatch({
    lmer(log_rt ~ modality * ui_mode * pressure + (1 | pid), 
         data = df, REML = FALSE,
         control = lmerControl(optimizer = "bobyqa"))
  }, error = function(e) {
      model_rt_error <<- paste0("Model fitting failed: ", e$message)
      NULL
    }, warning = function(w) {
      if (is.null(model_rt_error)) {
        model_rt_error <<- paste0("Model fitting warning: ", w$message)
      }
    NULL
  })
  
  if (!is.null(model_rt)) {
      # Check for convergence warnings
      conv_warnings <- warnings()
      if (length(conv_warnings) > 0) {
        model_rt_error <- paste0("Convergence warnings detected. Model may be unreliable.")
      }
      
    tryCatch({
      emm_rt <- emmeans(model_rt, ~ modality * ui_mode * pressure, type = "response")
      pairs_rt <- pairs(emm_rt, adjust = "holm")
    }, error = function(e) {
        if (is.null(model_rt_error)) {
          model_rt_error <<- paste0("Could not compute estimated marginal means: ", e$message)
        }
    })
  }
  }
} else {
  diag_rt <- list(n_participants = 0, n_trials = 0)
  model_rt_error <- "No data available for movement time analysis."
}

# Model 3: Error Rate
# Use df_all_trials which already has all trials (correct + incorrect)
df_errors <- df_all_trials %>%
  mutate(
    error = ifelse(is_correct, 0, 1),
    modality = factor(modality, levels = c("hand", "gaze")),
    ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
    pressure = factor(pressure),
    pid = factor(pid)
  )

model_err <- NULL
emm_err <- NULL
pairs_err <- NULL
diag_err <- NULL
model_err_error <- NULL

if (nrow(df_errors) > 0) {
  diag_err <- diagnose_model_data(df_errors, "Error Rate")
  
  if (diag_err$n_participants <= 1) {
    model_err_error <- paste0("Insufficient participants: N = ", diag_err$n_participants, ". Need at least 2 participants for mixed-effects models.")
  } else if (diag_err$n_trials == 0) {
    model_err_error <- "No valid trials in dataset."
  } else if (length(diag_err$single_level_factors) > 0) {
    model_err_error <- paste0("Single-level factor(s) detected: ", paste(diag_err$single_level_factors, collapse = ", "), 
                              ". All factors (modality, ui_mode, pressure) must have at least 2 levels for the model to fit. ",
                              "This typically happens when data collection is incomplete (e.g., only pressure=1 data collected so far).")
  } else if (diag_err$min_trials_per_condition < 3) {
    model_err_error <- paste0("Insufficient data per condition: minimum ", diag_err$min_trials_per_condition, " trials per condition. Some conditions have very few observations.")
  } else if (diag_err$empty_conditions > 0) {
    model_err_error <- paste0("Empty conditions detected: ", diag_err$empty_conditions, " condition(s) have no data.")
  } else {
    # Check for sufficient error variance (GLMM needs some errors)
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    if (error_rate < 0.01 || error_rate > 0.99) {
      model_err_error <- paste0("Insufficient error variance: error rate = ", round(error_rate * 100, 1), "%. GLMM requires some variation in outcomes.")
    } else {
  model_err <- tryCatch({
    glmer(error ~ modality * ui_mode * pressure + (1 | pid),
          data = df_errors, family = binomial(link = "logit"),
          control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
  }, error = function(e) {
        model_err_error <<- paste0("Model fitting failed: ", e$message)
        NULL
      }, warning = function(w) {
        if (is.null(model_err_error)) {
          model_err_error <<- paste0("Model fitting warning: ", w$message)
        }
    NULL
  })
  
  if (!is.null(model_err)) {
        # Check for convergence warnings
        conv_warnings <- warnings()
        if (length(conv_warnings) > 0) {
          model_err_error <- paste0("Convergence warnings detected. Model may be unreliable.")
        }
        
    tryCatch({
      emm_err <- emmeans(model_err, ~ modality * ui_mode * pressure, type = "response")
      pairs_err <- pairs(emm_err, adjust = "holm")
    }, error = function(e) {
          if (is.null(model_err_error)) {
            model_err_error <<- paste0("Could not compute estimated marginal means: ", e$message)
          }
    })
  }
    }
  }
} else {
  diag_err <- list(n_participants = 0, n_trials = 0)
  model_err_error <- "No data available for error rate analysis."
}
```

# 1. Executive Summary

This report analyzes **`r n_distinct(df$pid)`** participants performing Fitts' law pointing tasks across two input modalities (Hand, Gaze) and two UI modes (Static, Adaptive).

**Note on Participant Exclusions:** Seven participants (P002, P003, P007, P008, P015, P039, P040) were excluded from the main 2×2×2 factorial analysis due to a data logging error that incorrectly recorded pressure conditions. The bug was fixed on December 8, 2025 (commit `04758db`), and seven replacement participants (P049-P055) were added. The final analysis sample consists of N=48 participants with complete data across all experimental conditions. See the Data Quality Notes section and `EXCLUSION_CRITERIA.md` for details.

## Key Findings

  * **Total Trials Analyzed:** `r nrow(df)` valid trials (correct responses, RT 150-6000ms)
  * **Total Trials Collected:** `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))`
  * **Overall Error Rate:** `r percent(round(1 - (sum(df$correct == TRUE | df$correct == "true" | df$correct == 1)/nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))), 3))`
  * **Mean Throughput:** `r round(mean(df_iso$TP, na.rm = TRUE), 2)` bits/s (SD = `r round(sd(df_iso$TP, na.rm = TRUE), 2)`)
  * **Mean Movement Time:** `r round(mean(df$rt_s, na.rm = TRUE), 3)`s (SD = `r round(sd(df$rt_s, na.rm = TRUE), 3)`s)

-----

# 2. Demographics

```{r demographics}
# Ensure pid column exists
demog_raw <- df_raw
if ("participant_id" %in% names(demog_raw) && !"pid" %in% names(demog_raw)) {
  demog_raw <- demog_raw %>% rename(pid = participant_id)
}

demog_summary <- demog_raw %>%
  distinct(pid, .keep_all = TRUE) %>%
  select(pid, age, gender, gaming_hours_per_week, input_device) %>%
  filter(!is.na(pid))

# Overall summary
overall_stats <- demog_summary %>%
  summarise(
    `N` = n(),
    `Mean Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Age Range` = paste(round(min(age, na.rm=TRUE), 0), "-", round(max(age, na.rm=TRUE), 0)),
    `Mean Gaming (Hrs/Week)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    `SD Gaming` = round(sd(gaming_hours_per_week, na.rm=TRUE), 1)
  )

# By gender
gender_stats <- demog_summary %>%
  filter(!is.na(gender)) %>%
  group_by(gender) %>%
  summarise(
    Count = n(),
    `Avg Age` = round(mean(age, na.rm=TRUE), 1),
    `SD Age` = round(sd(age, na.rm=TRUE), 1),
    `Avg Gaming (Hrs)` = round(mean(gaming_hours_per_week, na.rm=TRUE), 1),
    .groups = "drop"
  )

# Input device distribution
device_stats <- demog_summary %>%
  filter(!is.na(input_device)) %>%
  count(input_device, name = "Count") %>%
  mutate(Percentage = round(100 * Count / sum(Count), 1))


```

## Overall Demographics

```{r}
overall_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## By Gender

```{r}
gender_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


## Input Device Distribution

```{r}
device_stats %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


-----

# 3. Primary Analysis: Throughput

**Research Question:** Does the Adaptive UI improve performance (Throughput) compared to Static, especially for Gaze?

## Summary Statistics

```{r tp-summary}
tp_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N = n(),
    Mean = round(mean(TP, na.rm = TRUE), 2),
    SD = round(sd(TP, na.rm = TRUE), 2),
    Median = round(median(TP, na.rm = TRUE), 2),
    Q25 = round(quantile(TP, 0.25, na.rm = TRUE), 2),
    Q75 = round(quantile(TP, 0.75, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

tp_summary %>%
  kable(caption = "Throughput (bits/s) by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-tp}
#| fig-cap: "Throughput by Modality and UI Mode. Higher values indicate better performance. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles, and individual points may be visible as outliers."
# Main plot with all conditions - improved faceting and aesthetics
p1 <- ggplot(df_iso, aes(x = ui_mode, y = TP, fill = ui_mode)) +
  geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
              show.legend = FALSE) +
  geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
               outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
               position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
  facet_grid(modality ~ pressure, 
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2,
                     labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Throughput (bits/s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
  )

print(p1)
```

```{r plot-tp-emm}
#| fig-cap: "Estimated Marginal Means for Throughput. Error bars represent 95% confidence intervals from the linear mixed-effects model. Points are connected by lines to show the interaction pattern between modality and UI mode, faceted by pressure condition."
# Interaction plot
if (exists("emm_tp") && !is.null(emm_tp)) {
  emm_tp_df <- as.data.frame(emm_tp) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  p2 <- ggplot(emm_tp_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.2, position = position_dodge(0.2)) +
    geom_point(size = 3, position = position_dodge(0.2)) +
    geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), 
                  width = 0.1, position = position_dodge(0.2)) +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Throughput (bits/s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top")
  
  print(p2)
}
```

## Statistical Model Results

```{r tp-model}
if (exists("model_tp") && !is.null(model_tp)) {
  cat("### Model: TP ~ Modality × UI Mode × Pressure + (1 | Participant)\n\n")
  
  # Show diagnostics
  if (!is.null(diag_tp)) {
    cat("**Data Summary:** ", diag_tp$n_participants, " participants, ", diag_tp$n_trials, " trials, ", 
        diag_tp$n_conditions, " conditions, minimum ", diag_tp$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_tp <- anova(model_tp, type = "III")
  print(anova_tp)
  
  # Model summary
  cat("\n#### Model Summary\n")
  print(summary(model_tp))
  
  # Pairwise comparisons
  if (exists("pairs_tp") && !is.null(pairs_tp)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_tp_df <- as.data.frame(pairs_tp)
    print(pairs_tp_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Throughput.**\n\n")
  
  if (!is.null(model_tp_error)) {
    cat("**Reason:** ", model_tp_error, "\n\n")
  }
  
  if (!is.null(diag_tp)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_tp$n_participants, "\n")
    cat("- Total trials: ", diag_tp$n_trials, "\n")
    cat("- Conditions: ", diag_tp$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_tp$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_tp$empty_conditions, "\n")
    
    if (length(diag_tp$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_tp$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_tp$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_tp$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 4. Movement Time Analysis

**Research Question:** How does movement time vary across conditions?

## Summary Statistics

```{r rt-summary}
rt_summary <- df %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    N = n(),
    Mean = round(mean(rt_s, na.rm = TRUE), 3),
    SD = round(sd(rt_s, na.rm = TRUE), 3),
    Median = round(median(rt_s, na.rm = TRUE), 3),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

rt_summary %>%
  kable(caption = "Movement Time (s) by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

## Visualizations

```{r plot-rt}
#| fig-cap: "Movement Time by Modality and UI Mode. Lower values indicate faster performance. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles, and individual points may be visible as outliers."
# Movement time distribution - improved faceting and aesthetics
p1 <- ggplot(df, aes(x = ui_mode, y = rt_s, fill = ui_mode)) +
  geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
              show.legend = FALSE) +
  geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
               outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
               position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
  facet_grid(modality ~ pressure,
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2,
                     labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Movement Time (s)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
  )

print(p1)
```

```{r plot-rt-emm}
#| fig-cap: "Estimated Marginal Means for Movement Time. Error bars represent 95% confidence intervals from the linear mixed-effects model. Points are connected by lines to show the interaction pattern between modality and UI mode, faceted by pressure condition."
# Estimated marginal means
if (exists("emm_rt") && !is.null(emm_rt)) {
  emm_rt_df <- as.data.frame(emm_rt) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  p2 <- ggplot(emm_rt_df, aes(x = modality, y = emmean, color = ui_mode, group = ui_mode)) +
    geom_line(size = 1.2, position = position_dodge(0.2)) +
    geom_point(size = 3, position = position_dodge(0.2)) +
    geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), 
                  width = 0.1, position = position_dodge(0.2)) +
    facet_wrap(~pressure, labeller = labeller(pressure = function(x) paste("Pressure:", x))) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    labs(
      x = "Input Modality",
      y = "Movement Time (s)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top")
  
  print(p2)
}
```

## Statistical Model Results

```{r rt-model}
if (exists("model_rt") && !is.null(model_rt)) {
  cat("### Model: log(Movement Time) ~ Modality × UI Mode × Pressure + (1 | Participant)\n\n")
  
  # Show diagnostics
  if (!is.null(diag_rt)) {
    cat("**Data Summary:** ", diag_rt$n_participants, " participants, ", diag_rt$n_trials, " trials, ", 
        diag_rt$n_conditions, " conditions, minimum ", diag_rt$min_trials_per_condition, " trials per condition.\n\n")
  }
  
  # ANOVA table
  cat("#### ANOVA Table\n")
  anova_rt <- anova(model_rt, type = "III")
  print(anova_rt)
  
  # Pairwise comparisons
  if (exists("pairs_rt") && !is.null(pairs_rt)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_rt_df <- as.data.frame(pairs_rt)
    print(pairs_rt_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Movement Time.**\n\n")
  
  if (!is.null(model_rt_error)) {
    cat("**Reason:** ", model_rt_error, "\n\n")
  }
  
  if (!is.null(diag_rt)) {
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_rt$n_participants, "\n")
    cat("- Total trials: ", diag_rt$n_trials, "\n")
    cat("- Conditions: ", diag_rt$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_rt$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_rt$empty_conditions, "\n")
    
    if (length(diag_rt$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_rt$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_rt$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_rt$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 5. Fitts' Law Modelling

**Research Question:** How well does the data fit Fitts' Law? (Linearity check).
*Flatter slopes indicate less sensitivity to difficulty (ballistic movement).*

```{r plot-fitts}
#| fig-cap: "Fitts' Law Regression (Movement Time vs Effective Index of Difficulty). The effective index of difficulty (IDe) is calculated using the effective target width (We) derived from the spatial distribution of selection endpoints. Shaded regions around regression lines represent 95% confidence intervals. Linear regression fits are shown separately for each modality and UI mode combination."
# Aggregate for regression plot
fitts_model <- df_iso %>%
  group_by(modality, ui_mode, IDe) %>%
  summarise(
    MT = mean(MT_avg, na.rm = TRUE),
    MT_se = sd(MT_avg, na.rm = TRUE) / sqrt(n()),
    N = n(),
    .groups = "drop"
  ) %>%
  filter(!is.na(IDe), !is.na(MT))

# Fit linear models for each condition
fitts_fits <- fitts_model %>%
  group_by(modality, ui_mode) %>%
  do(model = tryCatch(lm(MT ~ IDe, data = .), error = function(e) NULL)) %>%
  filter(!is.null(model)) %>%
  mutate(
    r_squared = round(summary(model)$r.squared, 3),
    slope = round(coef(model)[2], 3),
    intercept = round(coef(model)[1], 3)
  )

ggplot(fitts_model, aes(x = IDe, y = MT, color = ui_mode)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  facet_grid(. ~ modality) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
  labs(
    x = "Index of Difficulty (bits)",
    y = "Movement Time (s)",
    color = "UI Mode"
  ) +
  theme_light(base_size = 14) +
  theme(legend.position = "top")
```

```{r}
# Display R² values
if (nrow(fitts_fits) > 0) {
  cat("\n### Model Fit Statistics\n")
  fitts_fits %>%
    select(modality, ui_mode, r_squared, slope, intercept) %>%
    kable(caption = "Linear Regression: MT ~ IDe") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```

-----

# 6. Error Rate Analysis

**Research Question:** How do error rates differ across conditions?

```{r error-analysis}
#| fig-cap: "Error Rate by Modality and UI Mode. Lower values indicate fewer errors. Error rate is calculated as the percentage of trials with incorrect selections (misses, timeouts, or false activations). White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."
# Calculate error rates
error_summary <- df_errors %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Total = n(),
    Errors = sum(error, na.rm = TRUE),
    Error_Rate = round(100 * mean(error, na.rm = TRUE), 2),
    .groups = "drop"
  ) %>%
  arrange(modality, ui_mode, pressure)

error_summary %>%
  kable(caption = "Error Rates by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# Visualization - improved faceting and aesthetics
p_err <- df_errors %>%
  group_by(modality, ui_mode, pressure, pid) %>%
  summarise(Error_Rate = 100 * mean(error, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = ui_mode, y = Error_Rate, fill = ui_mode)) +
  geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
              show.legend = FALSE) +
  geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
               outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
               position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
  facet_grid(modality ~ pressure,
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2,
                     labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    x = "UI Mode",
    y = "Error Rate (%)",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
  )

print(p_err)
```

## Statistical Model Results

```{r error-model}
if (exists("model_err") && !is.null(model_err)) {
  cat("### Model: Error ~ Modality × UI Mode × Pressure + (1 | Participant)\n\n")
  
  # Show diagnostics
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Data Summary:** ", diag_err$n_participants, " participants, ", diag_err$n_trials, " trials, ", 
        diag_err$n_conditions, " conditions, minimum ", diag_err$min_trials_per_condition, " trials per condition.\n")
    cat("**Overall Error Rate:** ", round(error_rate * 100, 1), "%\n\n")
  }
  
  # ANOVA table
  if (requireNamespace("car", quietly = TRUE)) {
    library(car)
    cat("#### ANOVA Table\n")
    print(Anova(model_err, type = "III"))
  }
  
  # Pairwise comparisons
  if (exists("pairs_err") && !is.null(pairs_err)) {
    cat("\n#### Pairwise Comparisons (Holm-adjusted)\n")
    pairs_err_df <- as.data.frame(pairs_err)
    print(pairs_err_df %>% head(20))
  }
} else {
  cat("⚠ **Statistical model could not be fitted for Error Rate.**\n\n")
  
  if (!is.null(model_err_error)) {
    cat("**Reason:** ", model_err_error, "\n\n")
  }
  
  if (!is.null(diag_err)) {
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("**Diagnostics:**\n")
    cat("- Participants: ", diag_err$n_participants, "\n")
    cat("- Total trials: ", diag_err$n_trials, "\n")
    cat("- Conditions: ", diag_err$n_conditions, "\n")
    cat("- Minimum trials per condition: ", diag_err$min_trials_per_condition, "\n")
    cat("- Empty conditions: ", diag_err$empty_conditions, "\n")
    cat("- Overall error rate: ", round(error_rate * 100, 1), "%\n")
    
    if (length(diag_err$single_level_factors) > 0) {
      cat("- **Single-level factors:** ", paste(diag_err$single_level_factors, collapse = ", "), "\n")
      cat("  (These factors have only 1 level and prevent model fitting)\n")
    }
    
    if (!is.null(diag_err$condition_counts)) {
      cat("\n**Trials per condition:**\n")
      print(diag_err$condition_counts)
    }
  } else {
    cat("**Diagnostics:** No data available for analysis.\n")
  }
}
```

-----

# 7. Accuracy & Gaze Dynamics

## Effective Width ($W_e$)

*Lower $W_e$ indicates tighter shot grouping (higher precision).*

```{r we-summary}
#| tbl-cap: "Effective Width (px) by Condition"

we_summary <- df_iso %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Mean_We = round(mean(We, na.rm = TRUE), 2),
    SD_We = round(sd(We, na.rm = TRUE), 2),
    .groups = "drop"
  )

knitr::kable(we_summary)
```

```{r plot-we}
#| fig-cap: "Effective Target Width (Accuracy) by Modality and UI Mode. Lower values indicate tighter shot grouping and higher precision. Effective width (We) is calculated as 4.133 × SD of projected errors along the task axis, normalizing to a 4% error rate. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."

ggplot(df_iso, aes(x = ui_mode, y = We, fill = ui_mode)) +
  geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
              show.legend = FALSE) +
  geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
               outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
               position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
  facet_grid(modality ~ pressure,
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2,
                     labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Effective Width (px)",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
  )
```

## Endpoint Accuracy Scatter Plot

*Visualization of endpoint errors relative to target center. Each point represents one trial's endpoint position.*

```{r plot-accuracy-scatter}
#| fig-width: 12
#| fig-height: 8
#| fig-cap: "Endpoint Accuracy Scatter Plot for Gaze Modality. Each point represents one trial's endpoint position relative to the target center (0,0). The red dashed circle shows the approximate target size. Points closer to the center indicate better accuracy. Dotted lines indicate zero error in X and Y directions. Faceted by pressure condition."
# Calculate endpoint errors relative to target center
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  # Calculate target radius (approximate from W, assuming circular targets)
  target_radius <- ifelse("W" %in% names(gaze_accuracy), 
                          mean(gaze_accuracy$W, na.rm = TRUE) / 2, 
                          20)
  
  # Create circle data for target visualization
  circle_data <- data.frame(
    x = target_radius * cos(seq(0, 2*pi, length.out = 100)),
    y = target_radius * sin(seq(0, 2*pi, length.out = 100))
  )
  
  p_accuracy <- ggplot(gaze_accuracy, aes(x = err_x, y = err_y, color = UI)) +
    # Draw target circle (centered at 0,0)
    geom_path(data = circle_data, aes(x = x, y = y), 
              inherit.aes = FALSE, color = "red", linetype = "dashed", linewidth = 1) +
    # Scatter points
    geom_point(alpha = 0.5, size = 2) +
    # Reference lines
    geom_vline(xintercept = 0, color = "grey70", linetype = "dotted") +
    geom_hline(yintercept = 0, color = "grey70", linetype = "dotted") +
    # Facet by pressure
    facet_wrap(~PressureLabel) +
    scale_color_manual(values = custom_palette_2,
                        labels = c("Static", "Adaptive")) +
    coord_fixed(ratio = 1, xlim = c(-50, 50), ylim = c(-50, 50)) +
    labs(
      x = "Error X (px)",
      y = "Error Y (px)",
      color = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top")
  
  print(p_accuracy)
} else {
  cat("⚠ No gaze accuracy data available for scatter plot.\n")
}
```

```{r accuracy-summary}
# Summary statistics for accuracy scatter plot
df_accuracy <- df %>%
  filter(
    !is.na(endpoint_x), !is.na(endpoint_y),
    !is.na(target_center_x), !is.na(target_center_y),
    correct == TRUE | correct == "true" | correct == 1
  ) %>%
  mutate(
    err_x = endpoint_x - target_center_x,
    err_y = endpoint_y - target_center_y,
    err_distance = sqrt(err_x^2 + err_y^2),
    Modality = str_to_title(modality),
    UI = str_to_title(ui_mode)
  )

# Focus on Gaze modality (most interesting for accuracy)
gaze_accuracy <- df_accuracy %>%
  filter(str_to_lower(modality) == "gaze")

if (nrow(gaze_accuracy) > 0) {
  accuracy_summary <- gaze_accuracy %>%
    group_by(ui_mode, pressure) %>%
    summarise(
      N = n(),
      Mean_Error = round(mean(err_distance, na.rm = TRUE), 2),
      SD_Error = round(sd(err_distance, na.rm = TRUE), 2),
      Median_Error = round(median(err_distance, na.rm = TRUE), 2),
      .groups = "drop"
    )
  
  accuracy_summary %>%
    kable(caption = "Endpoint Error Distance (px) for Gaze Modality") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
} else {
  cat("⚠ No gaze accuracy data available for summary table.\n")
}
```

## The "Midas Touch" Struggle

*Target Re-entries measure how often the cursor drifted out of the target before selection.*

```{r reentry-summary}
reentry_summary <- df_iso %>%
  filter(!is.na(reentries)) %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    Mean_Reentries = round(mean(reentries, na.rm = TRUE), 2),
    SD_Reentries = round(sd(reentries, na.rm = TRUE), 2),
    .groups = "drop"
  )

reentry_summary %>%
  kable(caption = "Target Re-entries by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-reentry}
#| fig-cap: "Target Re-entries (Control Stability) by Modality and UI Mode. Re-entries count how often the cursor drifted out of the target before final selection, measuring control stability during the verification phase. Counts > 1 indicate slipping out of target. Lower values are better. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."

ggplot(df_iso %>% filter(!is.na(reentries)), 
       aes(x = ui_mode, y = reentries, fill = ui_mode)) +
  geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
              show.legend = FALSE) +
  geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
               outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
               position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
  facet_grid(modality ~ pressure,
             labeller = labeller(
               modality = function(x) paste("Modality:", str_to_title(x)),
               pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
             )) +
  scale_fill_manual(values = custom_palette_2,
                     labels = c("Static", "Adaptive")) +
  scale_x_discrete(labels = c("Static", "Adaptive")) +
  labs(
    y = "Avg Re-entries per Trial",
    x = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    strip.text = element_text(face = "bold", size = 12),
    strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
  )
```

-----

# 8. Workload (NASA-TLX)

*Subjective workload scores (lower is better).*

```{r plot-tlx}
#| fig-cap: "NASA-TLX Workload Scores by Modality and UI Mode. Scores range from 0-100, where lower values indicate lower subjective workload. The six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration) are shown separately. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."
# Check if TLX columns exist
tlx_cols <- c("tlx_mental", "tlx_physical", "tlx_temporal", "tlx_performance", "tlx_effort", "tlx_frustration")

if(all(tlx_cols %in% names(df_raw))) {
  df_tlx <- df_raw %>%
    filter(!is.na(pid)) %>%
    group_by(pid, modality, ui_mode) %>%
    summarise(across(starts_with("tlx_"), mean, na.rm = TRUE), .groups = "drop") %>%
    pivot_longer(cols = starts_with("tlx_"), names_to = "Scale", values_to = "Score") %>%
    mutate(
      Scale = str_remove(Scale, "tlx_"),
      Scale = str_to_title(Scale),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  # Summary table
  tlx_summary <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(
      Mean = round(mean(Score, na.rm = TRUE), 1),
      SD = round(sd(Score, na.rm = TRUE), 1),
      .groups = "drop"
    )
  
  tlx_summary %>%
    kable(caption = "NASA-TLX Scores by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
  # Visualization - improved faceting and aesthetics
  p1 <- ggplot(df_tlx, aes(x = ui_mode, y = Score, fill = ui_mode)) +
    geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                show.legend = FALSE) +
    geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                 outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
    stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                 position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
    facet_grid(modality ~ Scale,
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x)),
                 Scale = function(x) x
               )) +
    scale_fill_manual(values = custom_palette_2,
                       labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    labs(
      y = "Score (0-100)",
      x = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 11),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5),
      axis.text.x = element_text(angle = 0, hjust = 0.5)
    )
  
  print(p1)
  
  # Overall workload score - improved faceting
} else {
  cat("⚠ TLX Data not found in trial_data.csv\n")
  cat("Expected columns:", paste(tlx_cols, collapse = ", "), "\n")
  cat("Available columns with 'tlx':", 
      paste(grep("tlx", names(df_raw), value = TRUE, ignore.case = TRUE), collapse = ", "), "\n")
}
```

```{r plot-tlx-overall}
#| fig-cap: "Overall NASA-TLX Workload Score. Average across all 6 scales (Mental, Physical, Temporal, Performance, Effort, Frustration). Lower values indicate lower overall subjective workload. White diamonds show mean values. Violin plots show the distribution shape, boxplots show quartiles."
if(all(tlx_cols %in% names(df_raw)) && exists("df_tlx")) {
  df_tlx_overall <- df_tlx %>%
    group_by(pid, modality, ui_mode) %>%
    summarise(Overall_TLX = mean(Score, na.rm = TRUE), .groups = "drop") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive"))
    )
  
  p2 <- ggplot(df_tlx_overall, aes(x = ui_mode, y = Overall_TLX, fill = ui_mode)) +
    geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                show.legend = FALSE) +
    geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                 outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
    stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                 position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
    facet_wrap(~modality,
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x))
               )) +
    scale_fill_manual(values = custom_palette_2,
                       labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    labs(
      y = "Overall TLX Score (0-100)",
      x = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 12),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
    )
  
  print(p2)
}
```
  
```{r plot-tlx-stacked}
#| fig-cap: "NASA-TLX Workload Components (Stacked Bar Chart). Total height represents overall workload, with each colored segment representing one of the six TLX scales (Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, Frustration). Lower total height indicates lower overall subjective workload."
if(all(tlx_cols %in% names(df_raw)) && exists("df_tlx")) {
  # Stacked bar chart (inspired by Python script)
  df_tlx_stacked <- df_tlx %>%
    group_by(modality, ui_mode, Scale) %>%
    summarise(Mean_Score = mean(Score, na.rm = TRUE), .groups = "drop") %>%
    mutate(
      Modality = str_to_title(modality),
      UI = str_to_title(ui_mode),
      Condition = paste(Modality, UI, sep = "\n")
    )
  
  # Create stacked bar
  p3 <- ggplot(df_tlx_stacked, aes(x = Condition, y = Mean_Score, fill = Scale)) +
    geom_bar(stat = "identity", position = "stack", alpha = 0.8) +
    scale_fill_manual(values = custom_palette_multi) +
    labs(
      y = "TLX Score (0-100)",
      x = "Condition",
      fill = "TLX Scale"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "right",
      axis.text.x = element_text(angle = 0, hjust = 0.5)
    ) +
    guides(fill = guide_legend(ncol = 1))
  
  print(p3)
}
```

-----

# 9. Learning Curves & Practice Effects

**Research Question:** How does performance change within each condition? Do learning rates differ by condition?

*This section shows learning curves aligned by condition start (accounting for Williams counterbalancing). For block-level trends, see Section 12.*

```{r learning-curves}
# Calculate learning curves aligned by condition (not absolute trial number)
# With Williams counterbalancing, different participants experience conditions at different times
# So we align by "trial within condition" rather than absolute trial number

# For error rates, we need ALL trials (correct + incorrect)
# For movement time, we use only correct trials with valid RTs

# Option 1: Use trial_in_block if available (cleanest approach)
if ("trial_in_block" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      error_rate = 1 - mean(is_correct, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = mean(error_rate, na.rm = TRUE),
      error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_in_block), !is.na(block_number)) %>%
    group_by(trial_in_block, modality, ui_mode, pressure, pid, block_number) %>%
    summarise(
      rt_avg = mean(rt_s, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(trial_in_block, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_avg, na.rm = TRUE),
      rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_block", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_block"
  x_label <- "Trial Position in Block"
} else {
  # Option 2: Calculate position within condition by grouping consecutive trials
  # Error rates from all trials
  df_learning_errors <- df_all_trials %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      error_mean = 1 - mean(is_correct, na.rm = TRUE),
      error_se = sd(1 - is_correct, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Movement time from correct trials only
  df_learning_rt <- df %>%
    filter(!is.na(trial_number)) %>%
    arrange(pid, trial_number) %>%
    group_by(pid, modality, ui_mode, pressure) %>%
    mutate(
      trial_in_condition = row_number()
    ) %>%
    ungroup() %>%
    group_by(trial_in_condition, modality, ui_mode, pressure) %>%
    summarise(
      rt_mean = mean(rt_s, na.rm = TRUE),
      rt_se = sd(rt_s, na.rm = TRUE) / sqrt(n()),
      n_participants = n(),
      .groups = "drop"
    ) %>%
    filter(n_participants >= 2, trial_in_condition <= 50)
  
  # Combine
  df_learning_aligned <- df_learning_rt %>%
    left_join(df_learning_errors, by = c("trial_in_condition", "modality", "ui_mode", "pressure")) %>%
    mutate(n_participants = pmax(n_participants.x, n_participants.y, na.rm = TRUE)) %>%
    select(-n_participants.x, -n_participants.y)
  
  x_var <- "trial_in_condition"
  x_label <- "Trial Position in Condition"
}

# For throughput, we need to work with df_iso and join trial information
# Create approximate throughput learning by joining trial numbers
if ("trial_number" %in% names(df_raw)) {
  # Join df_iso with trial numbers from original data
  # Ensure pressure types match (df_iso has factor, df_raw has numeric)
  df_raw_for_join <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, trial_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),  # Convert to character for joining
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct()
  
  df_iso_for_join <- df_iso %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    )
  
  df_iso_with_trials <- df_raw_for_join %>%
    left_join(df_iso_for_join, by = c("pid", "modality", "ui_mode", "pressure", "A", "W")) %>%
    filter(!is.na(TP), !is.na(trial_number))
  
  if (nrow(df_iso_with_trials) > 0) {
    df_learning_tp <- df_iso_with_trials %>%
      mutate(
        trial_bin = cut(trial_number, breaks = seq(0, max(trial_number, na.rm = TRUE) + 1, 
                                                   length.out = 11), include.lowest = TRUE),
        trial_bin_num = as.numeric(trial_bin)
      ) %>%
      group_by(trial_bin_num, modality, ui_mode, pressure, pid) %>%
      summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
      group_by(trial_bin_num, modality, ui_mode, pressure) %>%
      summarise(
        TP_mean = mean(TP_avg, na.rm = TRUE),
        TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
        .groups = "drop"
      )
  } else {
    df_learning_tp <- data.frame()
  }
} else {
  df_learning_tp <- data.frame()
}

# Movement time learning curve (aligned by condition position)
if (nrow(df_learning_aligned) > 0) {
  # Check what conditions we have
  learning_summary_table <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      `N Positions` = n(),
      `Mean RT (s)` = round(mean(rt_mean, na.rm = TRUE), 3),
      `Mean Error Rate` = round(mean(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF")
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean RT (s)`, `Mean Error Rate`)
  
  learning_summary_table %>%
    kable(caption = "Learning Curve Data Summary by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-rt}
#| fig-cap: "Learning Curves: Movement Time Within Condition. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI."

if (nrow(df_learning_aligned) > 0) {
  # Create plot with dynamic x variable
  p1 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = rt_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points)
    geom_point(alpha = 0.4, size = 1.5) +
    # Smoothed trend line
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, labeller = labeller(
      pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF"),
      modality = function(x) str_to_title(x)
    )) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
    labs(
      title = "Learning Curves: Movement Time Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Movement Time (s)",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p1)
}
```
  
```{r error-summary-learning}
if (nrow(df_learning_aligned) > 0) {
  # Error rate learning curve (aligned by condition position)
  # Check error rate data availability
  error_summary <- df_learning_aligned %>%
    group_by(modality, ui_mode, pressure) %>%
    summarise(
      n = n(),
      mean_error = round(mean(error_mean, na.rm = TRUE), 4),
      min_error = round(min(error_mean, na.rm = TRUE), 4),
      max_error = round(max(error_mean, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    mutate(
      Modality = str_to_title(modality),
      `UI Mode` = str_to_title(ui_mode),
      Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
      `N Positions` = n,
      `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01),
      `Min Error Rate` = scales::percent(min_error, accuracy = 0.01),
      `Max Error Rate` = scales::percent(max_error, accuracy = 0.01)
    ) %>%
    select(Modality, `UI Mode`, Pressure, `N Positions`, `Mean Error Rate`, `Min Error Rate`, `Max Error Rate`)
  
  error_summary %>%
    kable(caption = "Error Rate Summary by Condition") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
}
```
  
```{r plot-learning-error}
#| fig-cap: "Learning Curves: Error Rate Within Condition. Learning aligned by position within condition (accounting for counterbalancing). LOESS smoothing. Lower is better. Shaded regions show 95% CI."

if (nrow(df_learning_aligned) > 0) {
  # Ensure we have data for both UI modes in each condition
  # If error rates are very low, use a different scale or show raw values
  p2 <- ggplot(df_learning_aligned, aes(x = .data[[x_var]], y = error_mean, color = ui_mode, fill = ui_mode)) +
    # Individual position means (light points) - make more visible
    geom_point(alpha = 0.6, size = 2, shape = 16) +
    # Smoothed trend line - only if we have enough data points
    geom_smooth(method = "loess", span = 0.4, se = TRUE, alpha = 0.2, linewidth = 1.2) +
    facet_grid(modality ~ pressure, labeller = labeller(
      pressure = function(x) {
        x_char <- as.character(x)
        ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
      },
      modality = function(x) str_to_title(x)
    )) +
    scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
    scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
    labs(
      title = "Learning Curves: Error Rate Within Condition",
      subtitle = paste("Learning aligned by position within condition (accounting for counterbalancing).",
                      "LOESS smoothing. Lower is better. Shaded regions show 95% CI."),
      x = x_label,
      y = "Error Rate",
      color = "UI Mode",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p2)
} else {
  cat("⚠ Insufficient data for learning curve visualization.\n")
}
```

*Note: Data aligned by position within condition to account for Williams counterbalancing. For block-level trends, see Section 12: Block Order & Temporal Effects.*

-----

# 10. Movement Quality Metrics

## Submovement Analysis

**Research Question:** Does adaptive UI reduce movement corrections? How do submovements relate to performance?

*Submovements indicate intermittent control - fewer submovements suggest smoother, more ballistic movements.*

```{r submovement-analysis}
if ("submovement_count" %in% names(df)) {
  df_submov <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov) > 0) {
    # Summary statistics
    submov_summary <- df_submov %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean = round(mean(submovement_count, na.rm = TRUE), 2),
        SD = round(sd(submovement_count, na.rm = TRUE), 2),
        Median = round(median(submovement_count, na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    submov_summary %>%
      kable(caption = "Submovement Count by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  }
}
```

```{r plot-submovement}
#| fig-cap: "Submovement Count (Movement Quality) by Modality and UI Mode. Lower indicates smoother, more ballistic movements. White diamonds indicate means. Violin plots show the distribution shape, boxplots show quartiles."

if ("submovement_count" %in% names(df)) {
  df_submov <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov) > 0) {
    # Visualization
    # Visualization - improved faceting and aesthetics
    p1 <- ggplot(df_submov, aes(x = ui_mode, y = submovement_count, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  show.legend = FALSE) +
      geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2,
                         labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        title = "Submovement Count (Movement Quality)",
        subtitle = "Lower indicates smoother, more ballistic movements. White diamonds indicate means.",
        x = "UI Mode",
        y = "Submovement Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p1)
  }
}
```

```{r plot-submovement-id}
#| fig-cap: "Submovements vs. Index of Difficulty. How movement corrections scale with task difficulty. Linear regression with 95% confidence intervals."

if ("submovement_count" %in% names(df)) {
  df_submov <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov) > 0) {
    # Submovements vs. Difficulty
    # Check if IDe exists, otherwise use ID
    if ("IDe" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(IDe)) %>%
        mutate(difficulty = IDe)
    } else if ("ID" %in% names(df_submov)) {
      df_submov_id <- df_submov %>%
        filter(!is.na(ID)) %>%
        mutate(difficulty = ID)
    } else {
      df_submov_id <- data.frame()
    }
    
    if (nrow(df_submov_id) > 0) {
      p2 <- ggplot(df_submov_id, aes(x = difficulty, y = submovement_count, color = ui_mode)) +
        geom_point(alpha = 0.3, size = 1) +
        geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
        facet_grid(modality ~ pressure, labeller = labeller(
          pressure = function(x) paste("Pressure:", x),
          modality = function(x) str_to_title(x)
        )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        labs(
          title = "Submovements vs. Index of Difficulty",
          subtitle = "How movement corrections scale with task difficulty",
          x = "Index of Difficulty (bits)",
          y = "Submovement Count",
          color = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(legend.position = "top", strip.text = element_text(face = "bold"))
      
      print(p2)
    }
  } else {
    cat("⚠ No valid submovement data available.\n")
  }
} else {
  cat("⚠ submovement_count column not found in dataset.\n")
}
```

## Verification Time Analysis

**Research Question:** How much time is spent "stopping" vs. "moving"? Does adaptive UI reduce verification time?

*Verification time represents the "precise stopping" phase, separate from the ballistic movement phase.*

```{r verification-time}
if ("verification_time_ms" %in% names(df)) {
  df_verify <- df %>%
    filter(!is.na(verification_time_ms), verification_time_ms > 0, verification_time_ms <= 6000)
  
  if (nrow(df_verify) > 0) {
    df_verify <- df_verify %>%
      mutate(
        verification_s = verification_time_ms / 1000,
        movement_s = rt_s - verification_s,
        verify_ratio = verification_time_ms / rt_ms,
        # Ensure PressureLabel exists
        PressureLabel = ifelse(pressure == 1, "Pressure: ON", "Pressure: OFF")
      )
    
    # Summary statistics
    verify_summary <- df_verify %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean_Verify = round(mean(verification_s, na.rm = TRUE), 3),
        Mean_MT = round(mean(rt_s, na.rm = TRUE), 3),
        Mean_Ratio = round(mean(verify_ratio, na.rm = TRUE), 3),
        .groups = "drop"
      )
    
    verify_summary %>%
      kable(caption = "Verification Time by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Visualization - improved faceting and aesthetics
    p1 <- ggplot(df_verify, aes(x = ui_mode, y = verification_s, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  show.legend = FALSE) +
      geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2,
                         labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        title = "Verification Time (Stopping Phase)",
        subtitle = "Time spent precisely stopping at target. Lower is better. White diamonds indicate means.",
        x = "UI Mode",
        y = "Verification Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p1)
    
    # Verification ratio (what proportion of total time is verification) - improved faceting
    p2 <- ggplot(df_verify, aes(x = ui_mode, y = verify_ratio, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  show.legend = FALSE) +
      geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2,
                         labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      scale_y_continuous(labels = scales::percent) +
      labs(
        title = "Verification Time as Proportion of Total Movement Time",
        subtitle = "What fraction of time is spent in the stopping phase? White diamonds indicate means.",
        x = "UI Mode",
        y = "Verification Ratio",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p2)
  } else {
    cat("⚠ No valid verification time data available.\n")
  }
} else {
  cat("⚠ verification_time_ms column not found in dataset.\n")
}
```

-----

# 11. Error Patterns & Types

**Research Question:** What types of errors occur? Do error patterns differ by condition?

```{r error-types}
if ("err_type" %in% names(df_raw)) {
  df_error_types <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    filter(!is.na(err_type), err_type != "") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      err_type = factor(err_type, levels = c("miss", "timeout", "slip"))
    )
  
  if (nrow(df_error_types) > 0) {
    # Summary table
    error_type_summary <- df_error_types %>%
      group_by(modality, ui_mode, pressure, err_type) %>%
      summarise(Count = n(), .groups = "drop") %>%
      group_by(modality, ui_mode, pressure) %>%
      mutate(
        Total = sum(Count),
        Percentage = round(100 * Count / Total, 1)
      ) %>%
      ungroup()
    
    error_type_summary %>%
      kable(caption = "Error Type Distribution by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  }
}
```

```{r plot-error-types-stacked}
#| fig-cap: "Error Type Distribution. Breakdown of error types by condition. Stacked bars show absolute counts for each error type (Miss, Timeout, Slip)."

if ("err_type" %in% names(df_raw)) {
  df_error_types <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    filter(!is.na(err_type), err_type != "") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      err_type = factor(err_type, levels = c("miss", "timeout", "slip"))
    )
  
  if (nrow(df_error_types) > 0) {
    error_type_summary <- df_error_types %>%
      group_by(modality, ui_mode, pressure, err_type) %>%
      summarise(Count = n(), .groups = "drop") %>%
      group_by(modality, ui_mode, pressure) %>%
      mutate(
        Total = sum(Count),
        Percentage = round(100 * Count / Total, 1)
      ) %>%
      ungroup()
    
    # Stacked bar chart
    p1 <- ggplot(error_type_summary, aes(x = interaction(modality, ui_mode), y = Count, fill = err_type)) +
      geom_bar(stat = "identity", position = "stack", alpha = 0.8) +
      facet_wrap(~pressure, labeller = labeller(
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_multi[1:3],
                         labels = c("Miss", "Timeout", "Slip")) +
      labs(
        title = "Error Type Distribution",
        subtitle = "Breakdown of error types by condition",
        x = "Condition (Modality - UI Mode)",
        y = "Error Count",
        fill = "Error Type"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1),
        strip.text = element_text(face = "bold")
      )
    
    print(p1)
  }
}
```

```{r plot-error-types-proportional}
#| fig-cap: "Error Type Proportions. Relative distribution of error types. Stacked bars show percentage of each error type (Miss, Timeout, Slip) within each condition."

if ("err_type" %in% names(df_raw)) {
  df_error_types <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    filter(!is.na(err_type), err_type != "") %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      err_type = factor(err_type, levels = c("miss", "timeout", "slip"))
    )
  
  if (nrow(df_error_types) > 0) {
    error_type_summary <- df_error_types %>%
      group_by(modality, ui_mode, pressure, err_type) %>%
      summarise(Count = n(), .groups = "drop") %>%
      group_by(modality, ui_mode, pressure) %>%
      mutate(
        Total = sum(Count),
        Percentage = round(100 * Count / Total, 1)
      ) %>%
      ungroup()
    
    # Proportional stacked bar
    p2 <- ggplot(error_type_summary, aes(x = interaction(modality, ui_mode), y = Percentage, fill = err_type)) +
      geom_bar(stat = "identity", position = "stack", alpha = 0.8) +
      facet_wrap(~pressure, labeller = labeller(
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
      scale_fill_manual(values = custom_palette_multi[1:3],
                         labels = c("Miss", "Timeout", "Slip")) +
      scale_y_continuous(labels = scales::percent_format(scale = 1)) +
      labs(
        title = "Error Type Proportions",
        subtitle = "Relative distribution of error types",
        x = "Condition (Modality - UI Mode)",
        y = "Percentage of Errors",
        fill = "Error Type"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1),
        strip.text = element_text(face = "bold")
      )
    
    print(p2)
  } else {
    cat("⚠ No error type data available.\n")
  }
} else {
  cat("⚠ err_type column not found in dataset.\n")
}
```

-----

# 12. Block Order & Temporal Effects

**Research Question:** Are there order effects? Does performance improve or degrade over blocks?

```{r block-effects}
# Performance by block number
# Note: TP is only in df_iso, so we'll use movement time and error rate
# Error rates need ALL trials, movement time uses only correct trials

# Error rates from all trials
df_blocks_errors <- df_all_trials %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    error_rate = 1 - mean(is_correct, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    error_mean = mean(error_rate, na.rm = TRUE),
    error_se = sd(error_rate, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Movement time from correct trials only
df_blocks_rt <- df %>%
  filter(!is.na(block_number)) %>%
  group_by(block_number, modality, ui_mode, pressure, pid) %>%
  summarise(
    rt_avg = mean(rt_s, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(block_number, modality, ui_mode, pressure) %>%
  summarise(
    rt_mean = mean(rt_avg, na.rm = TRUE),
    rt_se = sd(rt_avg, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Combine for convenience
df_blocks <- df_blocks_rt %>%
  left_join(df_blocks_errors, by = c("block_number", "modality", "ui_mode", "pressure"))

# Try to get throughput by block from df_iso
# Join df_iso with block information
if ("block_number" %in% names(df_raw)) {
  df_blocks_tp <- df_raw %>%
    filter(practice == "false" | practice == FALSE | is.na(practice)) %>%
    select(pid, modality, ui_mode, pressure, block_number, A, W) %>%
    mutate(
      pressure = as.character(pressure),
      modality = as.character(modality),
      ui_mode = as.character(ui_mode),
      pid = as.character(pid)
    ) %>%
    distinct() %>%
    left_join(
      df_iso %>% mutate(
        pressure = as.character(pressure),
        modality = as.character(modality),
        ui_mode = as.character(ui_mode),
        pid = as.character(pid)
      ),
      by = c("pid", "modality", "ui_mode", "pressure", "A", "W")
    ) %>%
    filter(!is.na(TP), !is.na(block_number)) %>%
    group_by(block_number, modality, ui_mode, pressure, pid) %>%
    summarise(TP_avg = mean(TP, na.rm = TRUE), .groups = "drop") %>%
    group_by(block_number, modality, ui_mode, pressure) %>%
    summarise(
      TP_mean = mean(TP_avg, na.rm = TRUE),
      TP_se = sd(TP_avg, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
} else {
  df_blocks_tp <- data.frame()
}
```

```{r plot-blocks-tp}
#| fig-cap: "Performance Across Blocks: Throughput. Throughput by block number. Higher is better. Shaded regions show ±1 SE."

# Throughput by block (if data available)
if (nrow(df_blocks_tp) > 0) {
  p1 <- ggplot(df_blocks_tp, aes(x = block_number, y = TP_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = TP_mean - TP_se, ymax = TP_mean + TP_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  labs(
    x = "Block Number",
    y = "Throughput (bits/s)",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))
  
  print(p1)
} else {
  cat("⚠ Throughput by block data not available (requires block-level aggregation).\n")
}
```

```{r plot-blocks-rt}
#| fig-cap: "Performance Across Blocks: Movement Time. Movement time by block number. Lower is better. Shaded regions show ±1 SE."

# Movement time by block
p2 <- ggplot(df_blocks, aes(x = block_number, y = rt_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = rt_mean - rt_se, ymax = rt_mean + rt_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
  labs(
    title = "Performance Across Blocks: Movement Time",
    subtitle = "Movement time by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Movement Time (s)",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p2)

# Error rate by block
# Check what conditions we have for blocks
block_summary_table <- df_blocks %>%
  group_by(modality, ui_mode, pressure) %>%
  summarise(
    n_blocks = n(),
    mean_error = round(mean(error_mean, na.rm = TRUE), 4),
    .groups = "drop"
  ) %>%
  mutate(
    Modality = str_to_title(modality),
    `UI Mode` = str_to_title(ui_mode),
    Pressure = ifelse(pressure == "1" | pressure == 1, "ON", "OFF"),
    `N Blocks` = n_blocks,
    `Mean Error Rate` = scales::percent(mean_error, accuracy = 0.01)
  ) %>%
  select(Modality, `UI Mode`, Pressure, `N Blocks`, `Mean Error Rate`)

block_summary_table %>%
  kable(caption = "Block-Level Data Summary by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

```{r plot-blocks-error}
#| fig-cap: "Performance Across Blocks: Error Rate. Error rate by block number. Lower is better. Shaded regions show ±1 SE."

p3 <- ggplot(df_blocks, aes(x = block_number, y = error_mean, color = ui_mode, fill = ui_mode)) +
  geom_ribbon(aes(ymin = error_mean - error_se, ymax = error_mean + error_se), 
              alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  facet_grid(modality ~ pressure, labeller = labeller(
    pressure = function(x) {
      x_char <- as.character(x)
      ifelse(x_char == "1" | x_char == "1.0", "Pressure: ON", "Pressure: OFF")
    },
    modality = function(x) str_to_title(x)
  )) +
  scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive"), drop = FALSE) +
  scale_y_continuous(labels = scales::percent, limits = c(0, NA)) +
  labs(
    title = "Performance Across Blocks: Error Rate",
    subtitle = "Error rate by block number. Lower is better. Shaded regions show ±1 SE.",
    x = "Block Number",
    y = "Error Rate",
    color = "UI Mode",
    fill = "UI Mode"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top", strip.text = element_text(face = "bold"))

print(p3)
```

-----

# 13. Spatial Patterns & Heatmaps

**Research Question:** Are there spatial biases in performance? Do some screen regions show better/worse performance?

## Performance by Target Position

```{r spatial-heatmap}
# Create spatial performance heatmap
# Error rates need ALL trials, movement time uses only correct trials
if ("target_center_x" %in% names(df_all_trials) && "target_center_y" %in% names(df_all_trials)) {
  # Error rates from all trials
  df_spatial_errors <- df_all_trials %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_error = 1 - mean(is_correct, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Movement time from correct trials only
  df_spatial_rt <- df %>%
    filter(!is.na(target_center_x), !is.na(target_center_y)) %>%
    mutate(
      x_bin = cut(target_center_x, breaks = seq(0, max(target_center_x, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      y_bin = cut(target_center_y, breaks = seq(0, max(target_center_y, na.rm = TRUE) + 100, 
                                                length.out = 9), include.lowest = TRUE),
      x_bin_num = as.numeric(x_bin),
      y_bin_num = as.numeric(y_bin)
    ) %>%
    group_by(x_bin_num, y_bin_num, modality, ui_mode) %>%
    summarise(
      mean_rt = mean(rt_s, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 3)
  
  # Combine
  df_spatial <- df_spatial_rt %>%
    left_join(df_spatial_errors, by = c("x_bin_num", "y_bin_num", "modality", "ui_mode")) %>%
    mutate(n_trials = pmax(n_trials.x, n_trials.y, na.rm = TRUE)) %>%
    select(-n_trials.x, -n_trials.y)
  
  if (nrow(df_spatial) > 0) {
    # Movement time heatmap
    p1 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_rt)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, labeller = labeller(
        modality = function(x) str_to_title(x),
        ui_mode = function(x) str_to_title(x)
      )) +
      scale_fill_viridis_c(name = "MT (s)", option = "plasma", direction = -1) +
      labs(
        title = "Spatial Performance Heatmap: Movement Time",
        subtitle = "Darker colors indicate faster movement times. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p1)
    
    # Error rate heatmap
    p2 <- ggplot(df_spatial, aes(x = x_bin_num, y = y_bin_num, fill = mean_error)) +
      geom_tile(alpha = 0.8) +
      facet_grid(modality ~ ui_mode, labeller = labeller(
        modality = function(x) str_to_title(x),
        ui_mode = function(x) str_to_title(x)
      )) +
      scale_fill_viridis_c(name = "Error\nRate", option = "inferno", direction = 1) +
      labs(
        title = "Spatial Performance Heatmap: Error Rate",
        subtitle = "Darker colors indicate higher error rates. Grid shows target positions.",
        x = "Target X Position (binned)",
        y = "Target Y Position (binned)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)
      )
    
    print(p2)
  } else {
    cat("⚠ Insufficient spatial data for heatmap visualization.\n")
  }
} else {
  cat("⚠ Target position columns (target_center_x, target_center_y) not found.\n")
}
```

## Error Density Heatmap

*Where do endpoint errors occur? Are there systematic spatial biases?*

```{r error-density-heatmap}
# Error density heatmap for gaze modality
# Recalculate error data to ensure we have it
if ("endpoint_x" %in% names(df) && "target_center_x" %in% names(df)) {
  df_error_spatial <- df %>%
    filter(
      !is.na(endpoint_x), !is.na(endpoint_y),
      !is.na(target_center_x), !is.na(target_center_y),
      correct == TRUE | correct == "true" | correct == 1
    ) %>%
    mutate(
      err_x = as.numeric(endpoint_x) - as.numeric(target_center_x),
      err_y = as.numeric(endpoint_y) - as.numeric(target_center_y)
    )
  
  # Focus on gaze modality
  df_error_gaze <- df_error_spatial %>%
    filter(str_to_lower(modality) == "gaze") %>%
    filter(!is.na(err_x), !is.na(err_y), is.finite(err_x), is.finite(err_y))
} else {
  df_error_gaze <- data.frame()
}

if (nrow(df_error_gaze) > 0) {
  # Check actual data range
  err_x_range <- range(df_error_gaze$err_x, na.rm = TRUE)
  err_y_range <- range(df_error_gaze$err_y, na.rm = TRUE)
  
  # Use actual data range, but cap extreme outliers
  x_limit <- min(100, max(abs(err_x_range), na.rm = TRUE) * 1.2)
  y_limit <- min(100, max(abs(err_y_range), na.rm = TRUE) * 1.2)
  
  # Filter to reasonable range
  df_error_gaze <- df_error_gaze %>%
    filter(
      abs(err_x) <= x_limit,
      abs(err_y) <= y_limit
    )
  
  if (nrow(df_error_gaze) > 0) {
    # 2D density heatmap
    p1 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
      stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
      geom_vline(xintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "white", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_fill_viridis_c(name = "Density", option = "plasma") +
      coord_fixed(ratio = 1) +
      labs(
        title = "Endpoint Error Density: Gaze Modality",
        subtitle = paste("Heatmap shows where endpoints cluster relative to target center (0,0).",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p1)
    
    # Hexbin plot - COMMENTED OUT due to scaling issues
    # # Hexbin plot - use actual data range for limits
    # # Calculate number of bins based on data
    # n_bins <- min(20, max(5, round(sqrt(nrow(df_error_gaze)) / 2)))
    # 
    # # Get actual data limits for setting axis ranges
    # x_min <- min(df_error_gaze$err_x, na.rm = TRUE)
    # x_max <- max(df_error_gaze$err_x, na.rm = TRUE)
    # y_min <- min(df_error_gaze$err_y, na.rm = TRUE)
    # y_max <- max(df_error_gaze$err_y, na.rm = TRUE)
    # 
    # # Add some padding
    # x_pad <- (x_max - x_min) * 0.1
    # y_pad <- (y_max - y_min) * 0.1
    # 
    # p2 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y)) +
    #   geom_hex(bins = n_bins, alpha = 0.8) +
    #   geom_vline(xintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   geom_hline(yintercept = 0, color = "red", linetype = "dashed", linewidth = 0.5) +
    #   facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
    #   scale_fill_viridis_c(name = "Count", option = "plasma", na.value = "white") +
    #   coord_fixed(ratio = 1, xlim = c(x_min - x_pad, x_max + x_pad), 
    #               ylim = c(y_min - y_pad, y_max + y_pad)) +
    #   labs(
    #     title = "Endpoint Error Distribution: Gaze Modality (Hexbin)",
    #     subtitle = paste("Hexagonal binning shows error density. Red lines indicate target center.",
    #                     "N =", nrow(df_error_gaze), "trials. Data range: X [", 
    #                     round(x_min, 1), ",", round(x_max, 1), "], Y [",
    #                     round(y_min, 1), ",", round(y_max, 1), "] px."),
    #     x = "Error X (px)",
    #     y = "Error Y (px)"
    #   ) +
    #   theme_minimal(base_size = 14) +
    #   theme(
    #     legend.position = "right",
    #     strip.text = element_text(face = "bold")
    #   )
    # 
    # print(p2)
    
    # Always show scatter plot as well for comparison
    p3 <- ggplot(df_error_gaze, aes(x = err_x, y = err_y, color = ui_mode)) +
      geom_point(alpha = 0.5, size = 1.5) +
      geom_vline(xintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      geom_hline(yintercept = 0, color = "grey70", linetype = "dashed", linewidth = 0.5) +
      facet_wrap(~ui_mode, labeller = labeller(ui_mode = function(x) str_to_title(x))) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      coord_fixed(ratio = 1, xlim = c(-x_limit, x_limit), ylim = c(-y_limit, y_limit)) +
      labs(
        title = "Endpoint Error Scatter: Gaze Modality",
        subtitle = paste("Individual trial endpoints. Red lines indicate target center.",
                        "N =", nrow(df_error_gaze), "trials."),
        x = "Error X (px)",
        y = "Error Y (px)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "right",
        strip.text = element_text(face = "bold")
      )
    
    print(p3)
  } else {
    cat("⚠ No error data available after filtering.\n")
  }
} else {
  cat("⚠ Insufficient error spatial data for heatmap visualization.\n")
}
```

-----

# 14. Adaptive UI Mechanism Analysis

## Width Scaling (Target Size Adaptation)

**Research Question:** Does the adaptive UI dynamically change target sizes? How does width scaling relate to performance?

*The adaptive UI may scale target widths based on performance. This section examines whether and how target sizes are adjusted.*

```{r width-scaling-analysis}
# Check if width scaling fields exist
if (all(c("nominal_width_px", "displayed_width_px", "width_scale_factor") %in% names(df_raw))) {
  df_width <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(nominal_width_px),
      !is.na(displayed_width_px)
    ) %>%
    mutate(
      # Calculate scale factor if not present
      width_scale_factor = ifelse(
        is.na(width_scale_factor) | width_scale_factor == 0,
        displayed_width_px / nominal_width_px,
        width_scale_factor
      ),
      width_difference = displayed_width_px - nominal_width_px,
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(width_scale_factor),
      is.finite(width_scale_factor),
      width_scale_factor > 0,
      width_scale_factor < 5  # Filter extreme outliers
    )
  
  if (nrow(df_width) > 0) {
    # Check if any scaling actually occurred
    has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
    
    if (!has_scaling) {
      cat("**Note:** No target width scaling was observed in this dataset.\n")
      cat("All `width_scale_factor` values are 1.0 (no scaling applied).\n\n")
      cat("This indicates that the adaptive policy did not trigger during data collection.\n")
      cat("Possible reasons:\n")
      cat("- Hysteresis gate threshold not met (requires N consecutive slow/error trials)\n")
      cat("- Performance thresholds (RT p75, error burst) not exceeded\n")
      cat("- Adaptive policy not properly configured or enabled\n")
      cat("- Participants performed well enough that adaptation was not needed\n\n")
      
      # Still show the summary table for completeness
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = "Target Width Scaling by Condition (No Scaling Observed)") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    } else {
      # Summary statistics (when scaling did occur)
      width_summary <- df_width %>%
        group_by(modality, ui_mode, pressure) %>%
        summarise(
          N = n(),
          Mean_Scale = round(mean(width_scale_factor, na.rm = TRUE), 3),
          SD_Scale = round(sd(width_scale_factor, na.rm = TRUE), 3),
          Mean_Diff = round(mean(width_difference, na.rm = TRUE), 2),
          SD_Diff = round(sd(width_difference, na.rm = TRUE), 2),
          Pct_Scaled = round(100 * mean(width_scale_factor != 1, na.rm = TRUE), 1),
          .groups = "drop"
        )
      
      width_summary %>%
        kable(caption = "Target Width Scaling by Condition") %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    }
  } else {
    cat("⚠ No valid width scaling data available.\n")
  }
} else {
  cat("⚠ Width scaling columns not found in dataset.\n")
}
```

```{r plot-width-scaling}
#| fig-cap: "Target Width Scale Factor by Condition. Scale factor = 1.0 means no scaling (nominal size). Values > 1.0 indicate enlarged targets, < 1.0 indicate reduced targets. White diamonds show mean values."

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  if (!has_scaling) {
    cat("**Note:** Visualization skipped - no width scaling observed (all values = 1.0).\n")
  } else {
    # Visualization - width scale factor
    p1 <- ggplot(df_width, aes(x = ui_mode, y = width_scale_factor, fill = ui_mode)) +
    geom_hline(yintercept = 1.0, linetype = "dashed", color = "red", linewidth = 0.8) +
    geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                show.legend = FALSE) +
    geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                 outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
    stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                 position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
    facet_grid(modality ~ pressure,
               labeller = labeller(
                 modality = function(x) paste("Modality:", str_to_title(x)),
                 pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
               )) +
    scale_fill_manual(values = custom_palette_2,
                       labels = c("Static", "Adaptive")) +
    scale_x_discrete(labels = c("Static", "Adaptive")) +
    labs(
      x = "UI Mode",
      y = "Width Scale Factor",
      fill = "UI Mode"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "top",
      strip.text = element_text(face = "bold", size = 12),
      strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
      panel.grid.minor = element_blank(),
      panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
    )
  
    print(p1)
  }
}
```

```{r plot-width-scaling-over-time}
#| fig-cap: "Width Scaling Over Time (by Trial Number). Shows how target scaling changes throughout the experiment. LOESS smoothing with 95% CI."

if (exists("df_width") && nrow(df_width) > 0 && "trial_number" %in% names(df_width)) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  if (!has_scaling) {
    cat("**Note:** Time series plot skipped - no width scaling observed.\n")
  } else {
    # Width scaling over time
    df_width_time <- df_width %>%
      filter(!is.na(trial_number), trial_number > 0, trial_number <= 500)
    
    if (nrow(df_width_time) > 0) {
    p2 <- ggplot(df_width_time, aes(x = trial_number, y = width_scale_factor, color = ui_mode)) +
      geom_hline(yintercept = 1.0, linetype = "dashed", color = "grey50", linewidth = 0.5) +
      geom_point(alpha = 0.2, size = 1) +
      geom_smooth(method = "loess", span = 0.3, se = TRUE, alpha = 0.2, linewidth = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Trial Number",
        y = "Width Scale Factor",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
      print(p2)
    }
  }
}
```

```{r plot-width-vs-performance}
#| fig-cap: "Width Scale Factor vs. Movement Time. Does target scaling improve performance? Linear regression with 95% CI."

if (exists("df_width") && nrow(df_width) > 0) {
  # Check if any scaling occurred
  has_scaling <- any(df_width$width_scale_factor != 1, na.rm = TRUE)
  
  if (!has_scaling) {
    cat("**Note:** Performance relationship plot skipped - no width scaling observed.\n")
  } else {
    # Join with performance data
    df_width_perf <- df_width %>%
      filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
      mutate(rt_s = rt_ms / 1000)
    
    if (nrow(df_width_perf) > 0) {
    p3 <- ggplot(df_width_perf, aes(x = width_scale_factor, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.3, size = 1.5) +
      geom_smooth(method = "lm", se = TRUE, alpha = 0.2, linewidth = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Width Scale Factor",
        y = "Movement Time (s)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5)
      )
    
      print(p3)
    }
  }
}
```

## Alignment Gate Metrics

**Research Question:** If alignment gates are used, how do they affect performance? How often are false triggers detected?

*Alignment gates may be used to ensure proper cursor alignment before selection. This section examines their usage and effectiveness.*

```{r alignment-gate-analysis}
# Check if alignment gate fields exist
if (all(c("alignment_gate_enabled", "alignment_gate_false_triggers") %in% names(df_raw))) {
  df_gate <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      alignment_gate_enabled == TRUE | alignment_gate_enabled == "true"
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    )
  
  if (nrow(df_gate) > 0) {
    # Summary statistics
    gate_summary <- df_gate %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_False_Triggers = round(mean(alignment_gate_false_triggers, na.rm = TRUE), 2),
        SD_False_Triggers = round(sd(alignment_gate_false_triggers, na.rm = TRUE), 2),
        Mean_Recovery_Time = round(mean(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        SD_Recovery_Time = round(sd(alignment_gate_recovery_time_ms, na.rm = TRUE), 1),
        Mean_Mean_Recovery_Time = round(mean(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        SD_Mean_Recovery_Time = round(sd(alignment_gate_mean_recovery_time_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    gate_summary %>%
      kable(caption = "Alignment Gate Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else {
    cat("⚠ No trials with alignment gate enabled found in dataset.\n")
  }
} else {
  cat("⚠ Alignment gate columns not found in dataset.\n")
}
```

```{r plot-alignment-gate}
#| fig-cap: "Alignment Gate False Triggers by Condition. Number of false triggers per trial. Lower is better. White diamonds show mean values."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - false triggers
  if (sum(!is.na(df_gate$alignment_gate_false_triggers)) > 0) {
    p1 <- ggplot(df_gate %>% filter(!is.na(alignment_gate_false_triggers)), 
                 aes(x = ui_mode, y = alignment_gate_false_triggers, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  show.legend = FALSE) +
      geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2,
                         labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "False Trigger Count",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p1)
  }
}
```

```{r plot-alignment-recovery}
#| fig-cap: "Alignment Gate Recovery Time by Condition. Time spent recovering from false triggers (ms). Lower is better. White diamonds show mean values."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - recovery time
  if (sum(!is.na(df_gate$alignment_gate_recovery_time_ms)) > 0) {
    df_gate_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_recovery_time_ms), alignment_gate_recovery_time_ms > 0)
    
    if (nrow(df_gate_recovery) > 0) {
      p2 <- ggplot(df_gate_recovery, 
                   aes(x = ui_mode, y = alignment_gate_recovery_time_ms, fill = ui_mode)) +
        geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                    show.legend = FALSE) +
        geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                     outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
        stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                     position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_fill_manual(values = custom_palette_2,
                           labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
        )
      
      print(p2)
    }
  }
}
```

```{r plot-alignment-mean-recovery}
#| fig-cap: "Alignment Gate Mean Recovery Time by Condition. Average recovery time across all false triggers within a trial (ms). Lower is better. White diamonds show mean values."

if (exists("df_gate") && nrow(df_gate) > 0) {
  # Visualization - mean recovery time (averaged across all recoveries in trial)
  if (sum(!is.na(df_gate$alignment_gate_mean_recovery_time_ms)) > 0) {
    df_gate_mean_recovery <- df_gate %>%
      filter(!is.na(alignment_gate_mean_recovery_time_ms), alignment_gate_mean_recovery_time_ms > 0)
    
    if (nrow(df_gate_mean_recovery) > 0) {
      p3 <- ggplot(df_gate_mean_recovery, 
                   aes(x = ui_mode, y = alignment_gate_mean_recovery_time_ms, fill = ui_mode)) +
        geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                    show.legend = FALSE) +
        geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                     outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
        stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                     position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_fill_manual(values = custom_palette_2,
                           labels = c("Static", "Adaptive")) +
        scale_x_discrete(labels = c("Static", "Adaptive")) +
        labs(
          x = "UI Mode",
          y = "Mean Recovery Time (ms)",
          fill = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank(),
          panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
        )
      
      print(p3)
    }
  }
}
```

## Task Type Analysis

**Research Question:** Are there different task types (point vs. drag)? How does performance differ across task types?

*If the experiment includes different task types, this section examines performance differences.*

```{r task-type-analysis}
# Check if task_type field exists
if ("task_type" %in% names(df_raw)) {
  df_task <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      !is.na(task_type),
      task_type != ""
    ) %>%
    mutate(
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure),
      task_type = factor(task_type)
    )
  
  if (nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
    # Summary statistics
    task_summary <- df_task %>%
      group_by(task_type, modality, ui_mode) %>%
      summarise(
        N_Trials = n(),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        SD_RT = round(sd(rt_ms, na.rm = TRUE), 1),
        Error_Rate = round(100 * mean(is.na(correct) | correct == FALSE | correct == "false", na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    task_summary %>%
      kable(caption = "Performance by Task Type") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else if (nrow(df_task) > 0) {
    cat("⚠ Only one task type found:", unique(df_task$task_type), "\n")
  } else {
    cat("⚠ No valid task type data available.\n")
  }
} else {
  cat("⚠ task_type column not found in dataset.\n")
}
```

```{r plot-task-type-rt}
#| fig-cap: "Movement Time by Task Type. Comparison of performance across different task types (if multiple exist). Lower is better. White diamonds show mean values."

if (exists("df_task") && nrow(df_task) > 0 && n_distinct(df_task$task_type) > 1) {
  # Filter for valid RT
  df_task_rt <- df_task %>%
    filter(!is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000) %>%
    mutate(rt_s = rt_ms / 1000)
  
  if (nrow(df_task_rt) > 0) {
    p1 <- ggplot(df_task_rt, aes(x = task_type, y = rt_s, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  position = position_dodge(0.9)) +
      geom_boxplot(width = 0.3, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_wrap(~modality,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x))
                 )) +
      scale_fill_manual(values = custom_palette_2,
                         labels = c("Static", "Adaptive")) +
      labs(
        x = "Task Type",
        y = "Movement Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p1)
  }
}
```

```{r drag-distance-analysis}
# Compute path length from trajectory and derive efficiency metrics
# Note: For pointing tasks, path length is the actual cursor travel distance (not straight-line A)
# This analysis requires trajectory data - early participants may not have it

library(jsonlite)
library(purrr)

# Helper function to compute path length from trajectory JSON
path_length <- function(traj_json) {
  if (is.na(traj_json) || traj_json == "" || traj_json == "[]" || traj_json == "null") {
    return(NA_real_)
  }
  pts <- tryCatch(fromJSON(traj_json), error = function(e) NULL)
  if (is.null(pts) || length(pts) == 0 || (is.data.frame(pts) && nrow(pts) < 2)) {
    return(NA_real_)
  }
  # Handle both list and data.frame formats
  if (is.data.frame(pts)) {
    dx <- diff(pts$x)
    dy <- diff(pts$y)
  } else if (is.list(pts) && length(pts) > 0 && "x" %in% names(pts[[1]])) {
    x_vals <- sapply(pts, function(p) p$x)
    y_vals <- sapply(pts, function(p) p$y)
    dx <- diff(x_vals)
    dy <- diff(y_vals)
  } else {
    return(NA_real_)
  }
  sum(sqrt(dx^2 + dy^2), na.rm = TRUE)
}

# Prepare data with computed path length and derived metrics
if ("trajectory" %in% names(df_raw) && "A" %in% names(df_raw)) {
  df_drag <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      correct == TRUE | correct == "true" | correct == 1,  # Only successful trials
      !is.na(rt_ms), rt_ms >= 150, rt_ms <= 6000,
      !is.na(A), A > 0
    ) %>%
    mutate(
      rt_s = rt_ms / 1000,
      # Compute path length from trajectory
      path_length_computed = map_dbl(trajectory, path_length),
      # Use existing drag_distance if numeric and valid, otherwise use computed
      # Convert drag_distance to numeric first to handle character/string values
      drag_distance_raw = if ("drag_distance" %in% names(.)) {
        suppressWarnings(as.numeric(drag_distance))
      } else {
        NA_real_
      },
      # Prefer computed path length, fall back to drag_distance if valid
      drag_distance = ifelse(
        !is.na(path_length_computed) & path_length_computed > 0,
        path_length_computed,
        ifelse(!is.na(drag_distance_raw) & drag_distance_raw > 0, drag_distance_raw, path_length_computed)
      ),
      # Derived metrics
      ratio = drag_distance / A,  # Path ratio (≥1, higher = less efficient)
      eff = A / drag_distance,    # Path efficiency (0-1], higher = more efficient
      excess = drag_distance - A, # Excess distance (px, 0 = straight)
      speed = drag_distance / rt_s, # Effective speed (px/s)
      # Flag outliers
      bad_traj = ratio < 1 | ratio > 5 | is.na(ratio),
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    ) %>%
    filter(
      !is.na(drag_distance),
      drag_distance > 0,
      !bad_traj  # Exclude invalid trajectories
    )
  
  if (nrow(df_drag) > 0) {
    # Summary statistics with derived metrics
    drag_summary <- df_drag %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N_Trials = n(),
        Mean_Path_Length = round(mean(drag_distance, na.rm = TRUE), 1),
        Mean_Amplitude = round(mean(A, na.rm = TRUE), 1),
        Mean_Ratio = round(mean(ratio, na.rm = TRUE), 2),
        Mean_Efficiency = round(mean(eff, na.rm = TRUE), 3),
        Mean_Excess = round(mean(excess, na.rm = TRUE), 1),
        Mean_RT = round(mean(rt_ms, na.rm = TRUE), 1),
        .groups = "drop"
      )
    
    drag_summary %>%
      kable(caption = "Path Length and Efficiency Metrics by Condition") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  } else {
    cat("⚠ No valid trajectory data available for path length computation.\n")
    cat("Note: Path length analysis requires trajectory data. Early participants may not have trajectory logs.\n")
    cat("This analysis will be limited to participants with trajectory data.\n")
  }
} else {
  cat("⚠ Required columns (trajectory, A) not found for path length analysis.\n")
  cat("Path length metrics require trajectory data to compute actual cursor travel distance.\n")
}
```

```{r plot-path-length-hexbin}
#| fig-cap: "Path Length vs. Movement Time (Log-Log Scale). 2D density plot showing the relationship between actual cursor path length and movement time. GAM smooth captures nonlinearity. Log scales handle right-skewed distributions and heteroscedasticity."

if (exists("df_drag") && nrow(df_drag) > 0) {
  # Try to load hexbin, fall back to density2d if not available
  has_hexbin <- requireNamespace("hexbin", quietly = TRUE)
  
  df_plot <- df_drag %>%
    filter(!is.na(drag_distance), drag_distance > 0, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    if (has_hexbin) {
      library(hexbin)
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_hex(bins = 35, alpha = 0.7, show.legend = FALSE) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma", trans = "log10") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)",
          color = "UI Mode",
          fill = "Count"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    } else {
      # Fallback: use density2d and points
      p1 <- ggplot(df_plot, aes(x = drag_distance, y = rt_s, color = ui_mode)) +
        geom_point(alpha = 0.1, size = 0.8) +
        stat_density2d(aes(fill = ..level..), geom = "polygon", alpha = 0.3, contour = TRUE) +
        geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                    alpha = 0.3, linewidth = 1.2, method.args = list(family = "gaussian")) +
        scale_x_log10(labels = scales::label_number()) +
        scale_y_log10(labels = scales::label_number()) +
        scale_fill_viridis_c(option = "plasma") +
        facet_grid(modality ~ pressure,
                   labeller = labeller(
                     modality = function(x) paste("Modality:", str_to_title(x)),
                     pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                   )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        labs(
          x = "Actual Path Length (px, log10)",
          y = "Movement Time (s, log10)",
          color = "UI Mode",
          fill = "Density"
        ) +
        theme_minimal(base_size = 14) +
        theme(
          legend.position = "top",
          strip.text = element_text(face = "bold", size = 12),
          strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
          panel.grid.minor = element_blank()
        )
    }
    
    print(p1)
  }
}
```

```{r plot-path-efficiency}
#| fig-cap: "Path Efficiency vs. Movement Time. Path efficiency (A / path length) indicates how straight the movement was. Higher efficiency (closer to 1.0) means straighter paths. This plot shows whether inefficient movements lead to longer movement times, and whether adaptive UI improves efficiency."

if (exists("df_drag") && nrow(df_drag) > 0) {
  df_plot <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1, rt_s > 0)
  
  if (nrow(df_plot) > 0) {
    p2 <- ggplot(df_plot, aes(x = eff, y = rt_s, color = ui_mode)) +
      geom_point(alpha = 0.15, size = 1) +
      geom_smooth(method = "gam", formula = y ~ s(x, k = 6), se = TRUE, 
                  alpha = 0.3, linewidth = 1.1, method.args = list(family = "gaussian")) +
      geom_vline(xintercept = 0.9, linetype = "dashed", alpha = 0.4, linewidth = 0.5) +
      scale_y_log10(labels = scales::label_number()) +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      labs(
        x = "Path Efficiency (A / path length)",
        y = "Movement Time (s, log10)",
        color = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p2)
  }
}
```

```{r plot-path-ratio-by-id}
#| fig-cap: "Path Ratio by Index of Difficulty. Mean path ratio (path length / amplitude) binned by ID quartiles. Shows whether excess path length increases with task difficulty, and whether adaptive UI reduces this effect. Higher ratio indicates less efficient (more curved) movements."

if (exists("df_drag") && nrow(df_drag) > 0 && "ID" %in% names(df_drag)) {
  df_filtered <- df_drag %>%
    filter(!is.na(ID), !is.na(ratio), ratio > 0)
  
  if (nrow(df_filtered) > 0) {
    # Compute quantiles and ensure breaks are unique
    id_quantiles <- quantile(df_filtered$ID, probs = seq(0, 1, 0.25), na.rm = TRUE, names = FALSE)
    id_quantiles <- unique(sort(id_quantiles))
    
    # Need at least 2 unique break points for cut() to work
    if (length(id_quantiles) >= 2) {
      # If we have fewer than 4 unique breaks, use fewer bins
      n_bins <- min(length(id_quantiles) - 1, 4)
      
      if (n_bins >= 2) {
        # Create breaks with unique values
        if (n_bins == 4) {
          breaks <- id_quantiles
          labels <- c("Q1 (Low)", "Q2", "Q3", "Q4 (High)")
        } else if (n_bins == 3) {
          breaks <- c(id_quantiles[1], id_quantiles[ceiling(length(id_quantiles)/2)], id_quantiles[length(id_quantiles)])
          labels <- c("Low", "Medium", "High")
        } else {
          breaks <- c(id_quantiles[1], id_quantiles[length(id_quantiles)])
          labels <- c("Low", "High")
        }
        
        df_binned <- df_filtered %>%
          mutate(
            ID_bin = cut(ID, 
                         breaks = breaks,
                         include.lowest = TRUE,
                         labels = labels)
          ) %>%
          filter(!is.na(ID_bin)) %>%
          group_by(modality, pressure, ui_mode, ID_bin) %>%
          summarise(
            n = n(),
            mean_ratio = mean(ratio, na.rm = TRUE),
            se_ratio = sd(ratio, na.rm = TRUE) / sqrt(n()),
            mean_eff = mean(eff, na.rm = TRUE),
            .groups = "drop"
          )
        
        if (nrow(df_binned) > 0 && sum(df_binned$n) > 0) {
          p3 <- ggplot(df_binned, aes(x = ID_bin, y = mean_ratio, group = ui_mode, color = ui_mode)) +
            geom_line(linewidth = 1, alpha = 0.8) +
            geom_point(size = 2.5) +
            geom_errorbar(aes(ymin = mean_ratio - se_ratio, ymax = mean_ratio + se_ratio),
                          width = 0.1, linewidth = 0.5, alpha = 0.6) +
            geom_hline(yintercept = 1.0, linetype = "dashed", alpha = 0.3, linewidth = 0.5) +
            facet_grid(modality ~ pressure,
                       labeller = labeller(
                         modality = function(x) paste("Modality:", str_to_title(x)),
                         pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                       )) +
            scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
            labs(
              x = "Index of Difficulty (binned)",
              y = "Mean Path Ratio (path length / amplitude)",
              color = "UI Mode"
            ) +
            theme_minimal(base_size = 14) +
            theme(
              legend.position = "top",
              strip.text = element_text(face = "bold", size = 12),
              strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
              panel.grid.minor = element_blank(),
              axis.text.x = element_text(angle = 45, hjust = 1)
            )
          
          print(p3)
        } else {
          cat("⚠ Insufficient data for ID binning plot.\n")
        }
      } else {
        cat("⚠ Insufficient ID variation for binning (all values are similar).\n")
        cat("Skipping ID binning plot.\n")
      }
    } else {
      cat("⚠ Insufficient ID variation for binning (all values are similar).\n")
      cat("Skipping ID binning plot.\n")
    }
  } else {
    cat("⚠ No valid ID/ratio data for binning plot.\n")
  }
}
```

```{r plot-path-efficiency-individual}
#| fig-cap: "Individual Differences in Path Efficiency. Thin lines show per-participant mean efficiency by UI mode. Thick line and large point show condition mean. Shows whether adaptive UI consistently improves efficiency across participants."

if (exists("df_drag") && nrow(df_drag) > 0 && "pid" %in% names(df_drag)) {
  df_pid <- df_drag %>%
    filter(!is.na(eff), eff > 0, eff <= 1) %>%
    group_by(pid, modality, pressure, ui_mode) %>%
    summarise(
      mean_eff = mean(eff, na.rm = TRUE),
      n_trials = n(),
      .groups = "drop"
    ) %>%
    filter(n_trials >= 5)  # Only participants with sufficient data
  
  if (nrow(df_pid) > 0) {
    p4 <- ggplot(df_pid, aes(x = ui_mode, y = mean_eff, group = pid)) +
      geom_line(alpha = 0.2, linewidth = 0.5) +
      geom_point(alpha = 0.3, size = 1.5) +
      stat_summary(aes(group = 1), fun = mean, geom = "line", linewidth = 1.2, color = "black") +
      stat_summary(aes(group = 1), fun = mean, geom = "point", size = 3, color = "black", shape = 21, fill = "white") +
      facet_grid(modality ~ pressure,
                 labeller = labeller(
                   modality = function(x) paste("Modality:", str_to_title(x)),
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        x = "UI Mode",
        y = "Mean Path Efficiency (A / path length)",
        caption = "Thin lines: individual participants. Thick line: condition mean."
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "none",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank()
      )
    
    print(p4)
  }
}
```

-----

# 15. Gaze-Specific Analysis

## Hover Time (Dwell Duration)

**Research Question:** How long do people hover before confirming? Does adaptive UI change dwell behavior?

*For gaze modality, hover time represents the dwell duration before confirmation.*

```{r hover-time}
if ("hover_ms" %in% names(df_raw)) {
  df_hover <- df_raw %>%
    filter(
      practice == "false" | practice == FALSE | is.na(practice),
      str_to_lower(modality) == "gaze",
      !is.na(hover_ms), hover_ms > 0
    ) %>%
    mutate(
      hover_s = hover_ms / 1000,
      hover_ratio = hover_ms / rt_ms,
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    )
  
  if (nrow(df_hover) > 0) {
    # Summary statistics
    hover_summary <- df_hover %>%
      group_by(ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean_Hover = round(mean(hover_s, na.rm = TRUE), 3),
        SD_Hover = round(sd(hover_s, na.rm = TRUE), 3),
        Mean_Ratio = round(mean(hover_ratio, na.rm = TRUE), 3),
        .groups = "drop"
      )
    
    hover_summary %>%
      kable(caption = "Hover Time for Gaze Modality") %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
    
    # Visualization - improved faceting and aesthetics
    p1 <- ggplot(df_hover, aes(x = ui_mode, y = hover_s, fill = ui_mode)) +
      geom_violin(trim = FALSE, alpha = 0.5, linewidth = 0.8, color = "white", 
                  show.legend = FALSE) +
      geom_boxplot(width = 0.15, position = position_dodge(0.9), alpha = 0.9, 
                   outlier.alpha = 0.4, outlier.size = 1.5, linewidth = 0.5) +
      stat_summary(fun = mean, geom = "point", shape = 23, size = 3.5, 
                   position = position_dodge(0.9), color = "black", fill = "white", stroke = 1.2) +
      facet_wrap(~pressure,
                 labeller = labeller(
                   pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
                 )) +
      scale_fill_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
      scale_x_discrete(labels = c("Static", "Adaptive")) +
      labs(
        title = "Hover Duration (Gaze Modality)",
        subtitle = "Dwell time before confirmation. White diamonds indicate means.",
        x = "UI Mode",
        y = "Hover Time (s)",
        fill = "UI Mode"
      ) +
      theme_minimal(base_size = 14) +
      theme(
        legend.position = "top",
        strip.text = element_text(face = "bold", size = 12),
        strip.background = element_rect(fill = "grey90", color = "grey70", linewidth = 0.5),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(color = "grey80", fill = NA, linewidth = 0.5)
      )
    
    print(p1)
    
    # Hover vs. Total RT
    # Check if IDe exists, otherwise use ID
    if ("IDe" %in% names(df_hover)) {
      df_hover_id <- df_hover %>%
        filter(!is.na(IDe)) %>%
        mutate(difficulty = IDe)
    } else if ("ID" %in% names(df_hover)) {
      df_hover_id <- df_hover %>%
        filter(!is.na(ID)) %>%
        mutate(difficulty = ID)
    } else {
      df_hover_id <- data.frame()
    }
    
    if (nrow(df_hover_id) > 0) {
      p2 <- ggplot(df_hover_id, aes(x = difficulty, y = hover_s, color = ui_mode)) +
        geom_point(alpha = 0.3, size = 1) +
        geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
        facet_wrap(~pressure, labeller = labeller(
        pressure = function(x) ifelse(x == "1" | x == 1, "Pressure: ON", "Pressure: OFF")
      )) +
        scale_color_manual(values = custom_palette_2, labels = c("Static", "Adaptive")) +
        labs(
          title = "Hover Time vs. Task Difficulty",
          subtitle = "How dwell duration scales with index of difficulty",
          x = "Index of Difficulty (bits)",
          y = "Hover Time (s)",
          color = "UI Mode"
        ) +
        theme_minimal(base_size = 14) +
        theme(legend.position = "top", strip.text = element_text(face = "bold"))
      
      print(p2)
    }
  } else {
    cat("⚠ No valid hover time data available for gaze modality.\n")
  }
} else {
  cat("⚠ hover_ms column not found in dataset.\n")
}
```

-----

# 16. Advanced Cognitive Models: Linear Ballistic Accumulator (LBA)

**Research Question:** How do decision verification processes differ across conditions? What caution thresholds do users adopt?

*The Linear Ballistic Accumulator (LBA) model [@brown2008] treats the selection decision as a race between independent accumulators. Unlike Drift Diffusion Models (DDM), LBA is robust to low error rates typical of Fitts' tasks and allows explicit estimation of the "Caution Threshold" (b - A)—the amount of evidence users require before committing to selection. We hypothesize that adaptive interventions reduce the cognitive need for caution, mathematically reflecting a lower estimated threshold b.*

**Status:** ⚠️ **PLACEHOLDER - Analysis not yet implemented**

**Note:** This section is a placeholder for future LBA model fitting. The analysis requires verification phase RTs (time from first target entry to selection), which are available in the `verification_time_ms` column. Implementation will require installing R packages such as `RWiener` or `rtdists` and fitting a **hierarchical LBA model** (not per-condition per-person fits) due to limited trials per condition (~24/cell) and low error rates (3-5%). See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed power analysis and modeling recommendations.

**Power Analysis Summary:**
- **N=48 is sufficient** for medium main effects (dz≈0.41, power≈0.80)
- **Interactions will be underpowered** unless large (treat as exploratory)
- **Key constraint:** Trial count (~24/cell) and error rate (3-5%) limit identifiability
- **Recommendation:** Use hierarchical LBA with parameters as functions of experimental factors

```{r lba-placeholder}
# TODO: Implement hierarchical LBA model fitting
# Required packages: RWiener, rtdists, or custom LBA implementation
# 
# IMPORTANT: Use hierarchical LBA (not per-condition per-person fits)
# Rationale: ~24 trials/cell is too thin for stable per-condition parameters
#            Low error rates (3-5%) limit identifiability
#            Hierarchical modeling with partial pooling stabilizes estimation
# 
# Steps:
# 1. Prepare data: Extract verification phase RTs (time from first target entry to selection)
# 2. Fit hierarchical LBA model with parameters as functions of experimental factors:
#    - Threshold (b-A) ~ UI mode + pressure + (UI mode × pressure) + (1|pid)
#    - Drift rate (v) ~ modality + (modality × UI mode) + (1|pid)
#    - Starting point (A): Fixed or vary by condition if theoretically justified
#    - Non-decision time (t0): Fixed or vary by condition
# 3. Early identifiability check: Fit on first ~15-20 participants
#    - Check for: divergent transitions, extreme posteriors, wide credible intervals
# 4. Compare parameters across conditions (main effects: N=48 sufficient)
# 5. Test hypothesis: Adaptive conditions → lower threshold (b)
# 6. Treat interactions as exploratory (underpowered with N=48)
# 
# See POWER_ANALYSIS_EXPERT_RESPONSE.md for detailed recommendations

cat("⚠️ **LBA Analysis Not Yet Implemented**\n\n")
cat("This section will analyze decision verification processes using the Linear Ballistic Accumulator model.\n\n")
cat("**Required Data:**\n")
cat("- Verification time (time from first target entry to selection)\n")
cat("- Correct/error outcomes\n")
cat("- Condition labels (modality, ui_mode, pressure)\n\n")

# Check if required data exists
if ("verification_time_ms" %in% names(df)) {
  df_verify_check <- df %>%
    filter(!is.na(verification_time_ms), verification_time_ms > 0, verification_time_ms <= 6000)
  
  if (nrow(df_verify_check) > 0) {
    cat("✅ Verification time data available:\n")
    cat("   - N trials with verification time:", nrow(df_verify_check), "\n")
    cat("   - Mean verification time:", round(mean(df_verify_check$verification_time_ms, na.rm = TRUE), 1), "ms\n")
    cat("   - Range:", round(min(df_verify_check$verification_time_ms, na.rm = TRUE), 1), "-", 
        round(max(df_verify_check$verification_time_ms, na.rm = TRUE), 1), "ms\n")
    cat("\n**Data Quality Check:**\n")
    
    # Check for sufficient data per condition
    verify_by_condition <- df_verify_check %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(n = n(), .groups = "drop")
    
    min_trials <- min(verify_by_condition$n, na.rm = TRUE)
    if (min_trials < 20) {
      cat("   ⚠️  Some conditions have < 20 trials (minimum:", min_trials, ")\n")
      cat("      ⚠️  CRITICAL: ~24 trials/cell is too thin for per-condition per-person LBA fits\n")
      cat("      ✅ Use hierarchical LBA with parameters as functions of factors (recommended)\n")
    } else {
      cat("   ✅ Sufficient trials per condition (minimum:", min_trials, ")\n")
      cat("      ⚠️  Note: ~24 trials/cell still requires hierarchical modeling approach\n")
    }
    
    # Check error rate (LBA needs some errors, but can work with low rates)
    error_rate <- mean(df_errors$error, na.rm = TRUE)
    cat("   - Overall error rate:", round(error_rate * 100, 2), "%\n")
    if (error_rate < 0.15) {
      cat("   ⚠️  CRITICAL: Low error rate (", round(error_rate * 100, 1), "%) limits LBA identifiability\n")
      cat("      Recommended range: 15-35% errors for strong identifiability\n")
      cat("      With low errors + small trial counts, parameters may trade off\n")
      cat("      ✅ Hierarchical modeling helps but identifiability check is essential\n")
    } else if (error_rate < 0.01) {
      cat("   ⚠️  Very low error rate - LBA can still fit but boundary separation may be less constrained\n")
    } else {
      cat("   ✅ Error rate sufficient for LBA fitting\n")
    }
    
    cat("\n**Next Steps:**\n")
    cat("1. Install required packages: `install.packages(c('RWiener', 'rtdists'))`\n")
    cat("2. Prepare verification phase RTs (correct trials only for now)\n")
    cat("3. Fit HIERARCHICAL LBA model (NOT per-condition per-person):\n")
    cat("   - Model parameters as functions of experimental factors\n")
    cat("   - Use partial pooling to stabilize estimation\n")
    cat("4. Early identifiability check: Fit on first ~15-20 participants\n")
    cat("   - Check for: divergent transitions, extreme posteriors, wide CIs\n")
    cat("5. Compare threshold (b) and drift rate (v) across conditions\n")
    cat("   - Main effects: N=48 is sufficient (dz≈0.41, power≈0.80)\n")
    cat("   - Interactions: Underpowered, treat as exploratory\n")
    cat("6. Test hypothesis: Adaptive UI → lower threshold (less caution needed)\n")
    cat("\n**See POWER_ANALYSIS_EXPERT_RESPONSE.md for detailed recommendations**\n")
  } else {
    cat("❌ No valid verification time data available\n")
  }
} else {
  cat("❌ verification_time_ms column not found in dataset\n")
}
```

```{r lba-data-prep}
# Placeholder: Data preparation for LBA analysis
# This chunk will prepare verification phase RTs for LBA fitting

if ("verification_time_ms" %in% names(df)) {
  df_lba_prep <- df %>%
    filter(
      !is.na(verification_time_ms),
      verification_time_ms > 0,
      verification_time_ms <= 6000,
      correct == TRUE | correct == "true" | correct == 1
    ) %>%
    mutate(
      verification_s = verification_time_ms / 1000,
      modality = factor(modality, levels = c("hand", "gaze")),
      ui_mode = factor(ui_mode, levels = c("static", "adaptive")),
      pressure = factor(pressure)
    )
  
  if (nrow(df_lba_prep) > 0) {
    cat("**LBA Data Preparation:**\n")
    cat("- Valid verification RTs:", nrow(df_lba_prep), "\n")
    cat("- Conditions:", n_distinct(interaction(df_lba_prep$modality, df_lba_prep$ui_mode, df_lba_prep$pressure)), "\n")
    cat("\n**Verification RT Summary by Condition:**\n")
    
    lba_summary <- df_lba_prep %>%
      group_by(modality, ui_mode, pressure) %>%
      summarise(
        N = n(),
        Mean = round(mean(verification_s, na.rm = TRUE), 3),
        SD = round(sd(verification_s, na.rm = TRUE), 3),
        Median = round(median(verification_s, na.rm = TRUE), 3),
        .groups = "drop"
      )
    
    print(knitr::kable(lba_summary, caption = "Verification Phase RTs (for LBA analysis)"))
    
    cat("\n⚠️ **LBA Model Fitting Not Yet Implemented**\n")
    cat("Data is prepared and ready for LBA analysis.\n")
  }
}
```

**Implementation Notes:**
- LBA requires RT data from the verification phase (time from target entry to selection)
- Model fitting can be done using `RWiener` or `rtdists` packages
- Key parameters to estimate: drift rate (v), threshold (b), starting point (A), non-decision time (t0)
- Hypothesis: Adaptive conditions should show lower threshold (b), indicating less caution needed

-----

# 17. Control Theory Analysis: Submovement Models

**Research Question:** How does the control loop efficiency differ across conditions? Do adaptive interventions reduce movement corrections?

*The Optimized Submovement Model [@meyer1988] posits that pointing movements are composed of a primary ballistic impulse followed by n corrective submovements. The Submovement Count (N_sub) serves as a proxy for the efficiency of the control loop. In gaze-based interaction, simulated lag and saccadic blindness force users into an intermittent control regime, theoretically increasing N_sub.*

**Status:** ⚠️ **PARTIALLY IMPLEMENTED - Basic analysis done, advanced control theory analysis pending**

**Note:** Basic submovement analysis (submovement count by condition) is already implemented in Section 10 (Movement Quality Metrics). This section is a placeholder for advanced control theory analyses such as velocity profile decomposition, primary vs. corrective movement identification, and control loop efficiency metrics. Trajectory data is now available in the `trajectory` column (JSON string) logged at ~60fps during trials.

**Power Analysis Summary:**
- **N=48 is sufficient** for medium main effects (dz≈0.41, power≈0.80)
- **Interactions will be underpowered** unless large (treat as exploratory)
- **60fps trajectory data** improves measurement precision but doesn't increase effective N
- **Key considerations:** Use duration-normalized smoothness metrics, control for multiple comparisons (FDR), pre-specify outcomes
- See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed recommendations

```{r control-theory-placeholder}
# TODO: Advanced control theory analysis
# Current status: Basic submovement_count analysis is in Section 10
# Advanced analysis needed:
# 1. Velocity profile analysis (extract from cursor trajectory data if available)
# 2. Submovement detection algorithm (zero-crossings in acceleration)
# 3. Primary vs. corrective movement decomposition
# 4. Control loop efficiency metrics

cat("⚠️ **Advanced Control Theory Analysis Not Yet Implemented**\n\n")
cat("This section will analyze movement control using the Optimized Submovement Model.\n\n")
cat("**Current Status:**\n")
cat("- Basic submovement_count analysis: ✅ DONE (Section 10)\n")
cat("- Velocity profile analysis: ❌ PENDING\n")
cat("- Submovement detection algorithm: ❌ PENDING\n")
cat("- Primary vs. corrective movement decomposition: ❌ PENDING\n\n")

# Check if submovement_count data exists
if ("submovement_count" %in% names(df)) {
  df_submov_check <- df %>%
    filter(!is.na(submovement_count), submovement_count >= 0)
  
  if (nrow(df_submov_check) > 0) {
    cat("✅ Submovement count data available:\n")
    cat("   - N trials with submovement data:", nrow(df_submov_check), "\n")
    cat("   - Mean submovements per trial:", round(mean(df_submov_check$submovement_count, na.rm = TRUE), 2), "\n")
    cat("   - Range:", round(min(df_submov_check$submovement_count, na.rm = TRUE), 0), "-", 
        round(max(df_submov_check$submovement_count, na.rm = TRUE), 0), "\n\n")
    
    # Check for condition differences
    submov_by_condition <- df_submov_check %>%
      group_by(modality, ui_mode) %>%
      summarise(
        Mean_Submov = round(mean(submovement_count, na.rm = TRUE), 2),
        SD_Submov = round(sd(submovement_count, na.rm = TRUE), 2),
        .groups = "drop"
      )
    
    cat("**Submovement Count by Modality and UI Mode:**\n")
    print(knitr::kable(submov_by_condition))
    
    cat("\n**Data Quality Check:**\n")
    # Check if we have cursor trajectory data (needed for velocity profile analysis)
    if ("trajectory" %in% names(df_raw)) {
      df_traj_check <- df_raw %>%
        filter(
          practice == "false" | practice == FALSE | is.na(practice),
          !is.na(trajectory),
          trajectory != "",
          trajectory != "null"
        )
      
      if (nrow(df_traj_check) > 0) {
        cat("   ✅ Trajectory data available in CSV:\n")
        cat("      - N trials with trajectory:", nrow(df_traj_check), "\n")
        cat("      - Trajectory stored as JSON string in 'trajectory' column\n")
        cat("      - Can be parsed in R: jsonlite::fromJSON(trajectory)\n")
      } else {
        cat("   ⚠️  Trajectory column exists but no data yet (may be from old data)\n")
      }
    } else {
      cat("   ⚠️  Trajectory column not found (may be from old data)\n")
    }
    cat("   - Current analysis uses pre-calculated submovement_count from FittsTask.tsx\n")
    
    cat("\n**Next Steps for Advanced Analysis:**\n")
    cat("1. If cursor trajectory data is needed, add logging to FittsTask.tsx\n")
    cat("2. Implement velocity profile extraction from trajectory\n")
    cat("3. Detect submovements using zero-crossings in acceleration profile\n")
    cat("4. Decompose primary vs. corrective movements\n")
    cat("5. Compare control loop efficiency across conditions\n")
    cat("6. Test hypothesis: Adaptive UI → fewer submovements (more ballistic)\n")
  } else {
    cat("❌ No valid submovement data available\n")
  }
} else {
  cat("❌ submovement_count column not found in dataset\n")
}
```

```{r control-theory-advanced}
# Placeholder: Advanced control theory metrics
# This would analyze velocity profiles and movement decomposition

cat("⚠️ **Advanced Control Theory Metrics Not Yet Implemented**\n\n")
cat("**Planned Analyses:**\n")
cat("1. **Velocity Profile Analysis:**\n")
cat("   - Peak velocity extraction\n")
cat("   - Time to peak velocity (TPV)\n")
cat("   - Deceleration phase duration\n")
cat("   - Velocity profile asymmetry\n\n")
cat("2. **Submovement Detection:**\n")
cat("   - Zero-crossing detection in acceleration profile\n")
cat("   - Primary movement identification (first ballistic phase)\n")
cat("   - Corrective submovement count and duration\n")
cat("   - Inter-submovement intervals\n\n")
cat("3. **Control Loop Efficiency:**\n")
cat("   - Ratio of primary to total movement time\n")
cat("   - Correction frequency (submovements per second)\n")
cat("   - Movement smoothness metrics (jerk, normalized jerk - MUST be duration-normalized)\n\n")
cat("4. **Modality-Specific Patterns:**\n")
cat("   - Gaze: Intermittent control due to lag and saccadic blindness\n")
cat("   - Hand: Continuous control with proprioceptive feedback\n")
cat("   - Adaptive: Reduced corrections due to target expansion/declutter\n\n")
cat("**Data Requirements:**\n")
cat("✅ Trajectory data is now available in 'trajectory' column (JSON string, ~60fps)\n")
cat("✅ Current CSV has submovement_count (pre-calculated) AND raw trajectory\n")
cat("\n**Power & Analysis Considerations:**\n")
cat("- N=48 is sufficient for main effects (dz≈0.41, power≈0.80)\n")
cat("- Interactions: Underpowered, treat as exploratory\n")
cat("- 60fps improves measurement precision but doesn't increase effective N\n")
cat("- Use duration-normalized smoothness metrics\n")
cat("- Control for multiple comparisons (FDR) if testing many metrics\n")
cat("- Pre-specify theoretically motivated outcomes\n")
cat("\n**See POWER_ANALYSIS_EXPERT_RESPONSE.md for detailed recommendations**\n")
```

**Implementation Notes:**
- Basic submovement analysis is already in Section 10 (Movement Quality Metrics)
- **Trajectory data is now available** in the `trajectory` column (JSON string, logged at ~60fps)
- Current `submovement_count` is pre-calculated in `FittsTask.tsx` using velocity peaks
- **Power:** N=48 sufficient for main effects (dz≈0.41, power≈0.80); interactions underpowered (treat as exploratory)
- **Key considerations:**
  - Use duration-normalized smoothness metrics (jerk is duration-sensitive)
  - Control for multiple comparisons (FDR) if testing many kinematic features
  - Pre-specify a small set of theoretically motivated outcomes
  - 60fps improves measurement precision but doesn't increase effective N
- **See `POWER_ANALYSIS_EXPERT_RESPONSE.md` for detailed power analysis and recommendations**

**Potential Issues to Check:**
- Verify that `submovement_count` calculation in `FittsTask.tsx` matches the Optimized Submovement Model definition
- Check if velocity profile data is needed or if pre-calculated counts are sufficient
- Ensure submovement detection algorithm handles both hand and gaze modalities correctly

-----

# 18. Summary & Conclusions

## Key Findings Summary

```{r summary-table}
# Create a comprehensive summary table
summary_table <- bind_rows(
  # Throughput
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Throughput (bits/s)",
      Mean = round(mean(TP, na.rm = TRUE), 2),
      SD = round(sd(TP, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Movement Time
  df %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Movement Time (s)",
      Mean = round(mean(rt_s, na.rm = TRUE), 3),
      SD = round(sd(rt_s, na.rm = TRUE), 3),
      .groups = "drop"
    ),
  # Error Rate
  df_errors %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Error Rate (%)",
      Mean = round(100 * mean(error, na.rm = TRUE), 2),
      SD = round(100 * sd(error, na.rm = TRUE), 2),
      .groups = "drop"
    ),
  # Effective Width
  df_iso %>%
    group_by(modality, ui_mode) %>%
    summarise(
      Metric = "Effective Width (px)",
      Mean = round(mean(We, na.rm = TRUE), 2),
      SD = round(sd(We, na.rm = TRUE), 2),
      .groups = "drop"
    )
) %>%
  arrange(Metric, modality, ui_mode)

summary_table %>%
  kable(caption = "Summary of Key Metrics by Condition") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

## Data Quality Notes

- **Participants:** `r n_distinct(df$pid)`
- **Valid Trials:** `r nrow(df)` (out of `r nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice)))` total experimental trials)
- **Exclusion Rate:** `r percent(round(1 - nrow(df) / nrow(df_raw %>% filter(practice == "false" | practice == FALSE | is.na(practice))), 3))` (due to errors, timeouts, or invalid RTs)
- **Trials per Participant:** Mean = `r round(mean(table(df$pid)), 1)`, Range = `r paste(round(min(table(df$pid)), 0), "-", round(max(table(df$pid)), 0))`

### Participant Exclusions

**Excluded Participants:** Seven participants (P002, P003, P007, P008, P015, P039, P040) were excluded from the main 2×2×2 factorial analysis due to a data logging error.

**Reason:** A bug in the data logging code (fixed December 8, 2025, commit `04758db`) incorrectly recorded all trials as `pressure = 1` regardless of block condition. The bug was caused by passing the pressure value (always 1.0) instead of the pressure condition boolean (`pressureEnabled`) to the logging function in `TaskPane.tsx` line 1105.

**Impact:** 
- All 7 affected participants have only `pressure = 1` data
- Modality and UI Mode were logged correctly (0 mismatches)
- Without both pressure conditions (0 and 1), these participants cannot contribute to the full factorial model

**Resolution:** 
- Bug fixed and deployed (commit `04758db`)
- Seven replacement participants (P049-P055) added to maintain N=48
- Affected participants' data retained for exploratory analyses

**Final Sample:** N=48 participants with complete data across all experimental conditions.

For detailed exclusion criteria, see `EXCLUSION_CRITERIA.md`. For technical audit details, see `AUDIT_REPORT.md`.

